{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LightAutoML —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º –∏–∑ OpenML\n",
        "\n",
        "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –±–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ LightAutoML –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ –∏–∑ OpenML.\n",
        "\n",
        "## üìã –†–µ–∑—é–º–µ —Ä–µ—à–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º\n",
        "\n",
        "### –ü—Ä–æ–±–ª–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã:\n",
        "\n",
        "1. **–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ LightAutoML (TypeError —Å log_calls)**\n",
        "   - **–ü—Ä–æ–±–ª–µ–º–∞**: `TypeError: cannot set 'get_record_history_wrapper' attribute of immutable type 'object'`\n",
        "   - **–†–µ—à–µ–Ω–∏–µ**: –û–±–Ω–æ–≤–ª–µ–Ω `log_calls` –¥–æ –≤–µ—Ä—Å–∏–∏ 0.3.2 –∏ `lightautoml` –¥–æ –≤–µ—Ä—Å–∏–∏ 0.4.1\n",
        "\n",
        "2. **–û—à–∏–±–∫–∞ —Å CategoricalDtype**\n",
        "   - **–ü—Ä–æ–±–ª–µ–º–∞**: `TypeError: Cannot interpret 'CategoricalDtype(...)' as a data type`\n",
        "   - **–†–µ—à–µ–Ω–∏–µ**: –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∏–ø –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–¥–∞—á–µ–π –≤ LightAutoML\n",
        "\n",
        "3. **–û—à–∏–±–∫–∞ —Å psutil/joblib**\n",
        "   - **–ü—Ä–æ–±–ª–µ–º–∞**: `AttributeError: module 'psutil' has no attribute 'Process'`\n",
        "   - **–†–µ—à–µ–Ω–∏–µ**: \n",
        "     - –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω `psutil`\n",
        "     - –û—Ç–∫–ª—é—á–µ–Ω—ã `advanced_roles` –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö reader (`advanced_roles: False`)\n",
        "     - –£–º–µ–Ω—å—à–µ–Ω `n_jobs` –¥–æ 1 –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\n",
        "\n",
        "### –ö–∞–∫ –∑–∞–ø—É—Å–∫–∞—Ç—å LightAutoML:\n",
        "\n",
        "1. **–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π**:\n",
        "   ```bash\n",
        "   uv pip install lightautoml>=0.4.1 log_calls psutil\n",
        "   ```\n",
        "\n",
        "2. **–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è**:\n",
        "   ```python\n",
        "   from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
        "   from lightautoml.tasks import Task\n",
        "   \n",
        "   task = Task('binary')  # –∏–ª–∏ 'reg' –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
        "   automl = TabularAutoML(\n",
        "       task=task,\n",
        "       timeout=300,\n",
        "       cpu_limit=4,\n",
        "       reader_params={\n",
        "           'n_jobs': 1,\n",
        "           'cv': 5,\n",
        "           'random_state': 42,\n",
        "           'advanced_roles': False,  # –í–∞–∂–Ω–æ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å psutil\n",
        "       }\n",
        "   )\n",
        "   ```\n",
        "\n",
        "3. **–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö**:\n",
        "   - –ü—Ä–µ–æ–±—Ä–∞–∑—É–π—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∏–ø\n",
        "   - –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ target —Ç–∞–∫–∂–µ —Å—Ç—Ä–æ–∫–æ–≤—ã–π, –µ—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π\n",
        "\n",
        "4. **–û–±—É—á–µ–Ω–∏–µ**:\n",
        "   ```python\n",
        "   roles = {\n",
        "       'target': 'target',\n",
        "       'category': categorical_features\n",
        "   }\n",
        "   oof_predictions = automl.fit_predict(train_data, roles=roles, verbose=1)\n",
        "   ```\n",
        "\n",
        "5. **–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è**:\n",
        "   ```python\n",
        "   test_predictions = automl.predict(test_data)\n",
        "   ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–í—Å–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã!\n"
          ]
        }
      ],
      "source": [
        "# –ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
        "import openml\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
        "from lightautoml.tasks import Task\n",
        "\n",
        "print(\"–í—Å–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ OpenML\n",
        "\n",
        "\n",
        "–í—ã–±–µ—Ä–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, dataset_id=31 (credit-g) - –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Ä–∏—Å–∫–∞.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å ID=31 –∏–∑ OpenML...\n",
            "–î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: credit-g\n",
            "–û–ø–∏—Å–∞–Ω–∏–µ: **Author**: Dr. Hans Hofmann  \n",
            "**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)) - 1994    \n",
            "**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy....\n",
            "\n",
            "–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: (1000, 20)\n",
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 20\n",
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 13\n",
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: 2\n",
            "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:\n",
            "class\n",
            "good    700\n",
            "bad     300\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ OpenML\n",
        "dataset_id = 31  # credit-g dataset\n",
        "print(f\"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å ID={dataset_id} –∏–∑ OpenML...\")\n",
        "\n",
        "dataset = openml.datasets.get_dataset(dataset_id)\n",
        "print(f\"–î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {dataset.name}\")\n",
        "print(f\"–û–ø–∏—Å–∞–Ω–∏–µ: {dataset.description[:200]}...\")\n",
        "\n",
        "# –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
        "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
        "    target=dataset.default_target_attribute\n",
        ")\n",
        "\n",
        "print(f\"\\n–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {X.shape}\")\n",
        "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}\")\n",
        "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {sum(categorical_indicator)}\")\n",
        "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {len(np.unique(y))}\")\n",
        "print(f\"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:\\n{pd.Series(y).value_counts()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç pandas DataFrame –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º –¥–ª—è LightAutoML.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (13): ['checking_status', 'credit_history', 'purpose', 'savings_status', 'employment']...\n",
            "\n",
            "–ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö:\n",
            "  checking_status  duration                  credit_history  \\\n",
            "0              <0         6  critical/other existing credit   \n",
            "1        0<=X<200        48                   existing paid   \n",
            "2     no checking        12  critical/other existing credit   \n",
            "3              <0        42                   existing paid   \n",
            "4              <0        24              delayed previously   \n",
            "\n",
            "               purpose  credit_amount    savings_status employment  \\\n",
            "0             radio/tv         1169.0  no known savings        >=7   \n",
            "1             radio/tv         5951.0              <100     1<=X<4   \n",
            "2            education         2096.0              <100     4<=X<7   \n",
            "3  furniture/equipment         7882.0              <100     4<=X<7   \n",
            "4              new car         4870.0              <100     1<=X<4   \n",
            "\n",
            "   installment_commitment     personal_status other_parties  ...  \\\n",
            "0                       4         male single          none  ...   \n",
            "1                       2  female div/dep/mar          none  ...   \n",
            "2                       2         male single          none  ...   \n",
            "3                       2         male single     guarantor  ...   \n",
            "4                       3         male single          none  ...   \n",
            "\n",
            "   property_magnitude age  other_payment_plans   housing existing_credits  \\\n",
            "0         real estate  67                 none       own                2   \n",
            "1         real estate  22                 none       own                1   \n",
            "2         real estate  49                 none       own                1   \n",
            "3      life insurance  45                 none  for free                1   \n",
            "4   no known property  53                 none  for free                2   \n",
            "\n",
            "                  job num_dependents  own_telephone foreign_worker target  \n",
            "0             skilled              1            yes            yes   good  \n",
            "1             skilled              1           none            yes    bad  \n",
            "2  unskilled resident              2           none            yes   good  \n",
            "3             skilled              2           none            yes   good  \n",
            "4             skilled              2           none            yes    bad  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 21 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   checking_status         1000 non-null   object \n",
            " 1   duration                1000 non-null   uint8  \n",
            " 2   credit_history          1000 non-null   object \n",
            " 3   purpose                 1000 non-null   object \n",
            " 4   credit_amount           1000 non-null   float64\n",
            " 5   savings_status          1000 non-null   object \n",
            " 6   employment              1000 non-null   object \n",
            " 7   installment_commitment  1000 non-null   uint8  \n",
            " 8   personal_status         1000 non-null   object \n",
            " 9   other_parties           1000 non-null   object \n",
            " 10  residence_since         1000 non-null   uint8  \n",
            " 11  property_magnitude      1000 non-null   object \n",
            " 12  age                     1000 non-null   uint8  \n",
            " 13  other_payment_plans     1000 non-null   object \n",
            " 14  housing                 1000 non-null   object \n",
            " 15  existing_credits        1000 non-null   uint8  \n",
            " 16  job                     1000 non-null   object \n",
            " 17  num_dependents          1000 non-null   uint8  \n",
            " 18  own_telephone           1000 non-null   object \n",
            " 19  foreign_worker          1000 non-null   object \n",
            " 20  target                  1000 non-null   object \n",
            "dtypes: float64(1), object(14), uint8(6)\n",
            "memory usage: 123.2+ KB\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\1435568455.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(data[col]):\n",
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\1435568455.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(data[col]):\n",
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\1435568455.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(data[col]):\n",
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\1435568455.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(data[col]):\n",
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\1435568455.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(data[col]):\n",
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\1435568455.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(data[col]):\n",
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\1435568455.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(data[col]):\n",
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\1435568455.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(data[col]):\n",
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\1435568455.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(data[col]):\n",
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\1435568455.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(data[col]):\n",
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\1435568455.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(data[col]):\n",
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\1435568455.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(data[col]):\n",
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\1435568455.py:17: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(data[col]):\n",
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\1435568455.py:23: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(data['target']):\n"
          ]
        }
      ],
      "source": [
        "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ pandas DataFrame\n",
        "if not isinstance(X, pd.DataFrame):\n",
        "    X = pd.DataFrame(X, columns=attribute_names)\n",
        "\n",
        "# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
        "data = X.copy()\n",
        "data['target'] = y\n",
        "\n",
        "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "categorical_features = [attribute_names[i] for i in range(len(attribute_names)) if categorical_indicator[i]]\n",
        "\n",
        "# –í–∞–∂–Ω–æ: –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∏–ø\n",
        "# –≠—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å LightAutoML 0.4.1\n",
        "for col in categorical_features:\n",
        "    if col in data.columns:\n",
        "        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º CategoricalDtype –≤ –æ–±—ã—á–Ω—ã–π —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∏–ø\n",
        "        if isinstance(data[col].dtype, pd.CategoricalDtype):\n",
        "            data[col] = data[col].astype(str)\n",
        "        elif data[col].dtype == 'object':\n",
        "            data[col] = data[col].astype(str)\n",
        "\n",
        "# –¢–∞–∫–∂–µ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º target –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∏–ø, –µ—Å–ª–∏ –æ–Ω –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π\n",
        "if isinstance(data['target'].dtype, pd.CategoricalDtype):\n",
        "    data['target'] = data['target'].astype(str)\n",
        "\n",
        "print(f\"–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(categorical_features)}): {categorical_features[:5]}...\")\n",
        "print(f\"\\n–ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö:\")\n",
        "print(data.head())\n",
        "print(f\"\\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö:\")\n",
        "print(data.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train –∏ test\n",
        "\n",
        "–†–∞–∑–¥–µ–ª–∏–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: (800, 21)\n",
            "–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: (200, 21)\n",
            "\n",
            "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ train:\n",
            "target\n",
            "good    560\n",
            "bad     240\n",
            "Name: count, dtype: int64\n",
            "\n",
            "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ test:\n",
            "target\n",
            "good    140\n",
            "bad      60\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\3916335668.py:12: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(train_data[col]):\n",
            "C:\\Users\\Aleksandr\\AppData\\Local\\Temp\\ipykernel_21176\\3916335668.py:14: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(test_data[col]):\n"
          ]
        }
      ],
      "source": [
        "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train –∏ test\n",
        "train_data, test_data = train_test_split(\n",
        "    data, \n",
        "    test_size=0.2, \n",
        "    random_state=42, \n",
        "    stratify=data['target']\n",
        ")\n",
        "\n",
        "# –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –æ—Å—Ç–∞—é—Ç—Å—è —Å—Ç—Ä–æ–∫–æ–≤—ã–º–∏ –ø–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è\n",
        "for col in categorical_features:\n",
        "    if col in train_data.columns:\n",
        "        if isinstance(train_data[col].dtype, pd.CategoricalDtype):\n",
        "            train_data[col] = train_data[col].astype(str)\n",
        "        if isinstance(test_data[col].dtype, pd.CategoricalDtype):\n",
        "            test_data[col] = test_data[col].astype(str)\n",
        "\n",
        "print(f\"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {train_data.shape}\")\n",
        "print(f\"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {test_data.shape}\")\n",
        "print(f\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ train:\")\n",
        "print(train_data['target'].value_counts())\n",
        "print(f\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ test:\")\n",
        "print(test_data['target'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ LightAutoML\n",
        "\n",
        "–°–æ–∑–¥–∞–¥–∏–º –º–æ–¥–µ–ª—å LightAutoML –∏ –æ–±—É—á–∏–º –µ—ë –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightAutoML –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!\n",
            "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
            "  - –ó–∞–¥–∞—á–∞: binary\n",
            "  - Timeout: 300 —Å–µ–∫—É–Ω–¥\n",
            "  - CPU limit: 4\n",
            "  - CV folds: 5\n",
            "  - Advanced roles: –æ—Ç–∫–ª—é—á–µ–Ω—ã (–¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å psutil)\n"
          ]
        }
      ],
      "source": [
        "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ (–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)\n",
        "task = Task('binary')\n",
        "\n",
        "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LightAutoML\n",
        "# –û—Ç–∫–ª—é—á–∞–µ–º advanced_roles, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å psutil/joblib\n",
        "automl = TabularAutoML(\n",
        "    task=task,\n",
        "    timeout=300,  # 5 –º–∏–Ω—É—Ç –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ\n",
        "    cpu_limit=4,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —è–¥–µ—Ä CPU\n",
        "    reader_params={\n",
        "        'n_jobs': 1,  # –£–º–µ–Ω—å—à–∞–µ–º –¥–æ 1, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π\n",
        "        'cv': 5,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
        "        'random_state': 42,\n",
        "        'advanced_roles': False,  # –û—Ç–∫–ª—é—á–∞–µ–º advanced roles –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å psutil\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"LightAutoML –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!\")\n",
        "print(f\"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
        "print(f\"  - –ó–∞–¥–∞—á–∞: {task.name}\")\n",
        "print(f\"  - Timeout: 300 —Å–µ–∫—É–Ω–¥\")\n",
        "print(f\"  - CPU limit: 4\")\n",
        "print(f\"  - CV folds: 5\")\n",
        "print(f\"  - Advanced roles: –æ—Ç–∫–ª—é—á–µ–Ω—ã (–¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å psutil)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "\n",
        "–û–±—É—á–∏–º –º–æ–¥–µ–ª—å –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ. LightAutoML –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏...\n",
            "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...\n",
            "[00:28:17] Stdout logging level is INFO.\n",
            "[00:28:17] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
            "[00:28:17] Task: binary\n",
            "\n",
            "[00:28:17] Start automl preset with listed constraints:\n",
            "[00:28:17] - time: 300.00 seconds\n",
            "[00:28:17] - CPU: 4 cores\n",
            "[00:28:17] - memory: 16 GB\n",
            "\n",
            "[00:28:17] \u001b[1mTrain data shape: (800, 21)\u001b[0m\n",
            "\n",
            "[00:28:17] Layer \u001b[1m1\u001b[0m train process start. Time left 299.99 secs\n",
            "[00:28:17] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
            "[00:28:29] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7968229166666666\u001b[0m\n",
            "[00:28:29] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
            "[00:28:29] Time left 287.64 secs\n",
            "\n",
            "[00:28:29] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
            "[00:28:29] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
            "[00:28:30] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.6512127976190476\u001b[0m\n",
            "[00:28:30] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
            "[00:28:30] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 61.69 secs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Optimization Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [00:09<00:00, 11.08it/s, best_trial=24, best_value=0.778]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:28:39] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
            "[00:28:39] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:28:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.6627529761904762\u001b[0m\n",
            "[00:28:39] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
            "[00:28:39] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
            "[00:28:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6469419642857143\u001b[0m\n",
            "[00:28:40] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
            "[00:28:40] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 206.17 secs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Optimization Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [00:17<00:00,  5.71it/s, best_trial=89, best_value=0.76]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:28:58] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
            "[00:28:58] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:28:58] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.6258296130952381\u001b[0m\n",
            "[00:28:58] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
            "[00:28:58] Time left 258.40 secs\n",
            "\n",
            "[00:28:58] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n",
            "[00:28:58] Blending: optimization starts with equal weights. Score = \u001b[1m0.7655357\u001b[0m\n",
            "[00:28:59] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8083780\u001b[0m, weights = \u001b[1m[0.53486145 0.13614719 0.24635072 0.         0.08264064]\u001b[0m\n",
            "[00:28:59] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8100074\u001b[0m, weights = \u001b[1m[0.5583037  0.         0.3126858  0.         0.12901053]\u001b[0m\n",
            "[00:28:59] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8100298\u001b[0m, weights = \u001b[1m[0.557355   0.         0.31613183 0.         0.1265132 ]\u001b[0m\n",
            "[00:28:59] Blending: no improvements for score. Terminated.\n",
            "\n",
            "[00:28:59] Blending: best score = \u001b[1m0.8100298\u001b[0m, best weights = \u001b[1m[0.557355   0.         0.31613183 0.         0.1265132 ]\u001b[0m\n",
            "[00:28:59] \u001b[1mAutoml preset training completed in 41.81 seconds\u001b[0m\n",
            "\n",
            "[00:28:59] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.55735 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.31613 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
            "\t 0.12651 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
            "\n",
            "\n",
            "–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\n",
            "–§–æ—Ä–º–∞ OOF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: (800, 1)\n"
          ]
        }
      ],
      "source": [
        "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–æ–ª–µ–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "roles = {\n",
        "    'target': 'target',\n",
        "    'category': categorical_features  # –£–∫–∞–∑—ã–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "}\n",
        "\n",
        "print(\"–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏...\")\n",
        "print(\"–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...\")\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "oof_predictions = automl.fit_predict(\n",
        "    train_data,\n",
        "    roles=roles,\n",
        "    verbose=1  # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è\n",
        ")\n",
        "\n",
        "print(\"\\n–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\")\n",
        "print(f\"–§–æ—Ä–º–∞ OOF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {oof_predictions.data.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ (OOF)\n",
        "\n",
        "–û—Ü–µ–Ω–∏–º –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –Ω–∞ out-of-fold –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ (OOF):\n",
            "  ROC-AUC: 0.8100\n",
            "  Accuracy: 0.7375\n",
            "\n",
            "–û—Ç—á–µ—Ç –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bad       0.67      0.25      0.36       240\n",
            "        good       0.75      0.95      0.83       560\n",
            "\n",
            "    accuracy                           0.74       800\n",
            "   macro avg       0.71      0.60      0.60       800\n",
            "weighted avg       0.72      0.74      0.69       800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# –ü–æ–ª—É—á–µ–Ω–∏–µ OOF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
        "oof_pred_proba = oof_predictions.data[:, 0]  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
        "\n",
        "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –º–µ—Ç–∫–∏ –≤ —á–∏—Å–ª–æ–≤—ã–µ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫\n",
        "# LightAutoML –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ—Ç–∫—É —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∫–∞–∫ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å\n",
        "unique_labels = sorted(train_data['target'].unique())\n",
        "label_to_num = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "train_target_num = train_data['target'].map(label_to_num)\n",
        "\n",
        "# –î–ª—è roc_auc_score –Ω—É–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –∫–∞–∫–æ–π –∫–ª–∞—Å—Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π\n",
        "# –û–±—ã—á–Ω–æ —ç—Ç–æ –∫–ª–∞—Å—Å —Å –∏–Ω–¥–µ–∫—Å–æ–º 1 (–≤—Ç–æ—Ä–æ–π –∫–ª–∞—Å—Å)\n",
        "# –ï—Å–ª–∏ –º–µ—Ç–∫–∏ 'good' –∏ 'bad', —Ç–æ 'bad' –æ–±—ã—á–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å\n",
        "if 'bad' in unique_labels:\n",
        "    # 'bad' - –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å (–∏–Ω–¥–µ–∫—Å 1)\n",
        "    positive_class_idx = unique_labels.index('bad')\n",
        "else:\n",
        "    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–ª–∞—Å—Å –∫–∞–∫ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π\n",
        "    positive_class_idx = len(unique_labels) - 1\n",
        "\n",
        "# –ï—Å–ª–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –∏–º–µ–µ—Ç –∏–Ω–¥–µ–∫—Å 0, –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏\n",
        "if positive_class_idx == 0:\n",
        "    oof_pred_proba = 1 - oof_pred_proba\n",
        "\n",
        "train_pred = (oof_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n",
        "train_auc = roc_auc_score(train_target_num, oof_pred_proba)\n",
        "train_accuracy = accuracy_score(train_target_num, train_pred)\n",
        "\n",
        "print(\"–ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ (OOF):\")\n",
        "print(f\"  ROC-AUC: {train_auc:.4f}\")\n",
        "print(f\"  Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"\\n–û—Ç—á–µ—Ç –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\")\n",
        "print(classification_report(train_target_num, train_pred, target_names=unique_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ\n",
        "\n",
        "–°–¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –∏ –æ—Ü–µ–Ω–∏–º –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:\n",
            "  ROC-AUC: 0.7544\n",
            "  Accuracy: 0.6950\n",
            "\n",
            "–û—Ç—á–µ—Ç –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bad       0.48      0.17      0.25        60\n",
            "        good       0.72      0.92      0.81       140\n",
            "\n",
            "    accuracy                           0.69       200\n",
            "   macro avg       0.60      0.54      0.53       200\n",
            "weighted avg       0.65      0.69      0.64       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ\n",
        "test_predictions = automl.predict(test_data)\n",
        "\n",
        "# –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π\n",
        "test_pred_proba = test_predictions.data[:, 0]  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
        "\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –º–∞–ø–ø–∏–Ω–≥ –º–µ—Ç–æ–∫, —á—Ç–æ –∏ –¥–ª—è train\n",
        "test_target_num = test_data['target'].map(label_to_num)\n",
        "\n",
        "# –ï—Å–ª–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –∏–º–µ–µ—Ç –∏–Ω–¥–µ–∫—Å 0, –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏\n",
        "if positive_class_idx == 0:\n",
        "    test_pred_proba = 1 - test_pred_proba\n",
        "\n",
        "test_pred = (test_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n",
        "test_auc = roc_auc_score(test_target_num, test_pred_proba)\n",
        "test_accuracy = accuracy_score(test_target_num, test_pred)\n",
        "\n",
        "print(\"–ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:\")\n",
        "print(f\"  ROC-AUC: {test_auc:.4f}\")\n",
        "print(f\"  Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"\\n–û—Ç—á–µ—Ç –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\")\n",
        "print(classification_report(test_target_num, test_pred, target_names=unique_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "\n",
        "–°—Ä–∞–≤–Ω–∏–º –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –∏ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∞—Ö.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\n",
            " –ú–µ—Ç—Ä–∏–∫–∞  Train (OOF)     Test\n",
            " ROC-AUC      0.81003 0.754405\n",
            "Accuracy      0.73750 0.695000\n",
            "\n",
            "–†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É train –∏ test:\n",
            "  ROC-AUC: 0.0556\n",
            "  Accuracy: 0.0425\n"
          ]
        }
      ],
      "source": [
        "# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
        "results = pd.DataFrame({\n",
        "    '–ú–µ—Ç—Ä–∏–∫–∞': ['ROC-AUC', 'Accuracy'],\n",
        "    'Train (OOF)': [train_auc, train_accuracy],\n",
        "    'Test': [test_auc, test_accuracy]\n",
        "})\n",
        "\n",
        "print(\"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\")\n",
        "print(results.to_string(index=False))\n",
        "print(f\"\\n–†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É train –∏ test:\")\n",
        "print(f\"  ROC-AUC: {abs(train_auc - test_auc):.4f}\")\n",
        "print(f\"  Accuracy: {abs(train_accuracy - test_accuracy):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏\n",
        "\n",
        "–ü–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª LightAutoML –∏ –¥—Ä—É–≥—É—é –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ LightAutoML:\n",
            "  –¢–∏–ø –∑–∞–¥–∞—á–∏: binary\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'TabularAutoML' object has no attribute 'timeout'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ LightAutoML:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  –¢–∏–ø –∑–∞–¥–∞—á–∏: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mautoml\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Timeout: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m —Å–µ–∫—É–Ω–¥\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  CPU limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mautoml\u001b[38;5;241m.\u001b[39mcpu_limit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –º–æ–¥–µ–ª–∏\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'TabularAutoML' object has no attribute 'timeout'"
          ]
        }
      ],
      "source": [
        "# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏\n",
        "print(\"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ LightAutoML:\")\n",
        "print(f\"  –¢–∏–ø –∑–∞–¥–∞—á–∏: {automl.task.name}\")\n",
        "\n",
        "# –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –º–æ–¥–µ–ª–∏\n",
        "try:\n",
        "    if hasattr(automl, 'timer'):\n",
        "        print(f\"  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {automl.timer.time_spent:.2f} —Å–µ–∫—É–Ω–¥\")\n",
        "    if hasattr(automl, 'cpu_limit'):\n",
        "        print(f\"  CPU limit: {automl.cpu_limit}\")\n",
        "    if hasattr(automl, 'model'):\n",
        "        print(f\"\\n  –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞ —á–µ—Ä–µ–∑ automl.model\")\n",
        "        print(f\"  –¢–∏–ø –º–æ–¥–µ–ª–∏: {type(automl.model)}\")\n",
        "except Exception as e:\n",
        "    print(f\"  –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
        "\n",
        "–≠—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –±–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ LightAutoML:\n",
        "- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ OpenML\n",
        "- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "- –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–¥–±–æ—Ä–æ–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤\n",
        "- –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –∏ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∞—Ö\n",
        "\n",
        "LightAutoML –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:\n",
        "- –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "- –í—ã–ø–æ–ª–Ω—è–µ—Ç feature engineering\n",
        "- –ü–æ–¥–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
        "- –°—Ç—Ä–æ–∏—Ç –∞–Ω—Å–∞–º–±–ª–∏ –º–æ–¥–µ–ª–µ–π\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
