{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ab17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-11-14 18:52:11,284] Trial 0 failed with parameters: {'max_iter': 8277, 'fit_intercept': True, 'C': 1.8590843630169627, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.9636627605010293} because of the following error: ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\src\\automl\\model\\utils\\optuna_utils.py\", line 127, in <lambda>\n",
      "    lambda trial: objective(trial, X, y, **kwargs),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\src\\automl\\model\\sklearn\\base.py\", line 177, in optuna_objective\n",
      "    _, score, _ = self.fit_fold(\n",
      "                  ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\src\\automl\\model\\sklearn\\base.py\", line 132, in fit_fold\n",
      "    fold_model = fold_model.fit(X_train, y_train)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1247, in fit\n",
      "    X, y = validate_data(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1105, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "[W 2025-11-14 18:52:11,288] Trial 0 failed with value None.\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from automl import AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423e209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e81a7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "task = openml.tasks.get_task(31)\n",
    "class_labels = task.class_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b38dfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bad', 'good']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ec44de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Начало загрузки данных из OpenML...\n",
      "[INFO] Загрузка задачи из OpenML (task_id=168868)...\n",
      "[INFO] Задача загружена: 168868\n",
      "[INFO] Загрузка датасета...\n",
      "[INFO] Датасет загружен: APSFailure\n",
      "[INFO] Получение параметров задачи...\n",
      "[INFO] Количество фолдов: 10\n",
      "[INFO] Классы: ['neg', 'pos']\n",
      "[INFO] Загрузка данных...\n",
      "[INFO] Данные загружены. Размер X: (76000, 170), размер y: (76000,)\n",
      "[INFO] Создание маппинга меток...\n",
      "[INFO] Уникальные классы в y: [0 1]\n",
      "[INFO] Распределение классов: {0: 74625, 1: 1375}\n",
      "[INFO] Данные успешно загружены и подготовлены\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from automl import AutoML\n",
    "\n",
    "\n",
    "# Инициализация переменных\n",
    "task_id = 168868\n",
    "\n",
    "task = None\n",
    "dataset = None\n",
    "X = None\n",
    "y = None\n",
    "categorical = None\n",
    "feature_names = None\n",
    "n_folds = 3\n",
    "class_labels = None\n",
    "label_mapping = None\n",
    "data_loaded = False\n",
    "\n",
    "print(\"[INFO] Начало загрузки данных из OpenML...\")\n",
    "\n",
    "try:\n",
    "    print(f\"[INFO] Загрузка задачи из OpenML (task_id={task_id})...\")\n",
    "    task = openml.tasks.get_task(task_id)\n",
    "    print(f\"[INFO] Задача загружена: {task.task_id}\")\n",
    "    \n",
    "    print(\"[INFO] Загрузка датасета...\")\n",
    "    dataset = task.get_dataset()\n",
    "    print(f\"[INFO] Датасет загружен: {dataset.name}\")\n",
    "    \n",
    "    print(\"[INFO] Получение параметров задачи...\")\n",
    "    params = task.estimation_parameters\n",
    "    n_folds = int(params.get(\"number_folds\", 3))\n",
    "    print(f\"[INFO] Количество фолдов: {n_folds}\")\n",
    "    \n",
    "    class_labels = task.class_labels\n",
    "    print(f\"[INFO] Классы: {class_labels}\")\n",
    "    \n",
    "    print(\"[INFO] Загрузка данных...\")\n",
    "    X, y, categorical, feature_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "    print(f\"[INFO] Данные загружены. Размер X: {X.shape}, размер y: {y.shape}\")\n",
    "    \n",
    "    # Проверки данных\n",
    "    if X is None:\n",
    "        print(\"[ERROR] X равен None. Пропуск дальнейшей обработки.\")\n",
    "    elif isinstance(X, pd.DataFrame) and X.empty:\n",
    "        print(\"[ERROR] X пустой DataFrame. Пропуск дальнейшей обработки.\")\n",
    "    elif isinstance(X, np.ndarray) and X.size == 0:\n",
    "        print(\"[ERROR] X пустой ndarray. Пропуск дальнейшей обработки.\")\n",
    "    elif len(X) == 0:\n",
    "        print(\"[ERROR] X имеет нулевую длину. Пропуск дальнейшей обработки.\")\n",
    "    elif y is None:\n",
    "        print(\"[ERROR] y равен None. Пропуск дальнейшей обработки.\")\n",
    "    elif isinstance(y, pd.Series) and y.empty:\n",
    "        print(\"[ERROR] y пустой Series. Пропуск дальнейшей обработки.\")\n",
    "    elif isinstance(y, (pd.Series, np.ndarray)) and len(y) == 0:\n",
    "        print(\"[ERROR] y имеет нулевую длину. Пропуск дальнейшей обработки.\")\n",
    "    elif len(X) != len(y):\n",
    "        print(f\"[ERROR] Несоответствие размеров: X={len(X)}, y={len(y)}. Пропуск дальнейшей обработки.\")\n",
    "    else:\n",
    "        print(\"[INFO] Создание маппинга меток...\")\n",
    "        label_mapping = {v: k for k, v in enumerate(class_labels)}\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = np.array(y.map(label_mapping), dtype=int)\n",
    "        else:\n",
    "            # Если y уже массив или другой тип, преобразуем через pandas для совместимости\n",
    "            y_series = pd.Series(y)\n",
    "            y = np.array(y_series.map(label_mapping), dtype=int)\n",
    "        \n",
    "        # Проверка после преобразования\n",
    "        if len(y) == 0:\n",
    "            print(\"[ERROR] y пустой после преобразования. Пропуск дальнейшей обработки.\")\n",
    "        elif len(np.unique(y)) < 2:\n",
    "            print(f\"[ERROR] Недостаточно классов в y: {np.unique(y)}. Пропуск дальнейшей обработки.\")\n",
    "        else:\n",
    "            print(f\"[INFO] Уникальные классы в y: {np.unique(y)}\")\n",
    "            print(f\"[INFO] Распределение классов: {pd.Series(y).value_counts().to_dict()}\")\n",
    "            \n",
    "            data_loaded = True\n",
    "            print(\"[INFO] Данные успешно загружены и подготовлены\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Ошибка при загрузке данных: {type(e).__name__}: {e}\")\n",
    "    data_loaded = False\n",
    "    print(\"[WARNING] Пайплайн остановлен из-за ошибки загрузки данных\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7baa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Инициализация AutoML...\n",
      "[INFO] Параметры: task=classification, n_splits=10, n_jobs=3\n",
      "[2025-11-14 18:52:54,050] - [  PREPROC   ] - Успешно заданы шаги pipeline\n",
      "[INFO] AutoML инициализирован\n",
      "[INFO] Начало обучения модели...\n",
      "[2025-11-14 18:52:54,074] - [  PREPROC   ] - NaN features to drop: ['ab_000', 'ad_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'cf_000', 'cg_000', 'ch_000', 'co_000', 'cr_000', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000']\n",
      "[2025-11-14 18:52:54,144] - [Pipeline] .. (step 1 of 6) Processing nan_cols_dropper, total=   0.1\n",
      "[2025-11-14 18:52:55,756] - [Pipeline] ....... (step 2 of 6) Processing nan_imputer, total=   1.6\n",
      "[2025-11-14 18:52:56,163] - [  PREPROC   ] - QConstant features to drop: ['ae_000', 'af_000', 'ag_000', 'ag_001', 'ak_000', 'ar_000', 'as_000', 'au_000', 'ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_009', 'az_009', 'cd_000', 'cn_000', 'cs_009', 'df_000', 'dg_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dz_000', 'ea_000', 'ef_000', 'eg_000']\n",
      "[2025-11-14 18:52:56,233] - [Pipeline] .... (step 3 of 6) Processing qconst_dropper, total=   0.5\n",
      "[2025-11-14 18:52:56,642] - [  PREPROC   ] - Corr features to drop: ['bt_000', 'ee_000', 'ba_000', 'ck_000', 'ci_000', 'cc_000', 'dn_000', 'by_000', 'bx_000', 'bv_000', 'aq_000', 'ap_000', 'ao_000', 'an_000', 'ah_000', 'bu_000', 'bj_000', 'bi_000', 'bh_000', 'bg_000', 'bb_000', 'ag_007', 'cn_004', 'cs_005', 'ee_003', 'ee_002', 'ee_001', 'ag_006', 'ba_006', 'ba_005', 'ba_004', 'cn_002', 'ag_005', 'ag_004', 'ba_003', 'ba_002', 'ba_001', 'ag_003', 'ag_002', 'ca_000', 'ec_00', 'dv_000', 'ds_000', 'do_000', 'al_000', 'bt_000', 'ee_000', 'ba_000', 'ck_000', 'ci_000', 'cc_000', 'dn_000', 'by_000', 'bx_000', 'bv_000', 'aq_000', 'ap_000', 'ao_000', 'an_000', 'ah_000', 'bu_000', 'bj_000', 'bi_000', 'bh_000', 'bg_000', 'bb_000', 'ag_007', 'cn_004', 'cs_005', 'ee_003', 'ee_002', 'ee_001', 'ag_006', 'ba_006', 'ba_005', 'ba_004', 'cn_002', 'ag_005', 'ag_004', 'ba_003', 'ba_002', 'ba_001', 'ag_003', 'ag_002', 'ca_000', 'ec_00', 'dv_000', 'ds_000', 'do_000', 'al_000']\n",
      "[2025-11-14 18:52:56,665] - [Pipeline] . (step 4 of 6) Processing corr_cols_dropper, total=   0.4\n",
      "[2025-11-14 18:52:57,061] - [Pipeline] .... (step 5 of 6) Processing outlier_capper, total=   0.4\n",
      "[2025-11-14 18:52:57,201] - [Pipeline] ... (step 6 of 6) Processing feature_encoder, total=   0.1\n",
      "[2025-11-14 18:52:57,842] - [   MODEL    ] - 1 out of 8. type\n",
      "[2025-11-14 18:52:57,843] - [   START    ] - Working with type\n",
      "[2025-11-14 18:52:57,844] - [   START    ] - Tuning type\n",
      "[2025-11-14 18:54:06,904] - [   OPTUNA   ] - Trial 0. New best score 0.9811996933116622 with parameters {'max_iter': 8277, 'fit_intercept': True, 'C': 1.8590843630169627, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.9636627605010293}\n",
      "[2025-11-14 18:54:06,905] - [   OPTUNA   ] - 1 trials completed\n",
      "[2025-11-14 18:54:06,906] - [BEST PARAMS ] - {'random_state': 0, 'n_jobs': 12, 'verbose': 0, 'max_iter': 8277, 'fit_intercept': True, 'C': 1.8590843630169627, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.9636627605010293, 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'type', 'eval_metric': 'custom_metric'}\n",
      "[2025-11-14 18:54:06,907] - [    END     ] - Tuning type\n",
      "[2025-11-14 18:54:06,909] - [   START    ] - Fitting type\n",
      "[2025-11-14 18:55:15,937] - [    END     ] - Fitting type\n",
      "[2025-11-14 18:55:16,059] - [   SCORE    ] - Train: 0.9834865186538755\n",
      "[2025-11-14 18:55:16,080] - [   SCORE    ] - OOF: 0.9812100015227654\n",
      "[2025-11-14 18:55:16,082] - [    END     ] - Working with type\n",
      "[2025-11-14 18:55:16,083] - [  NEW BEST  ] - type. Best score: 0.9812100015227654 \n",
      "\n",
      "[2025-11-14 18:55:16,084] - [   MODEL    ] - 2 out of 8. ABCMeta\n",
      "[2025-11-14 18:55:16,084] - [   START    ] - Working with ABCMeta\n",
      "[2025-11-14 18:55:16,085] - [   START    ] - Tuning ABCMeta\n",
      "[2025-11-14 19:24:04,221] - [   OPTUNA   ] - Trial 0. New best score 0.9532952650018467 with parameters {'n_estimators': 553, 'max_depth': 12, 'min_samples_split': 0.12055267521432877, 'min_samples_leaf': 0.10897663659937938, 'max_features': 0.4812893194050143, 'bootstrap': True, 'max_samples': 0.9458865003910399, 'oob_score': True, 'criterion': 'gini', 'class_weight': 'balanced_subsample'}\n",
      "[2025-11-14 19:24:04,222] - [   OPTUNA   ] - 1 trials completed\n",
      "[2025-11-14 19:24:04,223] - [BEST PARAMS ] - {'random_state': 0, 'n_jobs': 12, 'verbose': 0, 'n_estimators': 553, 'max_depth': 12, 'min_samples_split': 0.12055267521432877, 'min_samples_leaf': 0.10897663659937938, 'max_features': 0.4812893194050143, 'bootstrap': True, 'max_samples': 0.9458865003910399, 'oob_score': True, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'ABCMeta', 'eval_metric': 'custom_metric'}\n",
      "[2025-11-14 19:24:04,224] - [    END     ] - Tuning ABCMeta\n",
      "[2025-11-14 19:24:04,226] - [   START    ] - Fitting ABCMeta\n",
      "[2025-11-14 19:27:08,190] - [    END     ] - Fitting ABCMeta\n",
      "[2025-11-14 19:27:09,749] - [   SCORE    ] - Train: 0.9544937438708695\n",
      "[2025-11-14 19:27:09,768] - [   SCORE    ] - OOF: 0.9527023432313081\n",
      "[2025-11-14 19:27:09,771] - [    END     ] - Working with ABCMeta\n",
      "[2025-11-14 19:27:09,772] - [BEST  MODEL ] - type. Best score: 0.9812100015227654 \n",
      "\n",
      "[2025-11-14 19:27:09,772] - [   MODEL    ] - 3 out of 8. ABCMeta\n",
      "[2025-11-14 19:27:09,773] - [   START    ] - Working with ABCMeta\n",
      "[2025-11-14 19:27:09,773] - [   START    ] - Tuning ABCMeta\n",
      "[2025-11-14 19:30:20,139] - [   OPTUNA   ] - Trial 0. New best score 0.9190894632423829 with parameters {'n_estimators': 553, 'max_depth': 12, 'min_samples_split': 0.12055267521432877, 'min_samples_leaf': 0.10897663659937938, 'max_features': 0.4812893194050143, 'bootstrap': True, 'max_samples': 0.9458865003910399, 'oob_score': True, 'criterion': 'gini', 'class_weight': 'balanced_subsample'}\n",
      "[2025-11-14 19:30:20,140] - [   OPTUNA   ] - 1 trials completed\n",
      "[2025-11-14 19:30:20,141] - [BEST PARAMS ] - {'random_state': 0, 'n_jobs': 12, 'verbose': 0, 'n_estimators': 553, 'max_depth': 12, 'min_samples_split': 0.12055267521432877, 'min_samples_leaf': 0.10897663659937938, 'max_features': 0.4812893194050143, 'bootstrap': True, 'max_samples': 0.9458865003910399, 'oob_score': True, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'ABCMeta', 'eval_metric': 'custom_metric'}\n",
      "[2025-11-14 19:30:20,142] - [    END     ] - Tuning ABCMeta\n",
      "[2025-11-14 19:30:20,144] - [   START    ] - Fitting ABCMeta\n",
      "[2025-11-14 19:31:35,835] - [    END     ] - Fitting ABCMeta\n",
      "[2025-11-14 19:31:37,312] - [   SCORE    ] - Train: 0.9194535294655093\n",
      "[2025-11-14 19:31:37,333] - [   SCORE    ] - OOF: 0.9191046773260241\n",
      "[2025-11-14 19:31:37,336] - [    END     ] - Working with ABCMeta\n",
      "[2025-11-14 19:31:37,337] - [BEST  MODEL ] - type. Best score: 0.9812100015227654 \n",
      "\n",
      "[2025-11-14 19:31:37,337] - [   MODEL    ] - 4 out of 8. CatBoostClassification\n",
      "[2025-11-14 19:31:37,338] - [   START    ] - Working with CatBoostClassification\n",
      "[2025-11-14 19:31:37,338] - [   START    ] - Tuning CatBoostClassification\n",
      "[2025-11-14 19:38:36,643] - [   OPTUNA   ] - Trial 0. New best score 0.01811704929087457 with parameters {'boosting_type': 'Plain', 'depth': 9, 'l2_leaf_reg': 143.0378732744839, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Depthwise', 'min_data_in_leaf': 229, 'rsm': 0.9781976563006176, 'subsample': 0.6300649112954666, 'model_size_reg': 158.3450076165329, 'auto_class_weights': None, 'iterations': 1872}\n",
      "[2025-11-14 19:38:36,644] - [   OPTUNA   ] - 1 trials completed\n",
      "[2025-11-14 19:38:36,645] - [BEST PARAMS ] - {'iterations': 1872, 'thread_count': 12, 'logging_level': 'Silent', 'task_type': 'CPU', 'od_type': 'Iter', 'od_wait': 100, 'random_state': 0, 'od_pval': None, 'cat_features': [], 'boosting_type': 'Plain', 'depth': 9, 'l2_leaf_reg': 143.0378732744839, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Depthwise', 'min_data_in_leaf': 229, 'rsm': 0.9781976563006176, 'subsample': 0.6300649112954666, 'model_size_reg': 158.3450076165329, 'auto_class_weights': None, 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'CatBoostClassification', 'eval_metric': None}\n",
      "[2025-11-14 19:38:36,646] - [    END     ] - Tuning CatBoostClassification\n",
      "[2025-11-14 19:38:36,646] - [   START    ] - Fitting CatBoostClassification\n",
      "[2025-11-14 19:45:12,673] - [    END     ] - Fitting CatBoostClassification\n",
      "[2025-11-14 19:45:14,490] - [   SCORE    ] - Train: 0.994890369422872\n",
      "[2025-11-14 19:45:14,512] - [   SCORE    ] - OOF: 0.9909529855337293\n",
      "[2025-11-14 19:45:14,515] - [    END     ] - Working with CatBoostClassification\n",
      "[2025-11-14 19:45:14,515] - [  NEW BEST  ] - CatBoostClassification. Best score: 0.9909529855337293 \n",
      "\n",
      "[2025-11-14 19:45:14,516] - [   MODEL    ] - 5 out of 8. XGBClassification\n",
      "[2025-11-14 19:45:14,517] - [   START    ] - Working with XGBClassification\n",
      "[2025-11-14 19:45:14,517] - [   START    ] - Tuning XGBClassification\n",
      "[2025-11-14 19:45:30,671] - [   OPTUNA   ] - Trial 0. New best score 0.03084684567921876 with parameters {'max_depth': 9, 'grow_policy': 'depthwise', 'max_leaves': 284, 'gamma': 8.473095986778095, 'subsample': 0.6813047017599905, 'colsample_bytree': 0.49382849013642327, 'colsample_bylevel': 0.9025957007038717, 'reg_lambda': 9.636627605010293, 'reg_alpha': 3.8344151882577773, 'min_child_weight': 16, 'class_weight': 'balanced', 'num_boost_round': 534}\n",
      "[2025-11-14 19:45:30,673] - [   OPTUNA   ] - 1 trials completed\n",
      "[2025-11-14 19:45:30,673] - [BEST PARAMS ] - {'nthread': 12, 'device': 'cpu', 'objective': 'binary:logistic', 'seed': 0, 'verbosity': 0, 'num_boost_round': 534, 'early_stopping_rounds': 100, 'class_weight': 'balanced', 'scale_pos_weight': 54.29506871463217, 'max_depth': 9, 'grow_policy': 'depthwise', 'max_leaves': 284, 'gamma': 8.473095986778095, 'subsample': 0.6813047017599905, 'colsample_bytree': 0.49382849013642327, 'colsample_bylevel': 0.9025957007038717, 'reg_lambda': 9.636627605010293, 'reg_alpha': 3.8344151882577773, 'min_child_weight': 16, 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'XGBClassification', 'eval_metric': None}\n",
      "[2025-11-14 19:45:30,674] - [    END     ] - Tuning XGBClassification\n",
      "[2025-11-14 19:45:30,675] - [   START    ] - Fitting XGBClassification\n",
      "[2025-11-14 19:45:45,919] - [    END     ] - Fitting XGBClassification\n",
      "[2025-11-14 19:45:46,299] - [   SCORE    ] - Train: 0.9997584626161108\n",
      "[2025-11-14 19:45:46,318] - [   SCORE    ] - OOF: 0.9910652462311557\n",
      "[2025-11-14 19:45:46,331] - [    END     ] - Working with XGBClassification\n",
      "[2025-11-14 19:45:46,331] - [  NEW BEST  ] - XGBClassification. Best score: 0.9910652462311557 \n",
      "\n",
      "[2025-11-14 19:45:46,332] - [   MODEL    ] - 6 out of 8. LightGBMClassification\n",
      "[2025-11-14 19:45:46,333] - [   START    ] - Working with LightGBMClassification\n",
      "[2025-11-14 19:45:46,334] - [   START    ] - Tuning LightGBMClassification\n",
      "[2025-11-14 19:45:50,195] - [   OPTUNA   ] - Trial 0. New best score 0.03000099964568319 with parameters {'max_depth': 9, 'num_leaves': 369, 'min_data_in_leaf': 155, 'bagging_fraction': 0.7724415914984484, 'bagging_freq': 10, 'feature_fraction': 0.7875364678399936, 'lambda_l1': 4.375872112626925, 'lambda_l2': 8.917730007820797, 'min_gain_to_split': 19.273255210020587, 'is_unbalance': 'false', 'num_iterations': 38}\n",
      "[2025-11-14 19:46:01,126] - [   OPTUNA   ] - 3 trials completed\n",
      "[2025-11-14 19:46:01,127] - [BEST PARAMS ] - {'num_iterations': 38, 'num_threads': 12, 'seed': 0, 'verbosity': -1, 'device_type': 'cpu', 'early_stopping_round': 100, 'early_stopping_min_delta': 0.0001, 'objective': 'binary', 'metric': '', 'max_depth': 9, 'num_leaves': 369, 'min_data_in_leaf': 155, 'bagging_fraction': 0.7724415914984484, 'bagging_freq': 10, 'feature_fraction': 0.7875364678399936, 'lambda_l1': 4.375872112626925, 'lambda_l2': 8.917730007820797, 'min_gain_to_split': 19.273255210020587, 'is_unbalance': 'false', 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'LightGBMClassification', 'eval_metric': None}\n",
      "[2025-11-14 19:46:01,127] - [    END     ] - Tuning LightGBMClassification\n",
      "[2025-11-14 19:46:01,128] - [   START    ] - Fitting LightGBMClassification\n",
      "[2025-11-14 19:46:04,658] - [    END     ] - Fitting LightGBMClassification\n",
      "[2025-11-14 19:46:04,776] - [   SCORE    ] - Train: 0.9882473701842545\n",
      "[2025-11-14 19:46:04,803] - [   SCORE    ] - OOF: 0.986607710065479\n",
      "[2025-11-14 19:46:04,806] - [    END     ] - Working with LightGBMClassification\n",
      "[2025-11-14 19:46:04,807] - [BEST  MODEL ] - XGBClassification. Best score: 0.9910652462311557 \n",
      "\n",
      "[2025-11-14 19:46:04,807] - [   MODEL    ] - 7 out of 8. Stacker\n",
      "[2025-11-14 19:46:04,854] - [   START    ] - Working with Stacker\n",
      "[2025-11-14 19:46:04,854] - [   START    ] - Tuning Stacker\n",
      "[2025-11-14 19:46:06,667] - [   OPTUNA   ] - Trial 0. New best score 0.019013979976721475 with parameters {'max_depth': 9, 'num_leaves': 369, 'min_data_in_leaf': 155, 'bagging_fraction': 0.7724415914984484, 'bagging_freq': 10, 'feature_fraction': 0.7875364678399936, 'lambda_l1': 4.375872112626925, 'lambda_l2': 8.917730007820797, 'min_gain_to_split': 19.273255210020587, 'is_unbalance': 'false', 'num_iterations': 39}\n",
      "[2025-11-14 19:46:15,136] - [   OPTUNA   ] - 5 trials completed\n",
      "[2025-11-14 19:46:15,137] - [BEST PARAMS ] - {'num_iterations': 39, 'num_threads': 12, 'seed': 0, 'verbosity': -1, 'device_type': 'cpu', 'early_stopping_round': 100, 'early_stopping_min_delta': 0.0001, 'objective': 'binary', 'metric': '', 'max_depth': 9, 'num_leaves': 369, 'min_data_in_leaf': 155, 'bagging_fraction': 0.7724415914984484, 'bagging_freq': 10, 'feature_fraction': 0.7875364678399936, 'lambda_l1': 4.375872112626925, 'lambda_l2': 8.917730007820797, 'min_gain_to_split': 19.273255210020587, 'is_unbalance': 'false', 'time_series': False, 'model_type': 'classification', 'n_splits': 5, 'name': 'Stacker', 'eval_metric': None}\n",
      "[2025-11-14 19:46:15,138] - [    END     ] - Tuning Stacker\n",
      "[2025-11-14 19:46:15,139] - [   START    ] - Fitting Stacker\n",
      "[2025-11-14 19:46:16,783] - [    END     ] - Fitting Stacker\n",
      "[2025-11-14 19:46:17,033] - [   SCORE    ] - Train: 0.9931507622963303\n",
      "[2025-11-14 19:46:17,057] - [   SCORE    ] - OOF: 0.9919588828993452\n",
      "[2025-11-14 19:46:17,061] - [    END     ] - Working with Stacker\n",
      "[2025-11-14 19:46:17,062] - [  NEW BEST  ] - Stacker. Best score: 0.9919588828993452 \n",
      "\n",
      "[2025-11-14 19:46:17,062] - [   MODEL    ] - 8 out of 8. Blender\n",
      "[2025-11-14 19:46:17,067] - [   START    ] - Working with Blender\n",
      "[2025-11-14 19:46:17,068] - [   START    ] - Tuning Blender\n",
      "[2025-11-14 19:46:17,400] - [   OPTUNA   ] - Best score 0.9923252042028323 with weights [0.0, 0.0, 0.0, 0.7639320225002103, 0.2360679774997897, 0.0]\n",
      "[2025-11-14 19:46:17,708] - [   OPTUNA   ] - Best score 0.9923252042028323 with weights [0.0, 0.0, 0.0, 0.7639320225002103, 0.2360679774997897, 0.0]\n",
      "[2025-11-14 19:46:17,709] - [BEST PARAMS ] - {'weights': [0.0, 0.0, 0.0, 0.7639320225002103, 0.2360679774997897, 0.0], 'n': 6, 'random_state': 42, 'n_iters': 10, 'n_inner_iters': 3}\n",
      "[2025-11-14 19:46:17,710] - [    END     ] - Tuning Blender\n",
      "[2025-11-14 19:46:17,731] - [   SCORE    ] - Train: 0.9923252042028323\n",
      "[2025-11-14 19:46:17,750] - [   SCORE    ] - OOF: 0.9923252042028323\n",
      "[2025-11-14 19:46:17,752] - [    END     ] - Working with Blender\n",
      "[2025-11-14 19:46:17,753] - [  NEW BEST  ] - Blender. Best score: 0.9923252042028323 \n",
      "\n",
      "[INFO] Модель успешно обучена\n",
      "[INFO] Лучший OOF score: 0.9923252042028323\n"
     ]
    }
   ],
   "source": [
    "automl = None\n",
    "model_trained = False\n",
    "\n",
    "if not data_loaded:\n",
    "    print(\"[ERROR] Данные не загружены. Пропуск обучения модели.\")\n",
    "else:\n",
    "    try:\n",
    "        # Проверки перед обучением\n",
    "        if X is None or y is None:\n",
    "            print(\"[ERROR] X или y не определены. Пропуск обучения модели.\")\n",
    "        elif not isinstance(X, (pd.DataFrame, np.ndarray)):\n",
    "            print(f\"[ERROR] X должен быть DataFrame или ndarray, получен {type(X)}. Пропуск обучения модели.\")\n",
    "        elif not isinstance(y, np.ndarray):\n",
    "            print(f\"[ERROR] y должен быть ndarray, получен {type(y)}. Пропуск обучения модели.\")\n",
    "        else:\n",
    "            print(\"[INFO] Инициализация AutoML...\")\n",
    "            print(f\"[INFO] Параметры: task=classification, n_splits={n_folds}, n_jobs=3\")\n",
    "            \n",
    "            automl = AutoML(\n",
    "                task='classification',\n",
    "                use_preprocessing_pipeline=True,\n",
    "                feature_selector_type=None,\n",
    "                use_val_test_pipeline=False,\n",
    "                auto_models_init_kwargs = {\n",
    "                    \"metric\": \"roc_auc\",\n",
    "                    \"time_series\": False,\n",
    "                    \"models_list\": [\"linear\", \"forests\", \"boostings\"],\n",
    "                    \"blend\": True,\n",
    "                    \"stack\": True,\n",
    "                    \"n_splits\": n_folds,\n",
    "                },\n",
    "                n_jobs=12, \n",
    "                random_state=0,\n",
    "            )\n",
    "            print(\"[INFO] AutoML инициализирован\")\n",
    "            \n",
    "            print(\"[INFO] Начало обучения модели...\")\n",
    "            automl = automl.fit(\n",
    "                X, y, \n",
    "                auto_model_fit_kwargs = {\n",
    "                    \"tuning_timeout\": 10\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Проверка результата обучения\n",
    "            if automl is None:\n",
    "                print(\"[ERROR] AutoML вернул None после обучения. Пропуск дальнейшей обработки.\")\n",
    "            elif not hasattr(automl, 'auto_model'):\n",
    "                print(\"[ERROR] AutoML не имеет атрибута auto_model. Пропуск дальнейшей обработки.\")\n",
    "            else:\n",
    "                model_trained = True\n",
    "                print(\"[INFO] Модель успешно обучена\")\n",
    "                \n",
    "                if hasattr(automl.auto_model, 'best_score'):\n",
    "                    print(f\"[INFO] Лучший OOF score: {automl.auto_model.best_score}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Ошибка при обучении модели: {type(e).__name__}: {e}\")\n",
    "        import traceback\n",
    "        print(f\"[ERROR] Трассировка: {traceback.format_exc()}\")\n",
    "        model_trained = False\n",
    "        print(\"[WARNING] Модель не обучена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e921160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено строк: {len(df)}\n",
      "[2025-11-15 01:12:31,988] - [   MODEL    ] - 1 out of 8. type\n",
      "[2025-11-15 01:12:31,989] - [   START    ] - Working with type\n",
      "[2025-11-15 01:12:31,990] - [   START    ] - Tuning type\n",
      "[2025-11-15 01:12:38,251] - [   OPTUNA   ] - Trial 0. New best score 0.6021904761904763 with parameters {'max_iter': 8277, 'fit_intercept': True, 'C': 1.8590843630169627, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.9636627605010293}\n",
      "[2025-11-15 01:12:42,758] - [   OPTUNA   ] - Trial 1. New best score 0.6021904761904763 with parameters {'max_iter': 5813, 'fit_intercept': True, 'C': 2.5601615250028704, 'solver': 'saga', 'penalty': None}\n",
      "[2025-11-15 01:12:42,759] - [   OPTUNA   ] - 2 trials completed\n",
      "[2025-11-15 01:12:42,760] - [BEST PARAMS ] - {'random_state': 0, 'n_jobs': 3, 'verbose': 0, 'max_iter': 8277, 'fit_intercept': True, 'C': 1.8590843630169627, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.9636627605010293, 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'type', 'eval_metric': 'custom_metric'}\n",
      "[2025-11-15 01:12:42,760] - [    END     ] - Tuning type\n",
      "[2025-11-15 01:12:42,761] - [   START    ] - Fitting type\n",
      "[2025-11-15 01:12:49,127] - [    END     ] - Fitting type\n",
      "[2025-11-15 01:12:49,141] - [   SCORE    ] - Train: 0.6027476190476191\n",
      "[2025-11-15 01:12:49,143] - [   SCORE    ] - OOF: 0.598252380952381\n",
      "[2025-11-15 01:12:49,146] - [    END     ] - Working with type\n",
      "[2025-11-15 01:12:49,146] - [  NEW BEST  ] - type. Best score: 0.598252380952381 \n",
      "\n",
      "[2025-11-15 01:12:49,147] - [   MODEL    ] - 2 out of 8. ABCMeta\n",
      "[2025-11-15 01:12:49,147] - [   START    ] - Working with ABCMeta\n",
      "[2025-11-15 01:12:49,148] - [   START    ] - Tuning ABCMeta\n",
      "[2025-11-15 01:12:56,742] - [   OPTUNA   ] - Trial 0. New best score 0.7625238095238095 with parameters {'n_estimators': 553, 'max_depth': 12, 'min_samples_split': 0.12055267521432877, 'min_samples_leaf': 0.10897663659937938, 'max_features': 0.4812893194050143, 'bootstrap': True, 'max_samples': 0.9458865003910399, 'oob_score': True, 'criterion': 'gini', 'class_weight': 'balanced_subsample'}\n",
      "[2025-11-15 01:13:00,178] - [   OPTUNA   ] - Trial 2. New best score 0.7678571428571428 with parameters {'n_estimators': 272, 'max_depth': 12, 'min_samples_split': 0.09123006644330972, 'min_samples_leaf': 0.1136867897737297, 'max_features': 0.11691082039271963, 'bootstrap': True, 'max_samples': 0.8084669984373785, 'oob_score': True, 'criterion': 'entropy', 'class_weight': 'balanced'}\n",
      "[2025-11-15 01:13:00,180] - [   OPTUNA   ] - 3 trials completed\n",
      "[2025-11-15 01:13:00,180] - [BEST PARAMS ] - {'random_state': 0, 'n_jobs': 3, 'verbose': 0, 'n_estimators': 272, 'max_depth': 12, 'min_samples_split': 0.09123006644330972, 'min_samples_leaf': 0.1136867897737297, 'max_features': 0.11691082039271963, 'bootstrap': True, 'max_samples': 0.8084669984373785, 'oob_score': True, 'criterion': 'entropy', 'class_weight': 'balanced', 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'ABCMeta', 'eval_metric': 'custom_metric'}\n",
      "[2025-11-15 01:13:00,180] - [    END     ] - Tuning ABCMeta\n",
      "[2025-11-15 01:13:00,181] - [   START    ] - Fitting ABCMeta\n",
      "[2025-11-15 01:13:03,512] - [    END     ] - Fitting ABCMeta\n",
      "[2025-11-15 01:13:03,880] - [   SCORE    ] - Train: 0.7901714285714285\n",
      "[2025-11-15 01:13:03,882] - [   SCORE    ] - OOF: 0.7669047619047619\n",
      "[2025-11-15 01:13:03,884] - [    END     ] - Working with ABCMeta\n",
      "[2025-11-15 01:13:03,884] - [  NEW BEST  ] - ABCMeta. Best score: 0.7669047619047619 \n",
      "\n",
      "[2025-11-15 01:13:03,884] - [   MODEL    ] - 3 out of 8. ABCMeta\n",
      "[2025-11-15 01:13:03,885] - [   START    ] - Working with ABCMeta\n",
      "[2025-11-15 01:13:03,885] - [   START    ] - Tuning ABCMeta\n",
      "[2025-11-15 01:13:11,349] - [   OPTUNA   ] - Trial 0. New best score 0.7689999999999999 with parameters {'n_estimators': 553, 'max_depth': 12, 'min_samples_split': 0.12055267521432877, 'min_samples_leaf': 0.10897663659937938, 'max_features': 0.4812893194050143, 'bootstrap': True, 'max_samples': 0.9458865003910399, 'oob_score': True, 'criterion': 'gini', 'class_weight': 'balanced_subsample'}\n",
      "[2025-11-15 01:13:14,621] - [   OPTUNA   ] - 3 trials completed\n",
      "[2025-11-15 01:13:14,621] - [BEST PARAMS ] - {'random_state': 0, 'n_jobs': 3, 'verbose': 0, 'n_estimators': 553, 'max_depth': 12, 'min_samples_split': 0.12055267521432877, 'min_samples_leaf': 0.10897663659937938, 'max_features': 0.4812893194050143, 'bootstrap': True, 'max_samples': 0.9458865003910399, 'oob_score': True, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'ABCMeta', 'eval_metric': 'custom_metric'}\n",
      "[2025-11-15 01:13:14,622] - [    END     ] - Tuning ABCMeta\n",
      "[2025-11-15 01:13:14,622] - [   START    ] - Fitting ABCMeta\n",
      "[2025-11-15 01:13:23,964] - [    END     ] - Fitting ABCMeta\n",
      "[2025-11-15 01:13:24,570] - [   SCORE    ] - Train: 0.7853809523809525\n",
      "[2025-11-15 01:13:24,572] - [   SCORE    ] - OOF: 0.7628333333333334\n",
      "[2025-11-15 01:13:24,573] - [    END     ] - Working with ABCMeta\n",
      "[2025-11-15 01:13:24,574] - [BEST  MODEL ] - ABCMeta. Best score: 0.7669047619047619 \n",
      "\n",
      "[2025-11-15 01:13:24,574] - [   MODEL    ] - 4 out of 8. CatBoostClassification\n",
      "[2025-11-15 01:13:24,574] - [   START    ] - Working with CatBoostClassification\n",
      "[2025-11-15 01:13:24,575] - [   START    ] - Tuning CatBoostClassification\n",
      "[2025-11-15 01:16:27,507] - [   OPTUNA   ] - Trial 0. New best score 0.5639452442278577 with parameters {'boosting_type': 'Plain', 'depth': 9, 'l2_leaf_reg': 143.0378732744839, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Depthwise', 'min_data_in_leaf': 229, 'rsm': 0.9781976563006176, 'subsample': 0.6300649112954666, 'model_size_reg': 158.3450076165329, 'auto_class_weights': None, 'iterations': 442}\n",
      "[2025-11-15 01:16:27,509] - [   OPTUNA   ] - 1 trials completed\n",
      "[2025-11-15 01:16:27,509] - [BEST PARAMS ] - {'iterations': 442, 'thread_count': 3, 'logging_level': 'Silent', 'task_type': 'CPU', 'od_type': 'Iter', 'od_wait': 100, 'random_state': 0, 'od_pval': None, 'cat_features': ['personal_status', 'property_magnitude', 'purpose', 'savings_status', 'employment', 'own_telephone', 'checking_status', 'other_parties', 'housing', 'credit_history', 'other_payment_plans', 'job', 'foreign_worker'], 'boosting_type': 'Plain', 'depth': 9, 'l2_leaf_reg': 143.0378732744839, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Depthwise', 'min_data_in_leaf': 229, 'rsm': 0.9781976563006176, 'subsample': 0.6300649112954666, 'model_size_reg': 158.3450076165329, 'auto_class_weights': None, 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'CatBoostClassification', 'eval_metric': None}\n",
      "[2025-11-15 01:16:27,510] - [    END     ] - Tuning CatBoostClassification\n",
      "[2025-11-15 01:16:27,511] - [   START    ] - Fitting CatBoostClassification\n",
      "[2025-11-15 01:18:43,322] - [    END     ] - Fitting CatBoostClassification\n",
      "[2025-11-15 01:18:43,407] - [   SCORE    ] - Train: 0.7536428571428572\n",
      "[2025-11-15 01:18:43,409] - [   SCORE    ] - OOF: 0.6865285714285714\n",
      "[2025-11-15 01:18:43,412] - [    END     ] - Working with CatBoostClassification\n",
      "[2025-11-15 01:18:43,412] - [BEST  MODEL ] - ABCMeta. Best score: 0.7669047619047619 \n",
      "\n",
      "[2025-11-15 01:18:43,413] - [   MODEL    ] - 5 out of 8. XGBClassification\n",
      "[2025-11-15 01:18:43,413] - [   START    ] - Working with XGBClassification\n",
      "[2025-11-15 01:18:43,414] - [   START    ] - Tuning XGBClassification\n",
      "[2025-11-15 01:18:44,438] - [   OPTUNA   ] - Trial 0. New best score 0.5597762547656894 with parameters {'max_depth': 9, 'grow_policy': 'depthwise', 'max_leaves': 284, 'gamma': 8.473095986778095, 'subsample': 0.6813047017599905, 'colsample_bytree': 0.49382849013642327, 'colsample_bylevel': 0.9025957007038717, 'reg_lambda': 9.636627605010293, 'reg_alpha': 3.8344151882577773, 'min_child_weight': 16, 'class_weight': 'balanced', 'num_boost_round': 166}\n",
      "[2025-11-15 01:18:46,136] - [   OPTUNA   ] - Trial 2. New best score 0.5469156310781836 with parameters {'max_depth': 3, 'grow_policy': 'depthwise', 'max_leaves': 218, 'gamma': 5.29111224209254, 'subsample': 0.796810320490795, 'colsample_bytree': 0.5105352989948937, 'colsample_bylevel': 0.6115905539817836, 'reg_lambda': 0.18789800436355142, 'reg_alpha': 6.176354970758771, 'min_child_weight': 12, 'class_weight': 'balanced', 'num_boost_round': 132}\n",
      "[2025-11-15 01:18:47,093] - [   OPTUNA   ] - Trial 3. New best score 0.5113548259059899 with parameters {'max_depth': 11, 'grow_policy': 'lossguide', 'max_leaves': 360, 'gamma': 1.2045094325853967, 'subsample': 0.7000900439011009, 'colsample_bytree': 0.7035740826563435, 'colsample_bylevel': 0.2893443049664568, 'reg_lambda': 1.289262976548533, 'reg_alpha': 3.1542835092418384, 'min_child_weight': 7, 'class_weight': None, 'num_boost_round': 141}\n",
      "[2025-11-15 01:18:53,888] - [   OPTUNA   ] - 12 trials completed\n",
      "[2025-11-15 01:18:53,890] - [BEST PARAMS ] - {'nthread': 3, 'device': 'cpu', 'objective': 'binary:logistic', 'seed': 0, 'verbosity': 0, 'num_boost_round': 141, 'early_stopping_rounds': 100, 'class_weight': None, 'scale_pos_weight': 2.3333333333333335, 'max_depth': 11, 'grow_policy': 'lossguide', 'max_leaves': 360, 'gamma': 1.2045094325853967, 'subsample': 0.7000900439011009, 'colsample_bytree': 0.7035740826563435, 'colsample_bylevel': 0.2893443049664568, 'reg_lambda': 1.289262976548533, 'reg_alpha': 3.1542835092418384, 'min_child_weight': 7, 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'XGBClassification', 'eval_metric': None}\n",
      "[2025-11-15 01:18:53,891] - [    END     ] - Tuning XGBClassification\n",
      "[2025-11-15 01:18:53,891] - [   START    ] - Fitting XGBClassification\n",
      "[2025-11-15 01:18:54,876] - [    END     ] - Fitting XGBClassification\n",
      "[2025-11-15 01:18:54,901] - [   SCORE    ] - Train: 0.9236428571428571\n",
      "[2025-11-15 01:18:54,905] - [   SCORE    ] - OOF: 0.7869761904761906\n",
      "[2025-11-15 01:18:54,910] - [    END     ] - Working with XGBClassification\n",
      "[2025-11-15 01:18:54,911] - [  NEW BEST  ] - XGBClassification. Best score: 0.7869761904761906 \n",
      "\n",
      "[2025-11-15 01:18:54,912] - [   MODEL    ] - 6 out of 8. LightGBMClassification\n",
      "[2025-11-15 01:18:54,913] - [   START    ] - Working with LightGBMClassification\n",
      "[2025-11-15 01:18:54,914] - [   START    ] - Tuning LightGBMClassification\n",
      "[2025-11-15 01:18:55,101] - [   OPTUNA   ] - Trial 0. New best score 0.5712048372988828 with parameters {'max_depth': 9, 'num_leaves': 369, 'min_data_in_leaf': 155, 'bagging_fraction': 0.7724415914984484, 'bagging_freq': 10, 'feature_fraction': 0.7875364678399936, 'lambda_l1': 4.375872112626925, 'lambda_l2': 8.917730007820797, 'min_gain_to_split': 19.273255210020587, 'is_unbalance': 'false', 'num_iterations': 8}\n",
      "[2025-11-15 01:18:55,455] - [   OPTUNA   ] - Trial 2. New best score 0.5623445350484669 with parameters {'max_depth': 8, 'num_leaves': 402, 'min_data_in_leaf': 31, 'bagging_fraction': 0.819960510663762, 'bagging_freq': 0, 'feature_fraction': 0.9668013502297503, 'lambda_l1': 5.218483217500717, 'lambda_l2': 4.146619399905235, 'min_gain_to_split': 5.29111224209254, 'is_unbalance': 'true', 'num_iterations': 10}\n",
      "[2025-11-15 01:18:56,141] - [   OPTUNA   ] - Trial 5. New best score 0.5155735381468469 with parameters {'max_depth': 3, 'num_leaves': 338, 'min_data_in_leaf': 65, 'bagging_fraction': 0.7331553864281531, 'bagging_freq': 5, 'feature_fraction': 0.49538175018731184, 'lambda_l1': 1.1037514116430513, 'lambda_l2': 6.563295894652734, 'min_gain_to_split': 2.763659026972276, 'is_unbalance': 'false', 'num_iterations': 50}\n",
      "[2025-11-15 01:18:57,535] - [   OPTUNA   ] - Trial 10. New best score 0.4995032113185916 with parameters {'max_depth': 5, 'num_leaves': 182, 'min_data_in_leaf': 111, 'bagging_fraction': 0.964820177513915, 'bagging_freq': 5, 'feature_fraction': 0.5232207629150817, 'lambda_l1': 0.4781419499751117, 'lambda_l2': 9.560593113504746, 'min_gain_to_split': 0.26097890128892764, 'is_unbalance': 'false', 'num_iterations': 122}\n",
      "[2025-11-15 01:18:59,530] - [   OPTUNA   ] - Trial 16. New best score 0.49853211216085924 with parameters {'max_depth': 4, 'num_leaves': 130, 'min_data_in_leaf': 159, 'bagging_fraction': 0.9245587440876063, 'bagging_freq': 5, 'feature_fraction': 0.4819342320923877, 'lambda_l1': 1.8314779255534668, 'lambda_l2': 0.10032607509862501, 'min_gain_to_split': 0.012823406954340894, 'is_unbalance': 'false', 'num_iterations': 228}\n",
      "[2025-11-15 01:19:00,966] - [   OPTUNA   ] - Trial 21. New best score 0.4981984093702347 with parameters {'max_depth': 7, 'num_leaves': 215, 'min_data_in_leaf': 116, 'bagging_fraction': 0.9712881263760241, 'bagging_freq': 5, 'feature_fraction': 0.5669434486826914, 'lambda_l1': 0.6551539929436725, 'lambda_l2': 8.527565307949835, 'min_gain_to_split': 0.08867624582380937, 'is_unbalance': 'false', 'num_iterations': 147}\n",
      "[2025-11-15 01:19:02,968] - [   OPTUNA   ] - Trial 27. New best score 0.4976034427222176 with parameters {'max_depth': 3, 'num_leaves': 202, 'min_data_in_leaf': 130, 'bagging_fraction': 0.8442124066948405, 'bagging_freq': 0, 'feature_fraction': 0.5799972715237883, 'lambda_l1': 0.6105131563732318, 'lambda_l2': 9.203656336302673, 'min_gain_to_split': 0.01718060905452389, 'is_unbalance': 'false', 'num_iterations': 187}\n",
      "[2025-11-15 01:19:05,385] - [   OPTUNA   ] - 36 trials completed\n",
      "[2025-11-15 01:19:05,385] - [BEST PARAMS ] - {'num_iterations': 187, 'num_threads': 3, 'seed': 0, 'verbosity': -1, 'device_type': 'cpu', 'early_stopping_round': 100, 'early_stopping_min_delta': 0.0001, 'objective': 'binary', 'metric': '', 'max_depth': 3, 'num_leaves': 202, 'min_data_in_leaf': 130, 'bagging_fraction': 0.8442124066948405, 'bagging_freq': 0, 'feature_fraction': 0.5799972715237883, 'lambda_l1': 0.6105131563732318, 'lambda_l2': 9.203656336302673, 'min_gain_to_split': 0.01718060905452389, 'is_unbalance': 'false', 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'LightGBMClassification', 'eval_metric': None}\n",
      "[2025-11-15 01:19:05,385] - [    END     ] - Tuning LightGBMClassification\n",
      "[2025-11-15 01:19:05,386] - [   START    ] - Fitting LightGBMClassification\n",
      "[2025-11-15 01:19:05,856] - [    END     ] - Fitting LightGBMClassification\n",
      "[2025-11-15 01:19:05,922] - [   SCORE    ] - Train: 0.8480142857142856\n",
      "[2025-11-15 01:19:05,926] - [   SCORE    ] - OOF: 0.7818\n",
      "[2025-11-15 01:19:05,930] - [    END     ] - Working with LightGBMClassification\n",
      "[2025-11-15 01:19:05,932] - [BEST  MODEL ] - XGBClassification. Best score: 0.7869761904761906 \n",
      "\n",
      "[2025-11-15 01:19:05,933] - [   MODEL    ] - 7 out of 8. Stacker\n",
      "[2025-11-15 01:19:05,935] - [   START    ] - Working with Stacker\n",
      "[2025-11-15 01:19:05,936] - [   START    ] - Tuning Stacker\n",
      "[2025-11-15 01:19:06,087] - [   OPTUNA   ] - Trial 0. New best score 0.5338591107012596 with parameters {'max_depth': 9, 'num_leaves': 369, 'min_data_in_leaf': 155, 'bagging_fraction': 0.7724415914984484, 'bagging_freq': 10, 'feature_fraction': 0.7875364678399936, 'lambda_l1': 4.375872112626925, 'lambda_l2': 8.917730007820797, 'min_gain_to_split': 19.273255210020587, 'is_unbalance': 'false', 'num_iterations': 13}\n",
      "[2025-11-15 01:19:06,586] - [   OPTUNA   ] - Trial 5. New best score 0.49377805820333454 with parameters {'max_depth': 3, 'num_leaves': 338, 'min_data_in_leaf': 65, 'bagging_fraction': 0.7331553864281531, 'bagging_freq': 5, 'feature_fraction': 0.49538175018731184, 'lambda_l1': 1.1037514116430513, 'lambda_l2': 6.563295894652734, 'min_gain_to_split': 2.763659026972276, 'is_unbalance': 'false', 'num_iterations': 40}\n",
      "[2025-11-15 01:19:07,490] - [   OPTUNA   ] - Trial 12. New best score 0.4904010638140625 with parameters {'max_depth': 4, 'num_leaves': 218, 'min_data_in_leaf': 4, 'bagging_fraction': 0.7004993573546182, 'bagging_freq': 5, 'feature_fraction': 0.5174749517288866, 'lambda_l1': 0.08129804646619973, 'lambda_l2': 8.156486139454296, 'min_gain_to_split': 0.2137808497530701, 'is_unbalance': 'false', 'num_iterations': 38}\n",
      "[2025-11-15 01:19:15,988] - [   OPTUNA   ] - 74 trials completed\n",
      "[2025-11-15 01:19:15,988] - [BEST PARAMS ] - {'num_iterations': 38, 'num_threads': 3, 'seed': 0, 'verbosity': -1, 'device_type': 'cpu', 'early_stopping_round': 100, 'early_stopping_min_delta': 0.0001, 'objective': 'binary', 'metric': '', 'max_depth': 4, 'num_leaves': 218, 'min_data_in_leaf': 4, 'bagging_fraction': 0.7004993573546182, 'bagging_freq': 5, 'feature_fraction': 0.5174749517288866, 'lambda_l1': 0.08129804646619973, 'lambda_l2': 8.156486139454296, 'min_gain_to_split': 0.2137808497530701, 'is_unbalance': 'false', 'time_series': False, 'model_type': 'classification', 'n_splits': 5, 'name': 'Stacker', 'eval_metric': None}\n",
      "[2025-11-15 01:19:15,989] - [    END     ] - Tuning Stacker\n",
      "[2025-11-15 01:19:15,989] - [   START    ] - Fitting Stacker\n",
      "[2025-11-15 01:19:16,203] - [    END     ] - Fitting Stacker\n",
      "[2025-11-15 01:19:16,235] - [   SCORE    ] - Train: 0.8694952380952381\n",
      "[2025-11-15 01:19:16,239] - [   SCORE    ] - OOF: 0.7877666666666667\n",
      "[2025-11-15 01:19:16,244] - [    END     ] - Working with Stacker\n",
      "[2025-11-15 01:19:16,246] - [  NEW BEST  ] - Stacker. Best score: 0.7877666666666667 \n",
      "\n",
      "[2025-11-15 01:19:16,247] - [   MODEL    ] - 8 out of 8. Blender\n",
      "[2025-11-15 01:19:16,248] - [   START    ] - Working with Blender\n",
      "[2025-11-15 01:19:16,249] - [   START    ] - Tuning Blender\n",
      "[2025-11-15 01:19:16,300] - [   OPTUNA   ] - Best score 0.7958714285714286 with weights [0.0, 0.11446603088872445, 0.1291951885790642, 0.14847590630854748, 0.3474293869603747, 0.2604334872632892]\n",
      "[2025-11-15 01:19:16,346] - [   OPTUNA   ] - Best score 0.7959285714285714 with weights [0.0, 0.17109169803015084, 0.11853112173255022, 0.15515925271023392, 0.31914995002727536, 0.2360679774997897]\n",
      "[2025-11-15 01:19:16,377] - [   OPTUNA   ] - Best score 0.7959285714285714 with weights [0.0, 0.17109169803015084, 0.11853112173255022, 0.15515925271023392, 0.31914995002727536, 0.2360679774997897]\n",
      "[2025-11-15 01:19:16,378] - [BEST PARAMS ] - {'weights': [0.0, 0.17109169803015084, 0.11853112173255022, 0.15515925271023392, 0.31914995002727536, 0.2360679774997897], 'n': 6, 'random_state': 42, 'n_iters': 10, 'n_inner_iters': 3}\n",
      "[2025-11-15 01:19:16,379] - [    END     ] - Tuning Blender\n",
      "[2025-11-15 01:19:16,382] - [   SCORE    ] - Train: 0.7959285714285714\n",
      "[2025-11-15 01:19:16,385] - [   SCORE    ] - OOF: 0.7959285714285714\n",
      "[2025-11-15 01:19:16,388] - [    END     ] - Working with Blender\n",
      "[2025-11-15 01:19:16,389] - [  NEW BEST  ] - Blender. Best score: 0.7959285714285714 \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 21 features, but RandomForestClassifier is expecting 20 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     50\u001b[39m automl = automl.fit(\n\u001b[32m     51\u001b[39m     X,\n\u001b[32m     52\u001b[39m     y,\n\u001b[32m     53\u001b[39m     auto_model_fit_kwargs={\u001b[33m\"\u001b[39m\u001b[33mtuning_timeout\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m10\u001b[39m}\n\u001b[32m     54\u001b[39m )\n\u001b[32m     56\u001b[39m score = automl.auto_model.best_score\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m preds = \u001b[43mautoml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m test_predictions = preds[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\ITMO_bootcamp\\src\\automl\\main.py:258\u001b[39m, in \u001b[36mAutoML.predict\u001b[39m\u001b[34m(self, X_test)\u001b[39m\n\u001b[32m    255\u001b[39m     X_test = \u001b[38;5;28mself\u001b[39m.feature_selector.transform(X_test)\n\u001b[32m    257\u001b[39m \u001b[38;5;66;03m# inference the AutoModel\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\ITMO_bootcamp\\src\\automl\\model\\main.py:322\u001b[39m, in \u001b[36mAutoModel.predict\u001b[39m\u001b[34m(self, X, model_name)\u001b[39m\n\u001b[32m    320\u001b[39m non_zero_idx = np.where(\u001b[38;5;28mself\u001b[39m.blender.weights > \u001b[32m0\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m non_zero_idx:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     y_pred.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodels_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    324\u001b[39m \u001b[38;5;66;03m# inference blender\u001b[39;00m\n\u001b[32m    325\u001b[39m y_pred = \u001b[38;5;28mself\u001b[39m.blender.predict(y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\ITMO_bootcamp\\src\\automl\\model\\base.py:174\u001b[39m, in \u001b[36mBaseModel.predict\u001b[39m\u001b[34m(self, Xs)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;66;03m# If Xs is not a list or the model is a Blender, perform a single prediction\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xs, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name == \u001b[33m\"\u001b[39m\u001b[33mBlender\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;66;03m# several tests\u001b[39;00m\n\u001b[32m    177\u001b[39m ys_pred = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\ITMO_bootcamp\\src\\automl\\model\\sklearn\\base.py:215\u001b[39m, in \u001b[36mSKBase._predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    211\u001b[39m y_pred = np.zeros((X.shape[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.num_class)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_class \\\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m np.zeros((X.shape[\u001b[32m0\u001b[39m],))\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold_model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.models:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     y_pred += \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfold_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_predict_func_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type == \u001b[33m\"\u001b[39m\u001b[33mclassification\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_pred.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    218\u001b[39m     y_pred = np.vstack((\u001b[32m1\u001b[39m - y_pred, y_pred)).T\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User1\\Desktop\\ITMO_bootcamp\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:945\u001b[39m, in \u001b[36mForestClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    943\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[32m    948\u001b[39m n_jobs, _, _ = _partition_estimators(\u001b[38;5;28mself\u001b[39m.n_estimators, \u001b[38;5;28mself\u001b[39m.n_jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User1\\Desktop\\ITMO_bootcamp\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:637\u001b[39m, in \u001b[36mBaseForest._validate_X_predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    634\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    635\u001b[39m     ensure_all_finite = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X.indices.dtype != np.intc \u001b[38;5;129;01mor\u001b[39;00m X.indptr.dtype != np.intc):\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User1\\Desktop\\ITMO_bootcamp\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2975\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2975\u001b[39m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2977\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User1\\Desktop\\ITMO_bootcamp\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2839\u001b[39m, in \u001b[36m_check_n_features\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2836\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_features != estimator.n_features_in_:\n\u001b[32m-> \u001b[39m\u001b[32m2839\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2840\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2841\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.n_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features as input.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2842\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: X has 21 features, but RandomForestClassifier is expecting 20 features as input."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "from automl import AutoML\n",
    "\n",
    "\n",
    "CSV_PATH_TO_PREDICT = 'C:\\\\Users\\\\User1\\\\Desktop\\\\ITMO_bootcamp\\\\data\\\\datasets\\\\TEST\\\\test1__.csv'\n",
    "class_labels =  ['good', 'bad']\n",
    "# Загружаем данные\n",
    "csv_path = 'C:\\\\Users\\\\User1\\\\Desktop\\\\ITMO_bootcamp\\\\data\\\\datasets\\\\openml_31_credit-g.csv'\n",
    "df = pd.read_csv('C:\\\\Users\\\\User1\\\\Desktop\\\\ITMO_bootcamp\\\\data\\\\datasets\\\\openml_31_credit-g.csv')\n",
    "print(f\"Загружено строк: {{len(df)}}\")\n",
    "label = 'class'\n",
    "# Генерированный\n",
    "\n",
    "\n",
    "X = df.drop(columns=[label])\n",
    "y = df[label]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "label_mapping = {v: k for k, v in enumerate(class_labels)}\n",
    "\n",
    "if isinstance(y, pd.Series):\n",
    "    y = np.array(y.map(label_mapping), dtype=int)\n",
    "else:\n",
    "    y_series = pd.Series(y)\n",
    "    y = np.array(y_series.map(label_mapping), dtype=int)\n",
    "\n",
    "\n",
    "automl = AutoML(\n",
    "    task='classification',\n",
    "    use_preprocessing_pipeline=False,\n",
    "    feature_selector_type=None,\n",
    "    use_val_test_pipeline=False,\n",
    "    auto_models_init_kwargs={\n",
    "        \"metric\": \"roc_auc\",\n",
    "        \"time_series\": False,\n",
    "        \"models_list\": [\"linear\", \"forests\", \"boostings\"],\n",
    "        \"blend\": True,\n",
    "        \"stack\": True,\n",
    "        \"n_splits\": 10\n",
    "    },\n",
    "    n_jobs=3,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "automl = automl.fit(\n",
    "    X,\n",
    "    y,\n",
    "    auto_model_fit_kwargs={\"tuning_timeout\": 10}\n",
    ")\n",
    "\n",
    "score = automl.auto_model.best_score\n",
    "preds = automl.predict(df)\n",
    "test_predictions = preds[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7090f0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Получение предсказаний...\n",
      "[INFO] Получены предсказания. Размер: (76000, 2)\n",
      "[INFO] Используется вероятность второго класса\n",
      "[INFO] OOF score: 0.9923252042028323\n",
      "[INFO] Вычисление ROC-AUC на полных данных...\n",
      "[INFO] ROC-AUC на полных данных: 0.9998607632099894\n",
      "[INFO] Результаты: OOF=0.9923252042028323, Full=0.9998607632099894\n",
      "\n",
      "[RESULT] OOF score: 0.9923252042028323, Full data score: 0.9998607632099894\n"
     ]
    }
   ],
   "source": [
    "oof_score = None\n",
    "score = None\n",
    "predictions = None\n",
    "\n",
    "if not model_trained or automl is None:\n",
    "    print(\"[ERROR] Модель не обучена. Пропуск предсказаний и оценки.\")\n",
    "else:\n",
    "    try:\n",
    "        print(\"[INFO] Получение предсказаний...\")\n",
    "        \n",
    "        # Проверки перед предсказанием\n",
    "        if not hasattr(automl, 'predict'):\n",
    "            print(\"[ERROR] AutoML не имеет метода predict. Пропуск предсказаний.\")\n",
    "        elif X is None:\n",
    "            print(\"[ERROR] X не определен. Пропуск предсказаний.\")\n",
    "        else:\n",
    "            predictions = automl.predict(X)\n",
    "            \n",
    "            if predictions is None:\n",
    "                print(\"[ERROR] Предсказания равны None. Пропуск дальнейшей обработки.\")\n",
    "            elif len(predictions) == 0:\n",
    "                print(\"[ERROR] Предсказания пустые. Пропуск дальнейшей обработки.\")\n",
    "            else:\n",
    "                print(f\"[INFO] Получены предсказания. Размер: {predictions.shape}\")\n",
    "                \n",
    "                # Проверка формы предсказаний для бинарной классификации\n",
    "                if len(predictions.shape) == 2 and predictions.shape[1] >= 2:\n",
    "                    predictions_proba = predictions[:, 1]\n",
    "                    print(\"[INFO] Используется вероятность второго класса\")\n",
    "                elif len(predictions.shape) == 1:\n",
    "                    predictions_proba = predictions\n",
    "                    print(\"[INFO] Используются предсказания напрямую\")\n",
    "                else:\n",
    "                    print(f\"[ERROR] Неожиданная форма предсказаний: {predictions.shape}. Пропуск дальнейшей обработки.\")\n",
    "                    predictions_proba = None\n",
    "                \n",
    "                if predictions_proba is not None:\n",
    "                    # Получение OOF score\n",
    "                    if hasattr(automl.auto_model, 'best_score'):\n",
    "                        oof_score = automl.auto_model.best_score\n",
    "                        print(f\"[INFO] OOF score: {oof_score}\")\n",
    "                    else:\n",
    "                        print(\"[WARNING] best_score не найден в auto_model\")\n",
    "                    \n",
    "                    # Вычисление метрики на полных данных\n",
    "                    print(\"[INFO] Вычисление ROC-AUC на полных данных...\")\n",
    "                    if y is None:\n",
    "                        print(\"[ERROR] y не определен. Пропуск вычисления метрики.\")\n",
    "                    elif len(y) != len(predictions_proba):\n",
    "                        print(f\"[ERROR] Несоответствие размеров: y={len(y)}, predictions={len(predictions_proba)}. Пропуск вычисления метрики.\")\n",
    "                    else:\n",
    "                        try:\n",
    "                            score = roc_auc_score(y, predictions_proba)\n",
    "                            print(f\"[INFO] ROC-AUC на полных данных: {score}\")\n",
    "                            print(f\"[INFO] Результаты: OOF={oof_score}, Full={score}\")\n",
    "                        except Exception as metric_error:\n",
    "                            print(f\"[ERROR] Ошибка при вычислении ROC-AUC: {type(metric_error).__name__}: {metric_error}\")\n",
    "                            print(\"[WARNING] Метрика не вычислена\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Ошибка при получении предсказаний или оценке: {type(e).__name__}: {e}\")\n",
    "        import traceback\n",
    "        print(f\"[ERROR] Трассировка: {traceback.format_exc()}\")\n",
    "        print(\"[WARNING] Предсказания или оценка не выполнены\")\n",
    "\n",
    "# Вывод результатов\n",
    "if oof_score is not None and score is not None:\n",
    "    print(f\"\\n[RESULT] OOF score: {oof_score}, Full data score: {score}\")\n",
    "    (oof_score, score)\n",
    "else:\n",
    "    print(\"\\n[RESULT] Результаты недоступны\")\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69edf3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
