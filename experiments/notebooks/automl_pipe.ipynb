{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ab17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-11-14 18:52:11,284] Trial 0 failed with parameters: {'max_iter': 8277, 'fit_intercept': True, 'C': 1.8590843630169627, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.9636627605010293} because of the following error: ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\src\\automl\\model\\utils\\optuna_utils.py\", line 127, in <lambda>\n",
      "    lambda trial: objective(trial, X, y, **kwargs),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\src\\automl\\model\\sklearn\\base.py\", line 177, in optuna_objective\n",
      "    _, score, _ = self.fit_fold(\n",
      "                  ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\src\\automl\\model\\sklearn\\base.py\", line 132, in fit_fold\n",
      "    fold_model = fold_model.fit(X_train, y_train)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1247, in fit\n",
      "    X, y = validate_data(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1105, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"c:\\Users\\Aleksandr\\Documents\\python_apps\\MAS_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "[W 2025-11-14 18:52:11,288] Trial 0 failed with value None.\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from automl import AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ec44de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Начало загрузки данных из OpenML...\n",
      "[INFO] Загрузка задачи из OpenML (task_id=168868)...\n",
      "[INFO] Задача загружена: 168868\n",
      "[INFO] Загрузка датасета...\n",
      "[INFO] Датасет загружен: APSFailure\n",
      "[INFO] Получение параметров задачи...\n",
      "[INFO] Количество фолдов: 10\n",
      "[INFO] Классы: ['neg', 'pos']\n",
      "[INFO] Загрузка данных...\n",
      "[INFO] Данные загружены. Размер X: (76000, 170), размер y: (76000,)\n",
      "[INFO] Создание маппинга меток...\n",
      "[INFO] Уникальные классы в y: [0 1]\n",
      "[INFO] Распределение классов: {0: 74625, 1: 1375}\n",
      "[INFO] Данные успешно загружены и подготовлены\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from automl import AutoML\n",
    "\n",
    "\n",
    "# Инициализация переменных\n",
    "task_id = 168868\n",
    "\n",
    "task = None\n",
    "dataset = None\n",
    "X = None\n",
    "y = None\n",
    "categorical = None\n",
    "feature_names = None\n",
    "n_folds = 3\n",
    "class_labels = None\n",
    "label_mapping = None\n",
    "data_loaded = False\n",
    "\n",
    "print(\"[INFO] Начало загрузки данных из OpenML...\")\n",
    "\n",
    "try:\n",
    "    print(f\"[INFO] Загрузка задачи из OpenML (task_id={task_id})...\")\n",
    "    task = openml.tasks.get_task(task_id)\n",
    "    print(f\"[INFO] Задача загружена: {task.task_id}\")\n",
    "    \n",
    "    print(\"[INFO] Загрузка датасета...\")\n",
    "    dataset = task.get_dataset()\n",
    "    print(f\"[INFO] Датасет загружен: {dataset.name}\")\n",
    "    \n",
    "    print(\"[INFO] Получение параметров задачи...\")\n",
    "    params = task.estimation_parameters\n",
    "    n_folds = int(params.get(\"number_folds\", 3))\n",
    "    print(f\"[INFO] Количество фолдов: {n_folds}\")\n",
    "    \n",
    "    class_labels = task.class_labels\n",
    "    print(f\"[INFO] Классы: {class_labels}\")\n",
    "    \n",
    "    print(\"[INFO] Загрузка данных...\")\n",
    "    X, y, categorical, feature_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "    print(f\"[INFO] Данные загружены. Размер X: {X.shape}, размер y: {y.shape}\")\n",
    "    \n",
    "    # Проверки данных\n",
    "    if X is None:\n",
    "        print(\"[ERROR] X равен None. Пропуск дальнейшей обработки.\")\n",
    "    elif isinstance(X, pd.DataFrame) and X.empty:\n",
    "        print(\"[ERROR] X пустой DataFrame. Пропуск дальнейшей обработки.\")\n",
    "    elif isinstance(X, np.ndarray) and X.size == 0:\n",
    "        print(\"[ERROR] X пустой ndarray. Пропуск дальнейшей обработки.\")\n",
    "    elif len(X) == 0:\n",
    "        print(\"[ERROR] X имеет нулевую длину. Пропуск дальнейшей обработки.\")\n",
    "    elif y is None:\n",
    "        print(\"[ERROR] y равен None. Пропуск дальнейшей обработки.\")\n",
    "    elif isinstance(y, pd.Series) and y.empty:\n",
    "        print(\"[ERROR] y пустой Series. Пропуск дальнейшей обработки.\")\n",
    "    elif isinstance(y, (pd.Series, np.ndarray)) and len(y) == 0:\n",
    "        print(\"[ERROR] y имеет нулевую длину. Пропуск дальнейшей обработки.\")\n",
    "    elif len(X) != len(y):\n",
    "        print(f\"[ERROR] Несоответствие размеров: X={len(X)}, y={len(y)}. Пропуск дальнейшей обработки.\")\n",
    "    else:\n",
    "        print(\"[INFO] Создание маппинга меток...\")\n",
    "        label_mapping = {v: k for k, v in enumerate(class_labels)}\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = np.array(y.map(label_mapping), dtype=int)\n",
    "        else:\n",
    "            # Если y уже массив или другой тип, преобразуем через pandas для совместимости\n",
    "            y_series = pd.Series(y)\n",
    "            y = np.array(y_series.map(label_mapping), dtype=int)\n",
    "        \n",
    "        # Проверка после преобразования\n",
    "        if len(y) == 0:\n",
    "            print(\"[ERROR] y пустой после преобразования. Пропуск дальнейшей обработки.\")\n",
    "        elif len(np.unique(y)) < 2:\n",
    "            print(f\"[ERROR] Недостаточно классов в y: {np.unique(y)}. Пропуск дальнейшей обработки.\")\n",
    "        else:\n",
    "            print(f\"[INFO] Уникальные классы в y: {np.unique(y)}\")\n",
    "            print(f\"[INFO] Распределение классов: {pd.Series(y).value_counts().to_dict()}\")\n",
    "            \n",
    "            data_loaded = True\n",
    "            print(\"[INFO] Данные успешно загружены и подготовлены\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Ошибка при загрузке данных: {type(e).__name__}: {e}\")\n",
    "    data_loaded = False\n",
    "    print(\"[WARNING] Пайплайн остановлен из-за ошибки загрузки данных\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7baa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Инициализация AutoML...\n",
      "[INFO] Параметры: task=classification, n_splits=10, n_jobs=3\n",
      "[2025-11-14 18:52:54,050] - [  PREPROC   ] - Успешно заданы шаги pipeline\n",
      "[INFO] AutoML инициализирован\n",
      "[INFO] Начало обучения модели...\n",
      "[2025-11-14 18:52:54,074] - [  PREPROC   ] - NaN features to drop: ['ab_000', 'ad_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'cf_000', 'cg_000', 'ch_000', 'co_000', 'cr_000', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000']\n",
      "[2025-11-14 18:52:54,144] - [Pipeline] .. (step 1 of 6) Processing nan_cols_dropper, total=   0.1\n",
      "[2025-11-14 18:52:55,756] - [Pipeline] ....... (step 2 of 6) Processing nan_imputer, total=   1.6\n",
      "[2025-11-14 18:52:56,163] - [  PREPROC   ] - QConstant features to drop: ['ae_000', 'af_000', 'ag_000', 'ag_001', 'ak_000', 'ar_000', 'as_000', 'au_000', 'ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_009', 'az_009', 'cd_000', 'cn_000', 'cs_009', 'df_000', 'dg_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dz_000', 'ea_000', 'ef_000', 'eg_000']\n",
      "[2025-11-14 18:52:56,233] - [Pipeline] .... (step 3 of 6) Processing qconst_dropper, total=   0.5\n",
      "[2025-11-14 18:52:56,642] - [  PREPROC   ] - Corr features to drop: ['bt_000', 'ee_000', 'ba_000', 'ck_000', 'ci_000', 'cc_000', 'dn_000', 'by_000', 'bx_000', 'bv_000', 'aq_000', 'ap_000', 'ao_000', 'an_000', 'ah_000', 'bu_000', 'bj_000', 'bi_000', 'bh_000', 'bg_000', 'bb_000', 'ag_007', 'cn_004', 'cs_005', 'ee_003', 'ee_002', 'ee_001', 'ag_006', 'ba_006', 'ba_005', 'ba_004', 'cn_002', 'ag_005', 'ag_004', 'ba_003', 'ba_002', 'ba_001', 'ag_003', 'ag_002', 'ca_000', 'ec_00', 'dv_000', 'ds_000', 'do_000', 'al_000', 'bt_000', 'ee_000', 'ba_000', 'ck_000', 'ci_000', 'cc_000', 'dn_000', 'by_000', 'bx_000', 'bv_000', 'aq_000', 'ap_000', 'ao_000', 'an_000', 'ah_000', 'bu_000', 'bj_000', 'bi_000', 'bh_000', 'bg_000', 'bb_000', 'ag_007', 'cn_004', 'cs_005', 'ee_003', 'ee_002', 'ee_001', 'ag_006', 'ba_006', 'ba_005', 'ba_004', 'cn_002', 'ag_005', 'ag_004', 'ba_003', 'ba_002', 'ba_001', 'ag_003', 'ag_002', 'ca_000', 'ec_00', 'dv_000', 'ds_000', 'do_000', 'al_000']\n",
      "[2025-11-14 18:52:56,665] - [Pipeline] . (step 4 of 6) Processing corr_cols_dropper, total=   0.4\n",
      "[2025-11-14 18:52:57,061] - [Pipeline] .... (step 5 of 6) Processing outlier_capper, total=   0.4\n",
      "[2025-11-14 18:52:57,201] - [Pipeline] ... (step 6 of 6) Processing feature_encoder, total=   0.1\n",
      "[2025-11-14 18:52:57,842] - [   MODEL    ] - 1 out of 8. type\n",
      "[2025-11-14 18:52:57,843] - [   START    ] - Working with type\n",
      "[2025-11-14 18:52:57,844] - [   START    ] - Tuning type\n",
      "[2025-11-14 18:54:06,904] - [   OPTUNA   ] - Trial 0. New best score 0.9811996933116622 with parameters {'max_iter': 8277, 'fit_intercept': True, 'C': 1.8590843630169627, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.9636627605010293}\n",
      "[2025-11-14 18:54:06,905] - [   OPTUNA   ] - 1 trials completed\n",
      "[2025-11-14 18:54:06,906] - [BEST PARAMS ] - {'random_state': 0, 'n_jobs': 12, 'verbose': 0, 'max_iter': 8277, 'fit_intercept': True, 'C': 1.8590843630169627, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.9636627605010293, 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'type', 'eval_metric': 'custom_metric'}\n",
      "[2025-11-14 18:54:06,907] - [    END     ] - Tuning type\n",
      "[2025-11-14 18:54:06,909] - [   START    ] - Fitting type\n",
      "[2025-11-14 18:55:15,937] - [    END     ] - Fitting type\n",
      "[2025-11-14 18:55:16,059] - [   SCORE    ] - Train: 0.9834865186538755\n",
      "[2025-11-14 18:55:16,080] - [   SCORE    ] - OOF: 0.9812100015227654\n",
      "[2025-11-14 18:55:16,082] - [    END     ] - Working with type\n",
      "[2025-11-14 18:55:16,083] - [  NEW BEST  ] - type. Best score: 0.9812100015227654 \n",
      "\n",
      "[2025-11-14 18:55:16,084] - [   MODEL    ] - 2 out of 8. ABCMeta\n",
      "[2025-11-14 18:55:16,084] - [   START    ] - Working with ABCMeta\n",
      "[2025-11-14 18:55:16,085] - [   START    ] - Tuning ABCMeta\n",
      "[2025-11-14 19:24:04,221] - [   OPTUNA   ] - Trial 0. New best score 0.9532952650018467 with parameters {'n_estimators': 553, 'max_depth': 12, 'min_samples_split': 0.12055267521432877, 'min_samples_leaf': 0.10897663659937938, 'max_features': 0.4812893194050143, 'bootstrap': True, 'max_samples': 0.9458865003910399, 'oob_score': True, 'criterion': 'gini', 'class_weight': 'balanced_subsample'}\n",
      "[2025-11-14 19:24:04,222] - [   OPTUNA   ] - 1 trials completed\n",
      "[2025-11-14 19:24:04,223] - [BEST PARAMS ] - {'random_state': 0, 'n_jobs': 12, 'verbose': 0, 'n_estimators': 553, 'max_depth': 12, 'min_samples_split': 0.12055267521432877, 'min_samples_leaf': 0.10897663659937938, 'max_features': 0.4812893194050143, 'bootstrap': True, 'max_samples': 0.9458865003910399, 'oob_score': True, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'ABCMeta', 'eval_metric': 'custom_metric'}\n",
      "[2025-11-14 19:24:04,224] - [    END     ] - Tuning ABCMeta\n",
      "[2025-11-14 19:24:04,226] - [   START    ] - Fitting ABCMeta\n",
      "[2025-11-14 19:27:08,190] - [    END     ] - Fitting ABCMeta\n",
      "[2025-11-14 19:27:09,749] - [   SCORE    ] - Train: 0.9544937438708695\n",
      "[2025-11-14 19:27:09,768] - [   SCORE    ] - OOF: 0.9527023432313081\n",
      "[2025-11-14 19:27:09,771] - [    END     ] - Working with ABCMeta\n",
      "[2025-11-14 19:27:09,772] - [BEST  MODEL ] - type. Best score: 0.9812100015227654 \n",
      "\n",
      "[2025-11-14 19:27:09,772] - [   MODEL    ] - 3 out of 8. ABCMeta\n",
      "[2025-11-14 19:27:09,773] - [   START    ] - Working with ABCMeta\n",
      "[2025-11-14 19:27:09,773] - [   START    ] - Tuning ABCMeta\n",
      "[2025-11-14 19:30:20,139] - [   OPTUNA   ] - Trial 0. New best score 0.9190894632423829 with parameters {'n_estimators': 553, 'max_depth': 12, 'min_samples_split': 0.12055267521432877, 'min_samples_leaf': 0.10897663659937938, 'max_features': 0.4812893194050143, 'bootstrap': True, 'max_samples': 0.9458865003910399, 'oob_score': True, 'criterion': 'gini', 'class_weight': 'balanced_subsample'}\n",
      "[2025-11-14 19:30:20,140] - [   OPTUNA   ] - 1 trials completed\n",
      "[2025-11-14 19:30:20,141] - [BEST PARAMS ] - {'random_state': 0, 'n_jobs': 12, 'verbose': 0, 'n_estimators': 553, 'max_depth': 12, 'min_samples_split': 0.12055267521432877, 'min_samples_leaf': 0.10897663659937938, 'max_features': 0.4812893194050143, 'bootstrap': True, 'max_samples': 0.9458865003910399, 'oob_score': True, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'ABCMeta', 'eval_metric': 'custom_metric'}\n",
      "[2025-11-14 19:30:20,142] - [    END     ] - Tuning ABCMeta\n",
      "[2025-11-14 19:30:20,144] - [   START    ] - Fitting ABCMeta\n",
      "[2025-11-14 19:31:35,835] - [    END     ] - Fitting ABCMeta\n",
      "[2025-11-14 19:31:37,312] - [   SCORE    ] - Train: 0.9194535294655093\n",
      "[2025-11-14 19:31:37,333] - [   SCORE    ] - OOF: 0.9191046773260241\n",
      "[2025-11-14 19:31:37,336] - [    END     ] - Working with ABCMeta\n",
      "[2025-11-14 19:31:37,337] - [BEST  MODEL ] - type. Best score: 0.9812100015227654 \n",
      "\n",
      "[2025-11-14 19:31:37,337] - [   MODEL    ] - 4 out of 8. CatBoostClassification\n",
      "[2025-11-14 19:31:37,338] - [   START    ] - Working with CatBoostClassification\n",
      "[2025-11-14 19:31:37,338] - [   START    ] - Tuning CatBoostClassification\n",
      "[2025-11-14 19:38:36,643] - [   OPTUNA   ] - Trial 0. New best score 0.01811704929087457 with parameters {'boosting_type': 'Plain', 'depth': 9, 'l2_leaf_reg': 143.0378732744839, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Depthwise', 'min_data_in_leaf': 229, 'rsm': 0.9781976563006176, 'subsample': 0.6300649112954666, 'model_size_reg': 158.3450076165329, 'auto_class_weights': None, 'iterations': 1872}\n",
      "[2025-11-14 19:38:36,644] - [   OPTUNA   ] - 1 trials completed\n",
      "[2025-11-14 19:38:36,645] - [BEST PARAMS ] - {'iterations': 1872, 'thread_count': 12, 'logging_level': 'Silent', 'task_type': 'CPU', 'od_type': 'Iter', 'od_wait': 100, 'random_state': 0, 'od_pval': None, 'cat_features': [], 'boosting_type': 'Plain', 'depth': 9, 'l2_leaf_reg': 143.0378732744839, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Depthwise', 'min_data_in_leaf': 229, 'rsm': 0.9781976563006176, 'subsample': 0.6300649112954666, 'model_size_reg': 158.3450076165329, 'auto_class_weights': None, 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'CatBoostClassification', 'eval_metric': None}\n",
      "[2025-11-14 19:38:36,646] - [    END     ] - Tuning CatBoostClassification\n",
      "[2025-11-14 19:38:36,646] - [   START    ] - Fitting CatBoostClassification\n",
      "[2025-11-14 19:45:12,673] - [    END     ] - Fitting CatBoostClassification\n",
      "[2025-11-14 19:45:14,490] - [   SCORE    ] - Train: 0.994890369422872\n",
      "[2025-11-14 19:45:14,512] - [   SCORE    ] - OOF: 0.9909529855337293\n",
      "[2025-11-14 19:45:14,515] - [    END     ] - Working with CatBoostClassification\n",
      "[2025-11-14 19:45:14,515] - [  NEW BEST  ] - CatBoostClassification. Best score: 0.9909529855337293 \n",
      "\n",
      "[2025-11-14 19:45:14,516] - [   MODEL    ] - 5 out of 8. XGBClassification\n",
      "[2025-11-14 19:45:14,517] - [   START    ] - Working with XGBClassification\n",
      "[2025-11-14 19:45:14,517] - [   START    ] - Tuning XGBClassification\n",
      "[2025-11-14 19:45:30,671] - [   OPTUNA   ] - Trial 0. New best score 0.03084684567921876 with parameters {'max_depth': 9, 'grow_policy': 'depthwise', 'max_leaves': 284, 'gamma': 8.473095986778095, 'subsample': 0.6813047017599905, 'colsample_bytree': 0.49382849013642327, 'colsample_bylevel': 0.9025957007038717, 'reg_lambda': 9.636627605010293, 'reg_alpha': 3.8344151882577773, 'min_child_weight': 16, 'class_weight': 'balanced', 'num_boost_round': 534}\n",
      "[2025-11-14 19:45:30,673] - [   OPTUNA   ] - 1 trials completed\n",
      "[2025-11-14 19:45:30,673] - [BEST PARAMS ] - {'nthread': 12, 'device': 'cpu', 'objective': 'binary:logistic', 'seed': 0, 'verbosity': 0, 'num_boost_round': 534, 'early_stopping_rounds': 100, 'class_weight': 'balanced', 'scale_pos_weight': 54.29506871463217, 'max_depth': 9, 'grow_policy': 'depthwise', 'max_leaves': 284, 'gamma': 8.473095986778095, 'subsample': 0.6813047017599905, 'colsample_bytree': 0.49382849013642327, 'colsample_bylevel': 0.9025957007038717, 'reg_lambda': 9.636627605010293, 'reg_alpha': 3.8344151882577773, 'min_child_weight': 16, 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'XGBClassification', 'eval_metric': None}\n",
      "[2025-11-14 19:45:30,674] - [    END     ] - Tuning XGBClassification\n",
      "[2025-11-14 19:45:30,675] - [   START    ] - Fitting XGBClassification\n",
      "[2025-11-14 19:45:45,919] - [    END     ] - Fitting XGBClassification\n",
      "[2025-11-14 19:45:46,299] - [   SCORE    ] - Train: 0.9997584626161108\n",
      "[2025-11-14 19:45:46,318] - [   SCORE    ] - OOF: 0.9910652462311557\n",
      "[2025-11-14 19:45:46,331] - [    END     ] - Working with XGBClassification\n",
      "[2025-11-14 19:45:46,331] - [  NEW BEST  ] - XGBClassification. Best score: 0.9910652462311557 \n",
      "\n",
      "[2025-11-14 19:45:46,332] - [   MODEL    ] - 6 out of 8. LightGBMClassification\n",
      "[2025-11-14 19:45:46,333] - [   START    ] - Working with LightGBMClassification\n",
      "[2025-11-14 19:45:46,334] - [   START    ] - Tuning LightGBMClassification\n",
      "[2025-11-14 19:45:50,195] - [   OPTUNA   ] - Trial 0. New best score 0.03000099964568319 with parameters {'max_depth': 9, 'num_leaves': 369, 'min_data_in_leaf': 155, 'bagging_fraction': 0.7724415914984484, 'bagging_freq': 10, 'feature_fraction': 0.7875364678399936, 'lambda_l1': 4.375872112626925, 'lambda_l2': 8.917730007820797, 'min_gain_to_split': 19.273255210020587, 'is_unbalance': 'false', 'num_iterations': 38}\n",
      "[2025-11-14 19:46:01,126] - [   OPTUNA   ] - 3 trials completed\n",
      "[2025-11-14 19:46:01,127] - [BEST PARAMS ] - {'num_iterations': 38, 'num_threads': 12, 'seed': 0, 'verbosity': -1, 'device_type': 'cpu', 'early_stopping_round': 100, 'early_stopping_min_delta': 0.0001, 'objective': 'binary', 'metric': '', 'max_depth': 9, 'num_leaves': 369, 'min_data_in_leaf': 155, 'bagging_fraction': 0.7724415914984484, 'bagging_freq': 10, 'feature_fraction': 0.7875364678399936, 'lambda_l1': 4.375872112626925, 'lambda_l2': 8.917730007820797, 'min_gain_to_split': 19.273255210020587, 'is_unbalance': 'false', 'time_series': False, 'model_type': 'classification', 'n_splits': 10, 'name': 'LightGBMClassification', 'eval_metric': None}\n",
      "[2025-11-14 19:46:01,127] - [    END     ] - Tuning LightGBMClassification\n",
      "[2025-11-14 19:46:01,128] - [   START    ] - Fitting LightGBMClassification\n",
      "[2025-11-14 19:46:04,658] - [    END     ] - Fitting LightGBMClassification\n",
      "[2025-11-14 19:46:04,776] - [   SCORE    ] - Train: 0.9882473701842545\n",
      "[2025-11-14 19:46:04,803] - [   SCORE    ] - OOF: 0.986607710065479\n",
      "[2025-11-14 19:46:04,806] - [    END     ] - Working with LightGBMClassification\n",
      "[2025-11-14 19:46:04,807] - [BEST  MODEL ] - XGBClassification. Best score: 0.9910652462311557 \n",
      "\n",
      "[2025-11-14 19:46:04,807] - [   MODEL    ] - 7 out of 8. Stacker\n",
      "[2025-11-14 19:46:04,854] - [   START    ] - Working with Stacker\n",
      "[2025-11-14 19:46:04,854] - [   START    ] - Tuning Stacker\n",
      "[2025-11-14 19:46:06,667] - [   OPTUNA   ] - Trial 0. New best score 0.019013979976721475 with parameters {'max_depth': 9, 'num_leaves': 369, 'min_data_in_leaf': 155, 'bagging_fraction': 0.7724415914984484, 'bagging_freq': 10, 'feature_fraction': 0.7875364678399936, 'lambda_l1': 4.375872112626925, 'lambda_l2': 8.917730007820797, 'min_gain_to_split': 19.273255210020587, 'is_unbalance': 'false', 'num_iterations': 39}\n",
      "[2025-11-14 19:46:15,136] - [   OPTUNA   ] - 5 trials completed\n",
      "[2025-11-14 19:46:15,137] - [BEST PARAMS ] - {'num_iterations': 39, 'num_threads': 12, 'seed': 0, 'verbosity': -1, 'device_type': 'cpu', 'early_stopping_round': 100, 'early_stopping_min_delta': 0.0001, 'objective': 'binary', 'metric': '', 'max_depth': 9, 'num_leaves': 369, 'min_data_in_leaf': 155, 'bagging_fraction': 0.7724415914984484, 'bagging_freq': 10, 'feature_fraction': 0.7875364678399936, 'lambda_l1': 4.375872112626925, 'lambda_l2': 8.917730007820797, 'min_gain_to_split': 19.273255210020587, 'is_unbalance': 'false', 'time_series': False, 'model_type': 'classification', 'n_splits': 5, 'name': 'Stacker', 'eval_metric': None}\n",
      "[2025-11-14 19:46:15,138] - [    END     ] - Tuning Stacker\n",
      "[2025-11-14 19:46:15,139] - [   START    ] - Fitting Stacker\n",
      "[2025-11-14 19:46:16,783] - [    END     ] - Fitting Stacker\n",
      "[2025-11-14 19:46:17,033] - [   SCORE    ] - Train: 0.9931507622963303\n",
      "[2025-11-14 19:46:17,057] - [   SCORE    ] - OOF: 0.9919588828993452\n",
      "[2025-11-14 19:46:17,061] - [    END     ] - Working with Stacker\n",
      "[2025-11-14 19:46:17,062] - [  NEW BEST  ] - Stacker. Best score: 0.9919588828993452 \n",
      "\n",
      "[2025-11-14 19:46:17,062] - [   MODEL    ] - 8 out of 8. Blender\n",
      "[2025-11-14 19:46:17,067] - [   START    ] - Working with Blender\n",
      "[2025-11-14 19:46:17,068] - [   START    ] - Tuning Blender\n",
      "[2025-11-14 19:46:17,400] - [   OPTUNA   ] - Best score 0.9923252042028323 with weights [0.0, 0.0, 0.0, 0.7639320225002103, 0.2360679774997897, 0.0]\n",
      "[2025-11-14 19:46:17,708] - [   OPTUNA   ] - Best score 0.9923252042028323 with weights [0.0, 0.0, 0.0, 0.7639320225002103, 0.2360679774997897, 0.0]\n",
      "[2025-11-14 19:46:17,709] - [BEST PARAMS ] - {'weights': [0.0, 0.0, 0.0, 0.7639320225002103, 0.2360679774997897, 0.0], 'n': 6, 'random_state': 42, 'n_iters': 10, 'n_inner_iters': 3}\n",
      "[2025-11-14 19:46:17,710] - [    END     ] - Tuning Blender\n",
      "[2025-11-14 19:46:17,731] - [   SCORE    ] - Train: 0.9923252042028323\n",
      "[2025-11-14 19:46:17,750] - [   SCORE    ] - OOF: 0.9923252042028323\n",
      "[2025-11-14 19:46:17,752] - [    END     ] - Working with Blender\n",
      "[2025-11-14 19:46:17,753] - [  NEW BEST  ] - Blender. Best score: 0.9923252042028323 \n",
      "\n",
      "[INFO] Модель успешно обучена\n",
      "[INFO] Лучший OOF score: 0.9923252042028323\n"
     ]
    }
   ],
   "source": [
    "automl = None\n",
    "model_trained = False\n",
    "\n",
    "if not data_loaded:\n",
    "    print(\"[ERROR] Данные не загружены. Пропуск обучения модели.\")\n",
    "else:\n",
    "    try:\n",
    "        # Проверки перед обучением\n",
    "        if X is None or y is None:\n",
    "            print(\"[ERROR] X или y не определены. Пропуск обучения модели.\")\n",
    "        elif not isinstance(X, (pd.DataFrame, np.ndarray)):\n",
    "            print(f\"[ERROR] X должен быть DataFrame или ndarray, получен {type(X)}. Пропуск обучения модели.\")\n",
    "        elif not isinstance(y, np.ndarray):\n",
    "            print(f\"[ERROR] y должен быть ndarray, получен {type(y)}. Пропуск обучения модели.\")\n",
    "        else:\n",
    "            print(\"[INFO] Инициализация AutoML...\")\n",
    "            print(f\"[INFO] Параметры: task=classification, n_splits={n_folds}, n_jobs=3\")\n",
    "            \n",
    "            automl = AutoML(\n",
    "                task='classification',\n",
    "                use_preprocessing_pipeline=True,\n",
    "                feature_selector_type=None,\n",
    "                use_val_test_pipeline=False,\n",
    "                auto_models_init_kwargs = {\n",
    "                    \"metric\": \"roc_auc\",\n",
    "                    \"time_series\": False,\n",
    "                    \"models_list\": [\"linear\", \"forests\", \"boostings\"],\n",
    "                    \"blend\": True,\n",
    "                    \"stack\": True,\n",
    "                    \"n_splits\": n_folds,\n",
    "                },\n",
    "                n_jobs=12, \n",
    "                random_state=0,\n",
    "            )\n",
    "            print(\"[INFO] AutoML инициализирован\")\n",
    "            \n",
    "            print(\"[INFO] Начало обучения модели...\")\n",
    "            automl = automl.fit(\n",
    "                X, y, \n",
    "                auto_model_fit_kwargs = {\n",
    "                    \"tuning_timeout\": 10\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Проверка результата обучения\n",
    "            if automl is None:\n",
    "                print(\"[ERROR] AutoML вернул None после обучения. Пропуск дальнейшей обработки.\")\n",
    "            elif not hasattr(automl, 'auto_model'):\n",
    "                print(\"[ERROR] AutoML не имеет атрибута auto_model. Пропуск дальнейшей обработки.\")\n",
    "            else:\n",
    "                model_trained = True\n",
    "                print(\"[INFO] Модель успешно обучена\")\n",
    "                \n",
    "                if hasattr(automl.auto_model, 'best_score'):\n",
    "                    print(f\"[INFO] Лучший OOF score: {automl.auto_model.best_score}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Ошибка при обучении модели: {type(e).__name__}: {e}\")\n",
    "        import traceback\n",
    "        print(f\"[ERROR] Трассировка: {traceback.format_exc()}\")\n",
    "        model_trained = False\n",
    "        print(\"[WARNING] Модель не обучена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7090f0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Получение предсказаний...\n",
      "[INFO] Получены предсказания. Размер: (76000, 2)\n",
      "[INFO] Используется вероятность второго класса\n",
      "[INFO] OOF score: 0.9923252042028323\n",
      "[INFO] Вычисление ROC-AUC на полных данных...\n",
      "[INFO] ROC-AUC на полных данных: 0.9998607632099894\n",
      "[INFO] Результаты: OOF=0.9923252042028323, Full=0.9998607632099894\n",
      "\n",
      "[RESULT] OOF score: 0.9923252042028323, Full data score: 0.9998607632099894\n"
     ]
    }
   ],
   "source": [
    "oof_score = None\n",
    "score = None\n",
    "predictions = None\n",
    "\n",
    "if not model_trained or automl is None:\n",
    "    print(\"[ERROR] Модель не обучена. Пропуск предсказаний и оценки.\")\n",
    "else:\n",
    "    try:\n",
    "        print(\"[INFO] Получение предсказаний...\")\n",
    "        \n",
    "        # Проверки перед предсказанием\n",
    "        if not hasattr(automl, 'predict'):\n",
    "            print(\"[ERROR] AutoML не имеет метода predict. Пропуск предсказаний.\")\n",
    "        elif X is None:\n",
    "            print(\"[ERROR] X не определен. Пропуск предсказаний.\")\n",
    "        else:\n",
    "            predictions = automl.predict(X)\n",
    "            \n",
    "            if predictions is None:\n",
    "                print(\"[ERROR] Предсказания равны None. Пропуск дальнейшей обработки.\")\n",
    "            elif len(predictions) == 0:\n",
    "                print(\"[ERROR] Предсказания пустые. Пропуск дальнейшей обработки.\")\n",
    "            else:\n",
    "                print(f\"[INFO] Получены предсказания. Размер: {predictions.shape}\")\n",
    "                \n",
    "                # Проверка формы предсказаний для бинарной классификации\n",
    "                if len(predictions.shape) == 2 and predictions.shape[1] >= 2:\n",
    "                    predictions_proba = predictions[:, 1]\n",
    "                    print(\"[INFO] Используется вероятность второго класса\")\n",
    "                elif len(predictions.shape) == 1:\n",
    "                    predictions_proba = predictions\n",
    "                    print(\"[INFO] Используются предсказания напрямую\")\n",
    "                else:\n",
    "                    print(f\"[ERROR] Неожиданная форма предсказаний: {predictions.shape}. Пропуск дальнейшей обработки.\")\n",
    "                    predictions_proba = None\n",
    "                \n",
    "                if predictions_proba is not None:\n",
    "                    # Получение OOF score\n",
    "                    if hasattr(automl.auto_model, 'best_score'):\n",
    "                        oof_score = automl.auto_model.best_score\n",
    "                        print(f\"[INFO] OOF score: {oof_score}\")\n",
    "                    else:\n",
    "                        print(\"[WARNING] best_score не найден в auto_model\")\n",
    "                    \n",
    "                    # Вычисление метрики на полных данных\n",
    "                    print(\"[INFO] Вычисление ROC-AUC на полных данных...\")\n",
    "                    if y is None:\n",
    "                        print(\"[ERROR] y не определен. Пропуск вычисления метрики.\")\n",
    "                    elif len(y) != len(predictions_proba):\n",
    "                        print(f\"[ERROR] Несоответствие размеров: y={len(y)}, predictions={len(predictions_proba)}. Пропуск вычисления метрики.\")\n",
    "                    else:\n",
    "                        try:\n",
    "                            score = roc_auc_score(y, predictions_proba)\n",
    "                            print(f\"[INFO] ROC-AUC на полных данных: {score}\")\n",
    "                            print(f\"[INFO] Результаты: OOF={oof_score}, Full={score}\")\n",
    "                        except Exception as metric_error:\n",
    "                            print(f\"[ERROR] Ошибка при вычислении ROC-AUC: {type(metric_error).__name__}: {metric_error}\")\n",
    "                            print(\"[WARNING] Метрика не вычислена\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Ошибка при получении предсказаний или оценке: {type(e).__name__}: {e}\")\n",
    "        import traceback\n",
    "        print(f\"[ERROR] Трассировка: {traceback.format_exc()}\")\n",
    "        print(\"[WARNING] Предсказания или оценка не выполнены\")\n",
    "\n",
    "# Вывод результатов\n",
    "if oof_score is not None and score is not None:\n",
    "    print(f\"\\n[RESULT] OOF score: {oof_score}, Full data score: {score}\")\n",
    "    (oof_score, score)\n",
    "else:\n",
    "    print(\"\\n[RESULT] Результаты недоступны\")\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69edf3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
