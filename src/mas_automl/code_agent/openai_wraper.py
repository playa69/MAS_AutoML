from __future__ import annotations

import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Optional

from langchain_community.chat_models import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage


@dataclass
class LLMConfig:
    #model: str = "deepseek/deepseek-chat-v3.1:free"
    temperature: float = 0.0


class LLMClient:
    """ÐžÐ±Ñ‘Ñ€Ñ‚ÐºÐ° Ð½Ð°Ð´ LangChain ChatOpenAI (OpenRouter ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ñ‹Ð¹ ÐºÐ»Ð¸ÐµÐ½Ñ‚) Ñ fallback-Ð»Ð¾Ð³Ð¸ÐºÐ¾Ð¹."""

    def __init__(self, config: Optional[LLMConfig] = None) -> None:
        _load_env_file()
        print("ðŸ”‘ OPENAI_API_KEY =", os.getenv("MAS_LLM__API_KEY")[:7])
        print("ðŸŒ BASE_URL =", os.getenv("MAS_LLM__BASE_URL"))

        self.config = config or LLMConfig()
        api_key = (
            os.getenv("OPENAI_API_KEY")
            or os.getenv("MAS_LLM__API_KEY")
            or os.getenv("OPENROUTER_API_KEY")
        )
        base_url = os.getenv("OPENAI_BASE_URL") or os.getenv("MAS_LLM__BASE_URL")

        self._client: ChatOpenAI | None = None
        model_from_env = os.getenv("MAS_LLM__MODEL")
        if model_from_env:
            self.config.model = model_from_env

        if api_key:
            client_kwargs: dict[str, Any] = {
                "model": self.config.model,
                "temperature": self.config.temperature,
                "openai_api_key": api_key,
                "openai_api_base": base_url or "https://openrouter.ai/api/v1",

            }
            print(f"KWARGS - {client_kwargs}")
            try:
                self._client = ChatOpenAI(**client_kwargs)
                print("âœ… ChatOpenAI ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½ Ð´Ð»Ñ OpenRouter")
            except Exception as e:
                import traceback
                print("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°:", repr(e))
                traceback.print_exc()
                self._client = None

    def chat(
        self,
        prompt: str,
        *,
        system: str | None = None,
        fallback: str = "",
        temperature: float | None = None,
    ) -> str:
        if self._client is None:
            return fallback or self._default_fallback(prompt)

        messages = []
        if system:
            messages.append(SystemMessage(content=system))
        messages.append(HumanMessage(content=prompt))

        try:
            llm = self._client.bind(temperature=temperature or self.config.temperature)
            response = llm.invoke(messages)
            content = getattr(response, "content", None)
            if not content:
                raise ValueError("LLM Ð²ÐµÑ€Ð½ÑƒÐ» Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚.")
            return content.strip()
        except Exception as e:
            import traceback
            print("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð²Ñ‹Ð·Ð¾Ð²Ðµ ChatOpenAI:", repr(e))
            traceback.print_exc()
            return fallback or self._default_fallback(prompt)

    def _default_fallback(self, prompt: str) -> str:
        """ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ ÑÐ²Ñ€Ð¸ÑÑ‚Ð¸ÐºÐ° Ð½Ð° ÑÐ»ÑƒÑ‡Ð°Ð¹ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº LLM."""
        if "framework" in prompt.lower():
            return json.dumps(
                {
                    "framework": "AutoGluon",
                    "reason": "Ð’Ñ‹Ð±Ñ€Ð°Ð½ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ: Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ‡Ð½Ð¾Ð¹ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸ÐµÐ¹.",
                },
                ensure_ascii=False,
            )
        return "# Fallback: LLM Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½."


def _load_env_file() -> None:
    env_loaded_flag = "_MAS_CODE_AGENT_ENV_LOADED"
    if os.environ.get(env_loaded_flag):
        return

    env_path = Path(__file__).resolve().parent / ".env"
    if not env_path.exists():
        os.environ[env_loaded_flag] = "1"
        return

    for line in env_path.read_text(encoding="utf-8").splitlines():
        line = line.strip()
        if not line or line.startswith("#") or "=" not in line:
            continue
        key, value = line.split("=", 1)
        key = key.strip()
        value = value.strip().strip('"').strip("'")
        os.environ[key] = value  # <-- Ð’ÐÐ–ÐÐž! Ð·Ð°Ð¼ÐµÐ½ÑÐµÐ¼ setdefault()

    os.environ[env_loaded_flag] = "1"


__all__ = ["LLMClient", "LLMConfig"]

if __name__ == "__main__":
    print("ðŸš€ Ð¡Ñ‚Ð°Ñ€Ñ‚ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ¸ LLMClient")
    try:
        client = LLMClient(LLMConfig())
        print("âœ… LLMClient ÑÐ¾Ð·Ð´Ð°Ð½.")
    except Exception as e:
        print("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ LLMClient:", repr(e))
        raise SystemExit(1)

    print("\nðŸ” ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¾Ð±ÑŠÐµÐºÑ‚ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°:")
    print("   _client =", type(getattr(client, "_client", None)).__name__)

    if client._client is None:
        print("âš ï¸  ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð½Ðµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒ API_KEY Ð¸ BASE_URL.")
        raise SystemExit(2)

    print("\nðŸ’¬ ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ðº Ð¼Ð¾Ð´ÐµÐ»Ð¸...")
    try:
        reply = client.chat("Ð¡ÐºÐ°Ð¶Ð¸ 'Ñ‚ÐµÑÑ‚ ÑÐ²ÑÐ·Ð¸'")
        print("âœ… ÐžÑ‚Ð²ÐµÑ‚ Ð¾Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸:", repr(reply))
    except Exception as e:
        print("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð²Ñ‹Ð·Ð¾Ð²Ðµ chat():", repr(e))
