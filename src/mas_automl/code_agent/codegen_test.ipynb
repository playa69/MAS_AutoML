{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc0ebeb",
   "metadata": {},
   "source": [
    "## –í—ã–±–æ—Ä —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd91304",
   "metadata": {},
   "source": [
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–æ—É—Ç–±—É–∫, —á—Ç–æ–±—ã –ø–æ —à–∞–≥–∞–º –∑–∞–ø—É—Å–∫–∞—Ç—å –∑–∞–≥—Ä—É–∑–∫—É –º–æ–∫–æ–≤, –≤—ã–±–æ—Ä —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ –∏ –∫–æ–¥–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—é."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f75451b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–ª—é—á–∏ data: ['summary', 'priority', 'steps', 'example_pipeline_snippet', 'frameworks_recommended', 'rationale', 'estimated_complexity', 'confidence']\n",
      "–ö–ª—é—á–∏ metadata: ['dataset_id', 'name', 'version', 'version_label', 'description', 'citation', 'paper_url', 'paper_reference', 'creator', 'contributor', 'collection_date', 'upload_date', 'language', 'licence', 'url', 'original_data_url', 'minio_url', 'format', 'file_id', 'default_target_attribute', 'ignore_attribute', 'row_id_attribute', 'num_rows', 'num_features', 'num_classes', 'num_missing_values', 'quality', 'dataset_type', 'tags', 'status', 'visibility', 'extra_info', 'local_path']\n",
      "–§—Ä–µ–π–º–≤–æ—Ä–∫–∏: ['AutoGluon', 'H2O AutoML', 'LightAutoML']\n"
     ]
    }
   ],
   "source": [
    "from mas_automl.code_agent.load_mocks import load_mock_inputs\n",
    "\n",
    "DATA_ANALYZE, METADATA, REGISTRY, FINAL_DATA = load_mock_inputs()\n",
    "print(f\"–ö–ª—é—á–∏ data: {list[str](DATA_ANALYZE.keys())}\")\n",
    "print(f\"–ö–ª—é—á–∏ metadata: {list(METADATA.keys())}\")\n",
    "print(f\"–§—Ä–µ–π–º–≤–æ—Ä–∫–∏: {list(REGISTRY.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8586fa58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Loaded Mock Inputs\n",
       "\n",
       "#### Data Analyze Keys\n",
       "summary, priority, steps, example_pipeline_snippet, frameworks_recommended, rationale, estimated_complexity, confidence\n",
       "\n",
       "#### Metadata Keys\n",
       "dataset_id, name, version, version_label, description, citation, paper_url, paper_reference, creator, contributor, collection_date, upload_date, language, licence, url, original_data_url, minio_url, format, file_id, default_target_attribute, ignore_attribute, row_id_attribute, num_rows, num_features, num_classes, num_missing_values, quality, dataset_type, tags, status, visibility, extra_info, local_path\n",
       "\n",
       "#### Registry Frameworks\n",
       "AutoGluon, H2O AutoML, LightAutoML\n",
       "\n",
       "manifest, validation_report, metafeatures, preprocessing_recipe, code_agent_recommendation, run_metadata\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mas_automl.code_agent.load_mocks import load_mock_inputs\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "DATA_ANALYZE, METADATA, REGISTRY, FINAL_DATA = load_mock_inputs()\n",
    "\n",
    "# Pretty display in notebook\n",
    "display(Markdown(f\"\"\"\n",
    "### Loaded Mock Inputs\n",
    "\n",
    "#### Data Analyze Keys\n",
    "{', '.join(DATA_ANALYZE.keys())}\n",
    "\n",
    "#### Metadata Keys\n",
    "{', '.join(METADATA.keys())}\n",
    "\n",
    "#### Registry Frameworks\n",
    "{', '.join(REGISTRY.keys())}\n",
    "\n",
    "{', '.join(FINAL_DATA.keys())}\n",
    "\"\"\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "729b02da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AutoGluon': \"AutoGluon ‚Äî AutoML-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫ AWS –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö, —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö, –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (stacking, bagging, blending) –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥—É–ª—å–Ω–∞—è: AutoGluon-Tabular, AutoGluon-Multimodal, AutoGluon-TimeSeries. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç GPU, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö. \\n\\n–ì–¥–µ –ø—Ä–∏–º–µ–Ω—è—Ç—å: —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –Ω–∞ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö; –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (classification, object detection) –∏ —Ç–µ–∫—Å—Ç–æ–≤ (sentiment analysis, NER) —á–µ—Ä–µ–∑ AutoMM; —Å–º–µ—à–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö (—Ç–∞–±–ª–∏—Ü–∞ + —Ç–µ–∫—Å—Ç/–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ); Kaggle/–ø—Ä–æ–¥–∞–∫—à–Ω-—Å—Ü–µ–Ω–∞—Ä–∏–∏, –≥–¥–µ –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –º–∞–∫—Å–∏–º—É–º –∫–∞—á–µ—Å—Ç–≤–∞ –±–µ–∑ —Ä—É—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏. \\n\\n–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤; –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤; –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π HPO (Bayesian Optimization + Random Search); —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π; –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å PyTorch –∏ MXNet; –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ GPU. \\n\\n–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: –ø–ª–æ—Ö–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –≥—Ä–∞—Ñ–æ–≤—ã—Ö, –º–Ω–æ–≥–æ—Ç–∞–±–ª–∏—á–Ω—ã—Ö –∏ —Å–∏–ª—å–Ω–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π; –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π; –¥–æ–ª–≥–∏–µ —Ü–∏–∫–ª—ã –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏ –ø–æ–ª–Ω–æ–º —Å—Ç–µ–∫–∏–Ω–≥–µ; RAM –∏ VRAM-–∑–∞–≤–∏—Å–∏–º—ã–π; —Ç—Ä–µ–±—É–µ—Ç —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Å–µ—Ö –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. \\n\\n–¢–∏–ø–∏—á–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: –Ω–∞ —Å—Ä–µ–¥–Ω–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö (–¥–æ 1 –º–ª–Ω —Å—Ç—Ä–æ–∫) –¥–æ—Å—Ç–∏–≥–∞–µ—Ç state-of-the-art –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏ 1‚Äì3 —á–∞—Å–∞—Ö –æ–±—É—á–µ–Ω–∏—è –Ω–∞ GPU. –í—Ä–µ–º—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è –ª–∏–Ω–µ–π–Ω–æ –æ—Ç —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Ä–∞–∑–º–µ—Ä–æ–≤ –∞–Ω—Å–∞–º–±–ª—è. \\n\\n–û–ø—Ç–∏–º–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: –ø—Ä–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏, –∫–æ–≥–¥–∞ –≤–∞–∂–Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤ –æ–±—É—á–µ–Ω–∏—è; –∫–æ–≥–¥–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω—Å–∞–º–±–ª—å. –ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ‚Äî –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä, –º–æ–¥–µ–ª–µ–π –≥—Ä–∞—Ñ–æ–≤, –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏–ª–∏ —Å—Ç—Ä–æ–≥–∏—Ö –ª–∏–º–∏—Ç–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—É—á–µ–Ω–∏—è. \\n\\n–ü—Ä–∏–º–µ—Ä:\\n```python\\nfrom autogluon.tabular import TabularPredictor\\npred = TabularPredictor(label='target').fit('data.csv', time_limit=3600)\\n```\",\n",
       " 'H2O AutoML': \"H2O AutoML ‚Äî –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π AutoML-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –Ω–∞ Java, —Å API –¥–ª—è Python, R –∏ Scala. –†–µ–∞–ª–∏–∑—É–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ —Å—Ç–µ–∫–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π (GBM, XGBoost, GLM, DRF, DeepLearning, StackedEnsemble). –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Spark, Hadoop –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ. \\n\\n–ì–¥–µ –ø—Ä–∏–º–µ–Ω—è—Ç—å: –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –Ω–∞ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ—Ç –¥–µ—Å—è—Ç–∫–æ–≤ –ú–ë –¥–æ —Å–æ—Ç–µ–Ω –ì–ë; production-—Å—Ü–µ–Ω–∞—Ä–∏–∏ —Å –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏ Spark/Hadoop; –ø—Ä–æ–µ–∫—Ç—ã, –≥–¥–µ –≤–∞–∂–Ω–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å. –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö —Å–∏—Å—Ç–µ–º, –≥–¥–µ —É–∂–µ –µ—Å—Ç—å JVM-–∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞. \\n\\n–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, early stopping, –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è leaderboard –º–æ–¥–µ–ª–µ–π, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π, –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å MOJO/POJO –¥–ª—è –¥–µ–ø–ª–æ—è –≤ Java-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç GPU –¥–ª—è XGBoost –∏ Deep Learning. \\n\\n–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: —Ç–æ–ª—å–∫–æ —Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ; –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, —Ç–µ–∫—Å—Ç–∞ –∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏; –≤—ã—Å–æ–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ RAM –ø—Ä–∏ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö; –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞; –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å–∏–ª—å–Ω–æ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è. \\n\\n–¢–∏–ø–∏—á–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: –Ω–∞ –Ω–∞–±–æ—Ä–µ –∏–∑ 1‚Äì10 –º–ª–Ω —Å—Ç—Ä–æ–∫ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–Ω–∏–º–∞–µ—Ç –æ—Ç 20 –º–∏–Ω—É—Ç –¥–æ 2 —á–∞—Å–æ–≤ –ø—Ä–∏ `max_runtime_secs=3600`. –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞. \\n\\n–û–ø—Ç–∏–º–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: –µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ, –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö ML-–∑–∞–¥–∞—á; –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫–∏–Ω–≥, –ª–∏–¥–µ—Ä–±–æ—Ä–¥ –∏ –¥–µ–ø–ª–æ–π –º–æ–¥–µ–ª–µ–π. –ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ‚Äî –ø—Ä–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –ø–∞–π–ø–ª–∞–π–Ω–∞—Ö, NLP –∏ CV-–∑–∞–¥–∞—á–∞—Ö. \\n\\n–ü—Ä–∏–º–µ—Ä:\\n```python\\nimport h2o\\nfrom h2o.automl import H2OAutoML\\nh2o.init()\\ndf = h2o.import_file('data.csv')\\naml = H2OAutoML(max_runtime_secs=3600)\\naml.train(y='target', training_frame=df)\\n```\",\n",
       " 'LightAutoML': \"LightAutoML (LAMA) ‚Äî AutoML-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ—Ç Sber AI Lab, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –Ω–∞ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π feature engineering, –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∞–Ω—Å–∞–º–±–ª–∏ –º–æ–¥–µ–ª–µ–π (CatBoost, LightGBM, Linear, NN), –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å –∏ white-box —Ä–µ–∂–∏–º. \\n\\n–ì–¥–µ –ø—Ä–∏–º–µ–Ω—è—Ç—å: –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, —Ä–µ–≥—Ä–µ—Å—Å–∏–∏, scoring –≤ –±–∞–Ω–∫–∞—Ö, —Ñ–∏–Ω—Ç–µ—Ö–µ, —Ç–µ–ª–µ–∫–æ–º–∞—Ö –∏ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç–∏; —Å—Ä–µ–¥–Ω–∏–µ –∏ –∫—Ä—É–ø–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (–¥–æ 10 –º–ª–Ω —Å—Ç—Ä–æ–∫); –ø—Ä–æ–¥–∞–∫—à–Ω-—Å—Ü–µ–Ω–∞—Ä–∏–∏, –≥–¥–µ –≤–∞–∂–Ω—ã –∫–æ–Ω—Ç—Ä–æ–ª—å, –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å. \\n\\n–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ CPU (LightGBM/CatBoost), –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –∏—Ö —Ç–∏–ø–æ–≤, —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–æ–ª—è–º–∏ (`roles`), white-box –ø—Ä–µ—Å–µ—Ç—ã –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (`timeout`), —Ä–∞–±–æ—Ç–∞ –Ω–∞ –æ–¥–Ω–æ–π –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö CPU. –ï—Å—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è explainability (SHAP, permutation importance). \\n\\n–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: —Ç–æ–ª—å–∫–æ —Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ; –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å (—Ç–µ–∫—Å—Ç, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è) –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ –º–æ–¥—É–ª—è–º–∏; —Å–ª–∞–±–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏ –≥—Ä–∞—Ñ–æ–≤—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä; –Ω–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π GPU-–ø–æ–¥–¥–µ—Ä–∂–∫–∏; —Ç—Ä–µ–±—É–µ—Ç –∞–∫–∫—É—Ä–∞—Ç–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è —Ä–æ–ª–µ–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. \\n\\n–¢–∏–ø–∏—á–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 10‚Äì30 –º–∏–Ω—É—Ç –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ –Ω–∞–±–æ—Ä–∞ (–¥–æ 1 –º–ª–Ω —Å—Ç—Ä–æ–∫); –¥–æ 2 —á–∞—Å–æ–≤ –¥–ª—è –∫—Ä—É–ø–Ω—ã—Ö (–¥–æ 10 –º–ª–Ω). –î–∞—ë—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç, —Å—Ä–∞–≤–Ω–∏–º—ã–π —Å —Ä—É—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –æ–ø—ã—Ç–Ω–æ–≥–æ DS. \\n\\n–û–ø—Ç–∏–º–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: –¥–ª—è –∑–∞–¥–∞—á —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏ –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –∫ explainability; –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ AutoML –¥–ª—è tabular production. –ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ‚Äî –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ GPU, –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å, —Å–ª–æ–∂–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏. \\n\\n–ü—Ä–∏–º–µ—Ä:\\n```python\\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML\\nfrom lightautoml.tasks import Task\\nimport pandas as pd\\ntrain = pd.read_csv('train.csv')\\nautoml = TabularAutoML(task=Task('binary', metric='auc'))\\nroles = {'target': 'target'}\\nautoml.fit_predict(train, roles=roles)\\n```\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fec16765",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATA.get('local_path')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9653946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User1\\\\Desktop\\\\ITMO_bootcamp\\\\data\\\\datasets\\\\openml_31_credit-g.csv'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_DATA[\"manifest\"][\"local_path\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e56cd773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   checking_status         1000 non-null   object \n",
      " 1   duration                1000 non-null   int64  \n",
      " 2   credit_history          1000 non-null   object \n",
      " 3   purpose                 1000 non-null   object \n",
      " 4   credit_amount           1000 non-null   float64\n",
      " 5   savings_status          1000 non-null   object \n",
      " 6   employment              1000 non-null   object \n",
      " 7   installment_commitment  1000 non-null   int64  \n",
      " 8   personal_status         1000 non-null   object \n",
      " 9   other_parties           1000 non-null   object \n",
      " 10  residence_since         1000 non-null   int64  \n",
      " 11  property_magnitude      1000 non-null   object \n",
      " 12  age                     1000 non-null   int64  \n",
      " 13  other_payment_plans     1000 non-null   object \n",
      " 14  housing                 1000 non-null   object \n",
      " 15  existing_credits        1000 non-null   int64  \n",
      " 16  job                     1000 non-null   object \n",
      " 17  num_dependents          1000 non-null   int64  \n",
      " 18  own_telephone           1000 non-null   object \n",
      " 19  foreign_worker          1000 non-null   object \n",
      " 20  class                   1000 non-null   object \n",
      "dtypes: float64(1), int64(6), object(14)\n",
      "memory usage: 164.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "   checking_status  duration                  credit_history   purpose  \\\n",
       " 0              <0         6  critical/other existing credit  radio/tv   \n",
       " 1        0<=X<200        48                   existing paid  radio/tv   \n",
       " \n",
       "    credit_amount    savings_status employment  installment_commitment  \\\n",
       " 0         1169.0  no known savings        >=7                       4   \n",
       " 1         5951.0              <100     1<=X<4                       2   \n",
       " \n",
       "       personal_status other_parties  ...  property_magnitude age  \\\n",
       " 0         male single          none  ...         real estate  67   \n",
       " 1  female div/dep/mar          none  ...         real estate  22   \n",
       " \n",
       "    other_payment_plans housing existing_credits      job num_dependents  \\\n",
       " 0                 none     own                2  skilled              1   \n",
       " 1                 none     own                1  skilled              1   \n",
       " \n",
       "    own_telephone foreign_worker class  \n",
       " 0            yes            yes  good  \n",
       " 1           none            yes   bad  \n",
       " \n",
       " [2 rows x 21 columns])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA_ANALYZE, METADATA, REGISTRY\n",
    "import pandas as pd\n",
    "\n",
    "PATH_TO_CSV = FINAL_DATA[\"manifest\"][\"local_path\"]\n",
    "dataset_df = pd.read_csv(PATH_TO_CSV)\n",
    "\n",
    "dataset_df.info(), dataset_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4deb842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë OPENAI_API_KEY = sk-or-v\n",
      "üåê BASE_URL = https://openrouter.ai/api/v1\n",
      "KWARGS - {'model': 'qwen/qwen3-coder-30b-a3b-instruct', 'temperature': 0.0, 'openai_api_key': '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', 'openai_api_base': 'https://openrouter.ai/api/v1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\Desktop\\ITMO_bootcamp\\src\\mas_automl\\code_agent\\openai_wraper.py:50: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the `langchain-openai package and should be used instead. To use it run `pip install -U `langchain-openai` and import as `from `langchain_openai import ChatOpenAI``.\n",
      "  self._client = ChatOpenAI(**client_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ChatOpenAI –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è OpenRouter\n"
     ]
    }
   ],
   "source": [
    "# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ ---\n",
    "from mas_automl.code_agent.openai_wraper import LLMClient, LLMConfig\n",
    "\n",
    "client = LLMClient(LLMConfig())\n",
    "\n",
    "# --- –í—ã–∑–æ–≤ –≤—ã–±–æ—Ä–∞ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "023583c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! It looks like you might have accidentally sent \"loh\" - is there something I can help you with? I\\'m here to assist with questions, conversations, or any other support you might need. Feel free to let me know how I can help!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.chat('loh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abdb71e",
   "metadata": {},
   "source": [
    "## –í—ã–±–æ—Ä —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a62a8",
   "metadata": {},
   "source": [
    "## –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞\n",
    "\n",
    "–ù–∏–∂–µ –ø–æ–∫–∞–∑–∞–Ω –ø—Ä–æ—Ü–µ—Å—Å –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞ —Å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º —á–µ—Ä–µ–∑ execnet_gateway\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e262490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞\n",
    "from mas_automl.code_agent.base_pipeline import generate_code, evaluate_code\n",
    "from mas_automl.code_agent.execnet_gateway import PythonSandboxClient\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "CSV_PATH = FINAL_DATA[\"manifest\"][\"local_path\"]\n",
    "OUTPUT_DIR = str(Path(CSV_PATH).parent / \"predictions\")\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "framework = \"scikit-learn\"\n",
    "max_iterations = 3\n",
    "feedback = \"\"\n",
    "\n",
    "print(f\"CSV –ø—É—Ç—å: {CSV_PATH}\")\n",
    "print(f\"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ø—Ä–µ–¥–∏–∫—Ç–æ–≤: {OUTPUT_DIR}\\n\")\n",
    "\n",
    "for iteration in range(1, max_iterations + 1):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"–ò—Ç–µ—Ä–∞—Ü–∏—è {iteration}/{max_iterations}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–¥\n",
    "    print(\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞...\")\n",
    "    code = generate_code(framework, client, iteration, feedback, FINAL_DATA)\n",
    "    print(f\"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥:\\n{code}\\n\")\n",
    "    \n",
    "    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–¥\n",
    "    print(\"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞...\")\n",
    "    tests_passed, test_feedback, predict_path = evaluate_code(\n",
    "        code, framework, CSV_PATH, OUTPUT_DIR, iteration, FINAL_DATA\n",
    "    )\n",
    "    \n",
    "    print(f\"–¢–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã: {tests_passed}\")\n",
    "    print(f\"–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å: {test_feedback}\")\n",
    "    if predict_path:\n",
    "        print(f\"–ü—É—Ç—å –∫ –ø—Ä–µ–¥–∏–∫—Ç–∞–º: {predict_path}\")\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–¥–∏–∫—Ç—ã\n",
    "        try:\n",
    "            pred_df = pd.read_csv(predict_path)\n",
    "            print(f\"\\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –ø—Ä–µ–¥–∏–∫—Ç–æ–≤:\")\n",
    "            print(pred_df.head())\n",
    "        except Exception as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ–¥–∏–∫—Ç–æ–≤: {e}\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    if tests_passed:\n",
    "        print(\"‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã! –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏—Ç–µ—Ä–∞—Ü–∏–∏.\")\n",
    "        break\n",
    "    else:\n",
    "        feedback = test_feedback\n",
    "        print(\"‚ùå –¢–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ–π–¥–µ–Ω—ã. –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ —Å —É—á–µ—Ç–æ–º –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏.\\n\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:\")\n",
    "print(f\"–ò—Ç–µ—Ä–∞—Ü–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {iteration}\")\n",
    "print(f\"–¢–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã: {tests_passed}\")\n",
    "print(f\"–ü—É—Ç—å –∫ –ø—Ä–µ–¥–∏–∫—Ç–∞–º: {predict_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cc4c40",
   "metadata": {},
   "source": [
    "## –ü—Ä–æ—Å–º–æ—Ç—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–∏–∫—Ç–æ–≤\n",
    "\n",
    "–ï—Å–ª–∏ –ø—Ä–µ–¥–∏–∫—Ç—ã –±—ã–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã, –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏—Ö\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ—Å–º–æ—Ç—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–∏–∫—Ç–æ–≤\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "if predict_path and Path(predict_path).exists():\n",
    "    pred_df = pd.read_csv(predict_path)\n",
    "    print(f\"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø—Ä–µ–¥–∏–∫—Ç–æ–≤: {len(pred_df)}\")\n",
    "    print(f\"\\n–ü–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫:\")\n",
    "    print(pred_df.head(10))\n",
    "    print(f\"\\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
    "    print(pred_df.describe())\n",
    "    \n",
    "    # –ü—Ä–æ—Å—Ç–∞—è –º–µ—Ç—Ä–∏–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏\n",
    "    if 'true_label' in pred_df.columns and 'prediction' in pred_df.columns:\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        accuracy = accuracy_score(pred_df['true_label'], pred_df['prediction'])\n",
    "        print(f\"\\n–¢–æ—á–Ω–æ—Å—Ç—å (accuracy): {accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"–ü—Ä–µ–¥–∏–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–µ–¥—ã–¥—É—â—É—é —è—á–µ–π–∫—É –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59277b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Selected Framework\n",
       "**Framework:** H2O AutoML\n",
       "\n",
       "### Reasoning\n",
       "H2O AutoML —è–≤–ª—è–µ—Ç—Å—è –Ω–∞–∏–±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–º –∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–º –≤—ã–±–æ—Ä–æ–º –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (1000 —Å—Ç—Ä–æ–∫, 21 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤) –∏ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏ (–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è). –û–Ω–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –Ω–∞–¥–µ–∂–Ω—ã–π —Å—Ç–µ–∫–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π (GBM, XGBoost, GLM, DRF, DeepLearning), –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é, —Ä–∞–Ω–Ω—é—é –æ—Å—Ç–∞–Ω–æ–≤–∫—É –∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É production-—Å—Ü–µ–Ω–∞—Ä–∏–µ–≤. –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ GPU –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π, –æ–Ω–æ —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å –≤—ã—Å–æ–∫–æ–π –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å—é –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å—é, —á—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ –≤ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –∏ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç AutoGluon, –∫–æ—Ç–æ—Ä–æ–µ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ –Ω–∞ –Ω–µ–±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö, H2O AutoML –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –±–æ–ª–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –∏ –±–æ–ª–µ–µ —à–∏—Ä–æ–∫—É—é —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–º–∏ —Ä–µ—à–µ–Ω–∏—è–º–∏.\n",
       "\n",
       "### Generated Prompt\n",
       "input_variables=['analysis_json', 'frameworks_list', 'metadata_json'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ AutoML –∏ ML-–∏–Ω–∂–µ–Ω–µ—Ä. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤—ã–±—Ä–∞—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π AutoML-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –û—Ü–µ–Ω–∏ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö, —Ä–∞–∑–º–µ—Ä, —Ç–∏–ø –∑–∞–¥–∞—á–∏, –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –∏–∑ —Å–ø–∏—Å–∫–∞.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['analysis_json', 'frameworks_list', 'metadata_json'], input_types={}, partial_variables={}, template='–í–æ—Ç –∞–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:\\n\\n### üìä Data Analysis\\n{analysis_json}\\n\\n### üßæ Metadata\\n{metadata_json}\\n\\n### ‚öôÔ∏è –î–æ—Å—Ç—É–ø–Ω—ã–µ AutoML —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏\\n{frameworks_list}\\n\\n–ü–æ—è—Å–Ω–∏ —Å–≤–æ–π –≤—ã–±–æ—Ä –∫—Ä–∞—Ç–∫–æ, –Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ. –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ö–æ–¥—è—Ç, –≤—ã–±–µ—Ä–∏ –Ω–∞–∏–±–æ–ª–µ–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç. –û—Ç–≤–µ—Ç –≤–µ—Ä–Ω–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:\\n{{\"framework\": \"...\", \"reason\": \"...\"}}'), additional_kwargs={})]\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Your existing call (unchanged)\n",
    "from mas_automl.code_agent.base_pipeline import choose_framework\n",
    "\n",
    "framework, reason, prompt = choose_framework(\n",
    "    DATA_ANALYZE, METADATA, REGISTRY, FINAL_DATA, client)\n",
    "\n",
    "# Pretty display in notebook\n",
    "display(Markdown(f\"\"\"\n",
    "### Selected Framework\n",
    "**Framework:** {framework}\n",
    "\n",
    "### Reasoning\n",
    "{reason}\n",
    "\n",
    "### Generated Prompt\n",
    "{prompt}\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efb6d4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n"
     ]
    }
   ],
   "source": [
    "print(type(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e9ce2a",
   "metadata": {},
   "source": [
    "# –ö–æ–¥–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b098bf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import h2o\n",
      "from h2o.automl import H2OAutoML\n",
      "\n",
      "def train_model(train_df, test_df, label):\n",
      "    h2o.init()\n",
      "    train = h2o.H2OFrame(train_df)\n",
      "    test = h2o.H2OFrame(test_df)\n",
      "    train[label] = train[label].asfactor()\n",
      "    test[label] = test[label].asfactor()\n",
      "    \n",
      "    aml = H2OAutoML(max_models=10, seed=1)\n",
      "    aml.train(x=train.columns, y=label, training_frame=train)\n",
      "    \n",
      "    return aml.leader\n",
      "(True, '–ü—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã.')\n"
     ]
    }
   ],
   "source": [
    "from mas_automl.code_agent.base_pipeline import generate_code, evaluate_code\n",
    "\n",
    "code_sample = generate_code(framework, client, iteration=1, feedback=\"\")\n",
    "print(code_sample)\n",
    "print(evaluate_code(code_sample, framework))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f51fe3c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmas_automl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcode_agent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_pipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_pipeline\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m result = \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\ITMO_bootcamp\\src\\mas_automl\\code_agent\\base_pipeline.py:34\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(max_iterations, llm)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_pipeline\u001b[39m(max_iterations: \u001b[38;5;28mint\u001b[39m = DEFAULT_MAX_ITERATIONS, llm: LLMClient | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> PipelineResult:\n\u001b[32m     33\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"–û—Å–Ω–æ–≤–Ω–æ–π —Å—Ü–µ–Ω–∞—Ä–∏–π: –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–∫–æ–≤ ‚Üí –≤—ã–±–æ—Ä —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ ‚Üí –∫–æ–¥–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è ‚Üí –ø—Ä–æ–≤–µ—Ä–∫–∞.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     data_analysis, metadata, registry = load_mock_inputs()\n\u001b[32m     35\u001b[39m     llm = llm \u001b[38;5;129;01mor\u001b[39;00m LLMClient(LLMConfig())\n\u001b[32m     37\u001b[39m     framework, reason = choose_framework(data_analysis, metadata, registry, llm)\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "from mas_automl.code_agent.base_pipeline import run_pipeline\n",
    "\n",
    "result = run_pipeline(max_iterations=2, llm=client)\n",
    "result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
