{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc0ebeb",
   "metadata": {},
   "source": [
    "## Выбор фреймворка\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd91304",
   "metadata": {},
   "source": [
    "Используйте ноутбук, чтобы по шагам запускать загрузку моков, выбор фреймворка и кодогенерацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3029806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f75451b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ключи data: ['summary', 'priority', 'steps', 'example_pipeline_snippet', 'frameworks_recommended', 'rationale', 'estimated_complexity', 'confidence']\n",
      "Ключи metadata: ['dataset_id', 'name', 'version', 'version_label', 'description', 'citation', 'paper_url', 'paper_reference', 'creator', 'contributor', 'collection_date', 'upload_date', 'language', 'licence', 'url', 'original_data_url', 'minio_url', 'format', 'file_id', 'default_target_attribute', 'ignore_attribute', 'row_id_attribute', 'num_rows', 'num_features', 'num_classes', 'num_missing_values', 'quality', 'dataset_type', 'tags', 'status', 'visibility', 'extra_info', 'local_path']\n",
      "Фреймворки: ['AutoGluon', 'H2O AutoML', 'LightAutoML']\n"
     ]
    }
   ],
   "source": [
    "from mas_automl.code_agent.load_mocks import load_mock_inputs\n",
    "\n",
    "DATA_ANALYZE, METADATA, REGISTRY, FINAL_DATA = load_mock_inputs()\n",
    "print(f\"Ключи data: {list[str](DATA_ANALYZE.keys())}\")\n",
    "print(f\"Ключи metadata: {list(METADATA.keys())}\")\n",
    "print(f\"Фреймворки: {list(REGISTRY.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8586fa58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Loaded Mock Inputs\n",
       "\n",
       "#### Data Analyze Keys\n",
       "summary, priority, steps, example_pipeline_snippet, frameworks_recommended, rationale, estimated_complexity, confidence\n",
       "\n",
       "#### Metadata Keys\n",
       "dataset_id, name, version, version_label, description, citation, paper_url, paper_reference, creator, contributor, collection_date, upload_date, language, licence, url, original_data_url, minio_url, format, file_id, default_target_attribute, ignore_attribute, row_id_attribute, num_rows, num_features, num_classes, num_missing_values, quality, dataset_type, tags, status, visibility, extra_info, local_path\n",
       "\n",
       "#### Registry Frameworks\n",
       "AutoGluon, H2O AutoML, LightAutoML\n",
       "\n",
       "manifest, validation_report, metafeatures, preprocessing_recipe, code_agent_recommendation, run_metadata\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mas_automl.code_agent.load_mocks import load_mock_inputs\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "DATA_ANALYZE, METADATA, REGISTRY, FINAL_DATA = load_mock_inputs()\n",
    "\n",
    "# Pretty display in notebook\n",
    "display(Markdown(f\"\"\"\n",
    "### Loaded Mock Inputs\n",
    "\n",
    "#### Data Analyze Keys\n",
    "{', '.join(DATA_ANALYZE.keys())}\n",
    "\n",
    "#### Metadata Keys\n",
    "{', '.join(METADATA.keys())}\n",
    "\n",
    "#### Registry Frameworks\n",
    "{', '.join(REGISTRY.keys())}\n",
    "\n",
    "{', '.join(FINAL_DATA.keys())}\n",
    "\"\"\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e56cd773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   checking_status         1000 non-null   object \n",
      " 1   duration                1000 non-null   int64  \n",
      " 2   credit_history          1000 non-null   object \n",
      " 3   purpose                 1000 non-null   object \n",
      " 4   credit_amount           1000 non-null   float64\n",
      " 5   savings_status          1000 non-null   object \n",
      " 6   employment              1000 non-null   object \n",
      " 7   installment_commitment  1000 non-null   int64  \n",
      " 8   personal_status         1000 non-null   object \n",
      " 9   other_parties           1000 non-null   object \n",
      " 10  residence_since         1000 non-null   int64  \n",
      " 11  property_magnitude      1000 non-null   object \n",
      " 12  age                     1000 non-null   int64  \n",
      " 13  other_payment_plans     1000 non-null   object \n",
      " 14  housing                 1000 non-null   object \n",
      " 15  existing_credits        1000 non-null   int64  \n",
      " 16  job                     1000 non-null   object \n",
      " 17  num_dependents          1000 non-null   int64  \n",
      " 18  own_telephone           1000 non-null   object \n",
      " 19  foreign_worker          1000 non-null   object \n",
      " 20  class                   1000 non-null   object \n",
      "dtypes: float64(1), int64(6), object(14)\n",
      "memory usage: 164.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "   checking_status  duration                  credit_history   purpose  \\\n",
       " 0              <0         6  critical/other existing credit  radio/tv   \n",
       " 1        0<=X<200        48                   existing paid  radio/tv   \n",
       " \n",
       "    credit_amount    savings_status employment  installment_commitment  \\\n",
       " 0         1169.0  no known savings        >=7                       4   \n",
       " 1         5951.0              <100     1<=X<4                       2   \n",
       " \n",
       "       personal_status other_parties  ...  property_magnitude age  \\\n",
       " 0         male single          none  ...         real estate  67   \n",
       " 1  female div/dep/mar          none  ...         real estate  22   \n",
       " \n",
       "    other_payment_plans housing existing_credits      job num_dependents  \\\n",
       " 0                 none     own                2  skilled              1   \n",
       " 1                 none     own                1  skilled              1   \n",
       " \n",
       "    own_telephone foreign_worker class  \n",
       " 0            yes            yes  good  \n",
       " 1           none            yes   bad  \n",
       " \n",
       " [2 rows x 21 columns])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA_ANALYZE, METADATA, REGISTRY\n",
    "import pandas as pd\n",
    "\n",
    "PATH_TO_CSV = FINAL_DATA[\"manifest\"][\"local_path\"]\n",
    "dataset_df = pd.read_csv(PATH_TO_CSV)\n",
    "\n",
    "dataset_df.info(), dataset_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "954b8d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_status</th>\n",
       "      <th>employment</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>other_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>property_magnitude</th>\n",
       "      <th>age</th>\n",
       "      <th>other_payment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>own_telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>6</td>\n",
       "      <td>critical/other existing credit</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>no known savings</td>\n",
       "      <td>&gt;=7</td>\n",
       "      <td>4</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>67</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0&lt;=X&lt;200</td>\n",
       "      <td>48</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>1&lt;=X&lt;4</td>\n",
       "      <td>2</td>\n",
       "      <td>female div/dep/mar</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>22</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no checking</td>\n",
       "      <td>12</td>\n",
       "      <td>critical/other existing credit</td>\n",
       "      <td>education</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>4&lt;=X&lt;7</td>\n",
       "      <td>2</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>49</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>unskilled resident</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>42</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>4&lt;=X&lt;7</td>\n",
       "      <td>2</td>\n",
       "      <td>male single</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>...</td>\n",
       "      <td>life insurance</td>\n",
       "      <td>45</td>\n",
       "      <td>none</td>\n",
       "      <td>for free</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>24</td>\n",
       "      <td>delayed previously</td>\n",
       "      <td>new car</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>1&lt;=X&lt;4</td>\n",
       "      <td>3</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>no known property</td>\n",
       "      <td>53</td>\n",
       "      <td>none</td>\n",
       "      <td>for free</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>no checking</td>\n",
       "      <td>12</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>4&lt;=X&lt;7</td>\n",
       "      <td>3</td>\n",
       "      <td>female div/dep/mar</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>31</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>unskilled resident</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>30</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>used car</td>\n",
       "      <td>3857.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>1&lt;=X&lt;4</td>\n",
       "      <td>4</td>\n",
       "      <td>male div/sep</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>life insurance</td>\n",
       "      <td>40</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>high qualif/self emp/mgmt</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>no checking</td>\n",
       "      <td>12</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>804.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>&gt;=7</td>\n",
       "      <td>4</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>car</td>\n",
       "      <td>38</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>45</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>1&lt;=X&lt;4</td>\n",
       "      <td>4</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>no known property</td>\n",
       "      <td>23</td>\n",
       "      <td>none</td>\n",
       "      <td>for free</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0&lt;=X&lt;200</td>\n",
       "      <td>45</td>\n",
       "      <td>critical/other existing credit</td>\n",
       "      <td>used car</td>\n",
       "      <td>4576.0</td>\n",
       "      <td>100&lt;=X&lt;500</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>3</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>car</td>\n",
       "      <td>27</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    checking_status  duration                  credit_history  \\\n",
       "0                <0         6  critical/other existing credit   \n",
       "1          0<=X<200        48                   existing paid   \n",
       "2       no checking        12  critical/other existing credit   \n",
       "3                <0        42                   existing paid   \n",
       "4                <0        24              delayed previously   \n",
       "..              ...       ...                             ...   \n",
       "995     no checking        12                   existing paid   \n",
       "996              <0        30                   existing paid   \n",
       "997     no checking        12                   existing paid   \n",
       "998              <0        45                   existing paid   \n",
       "999        0<=X<200        45  critical/other existing credit   \n",
       "\n",
       "                 purpose  credit_amount    savings_status  employment  \\\n",
       "0               radio/tv         1169.0  no known savings         >=7   \n",
       "1               radio/tv         5951.0              <100      1<=X<4   \n",
       "2              education         2096.0              <100      4<=X<7   \n",
       "3    furniture/equipment         7882.0              <100      4<=X<7   \n",
       "4                new car         4870.0              <100      1<=X<4   \n",
       "..                   ...            ...               ...         ...   \n",
       "995  furniture/equipment         1736.0              <100      4<=X<7   \n",
       "996             used car         3857.0              <100      1<=X<4   \n",
       "997             radio/tv          804.0              <100         >=7   \n",
       "998             radio/tv         1845.0              <100      1<=X<4   \n",
       "999             used car         4576.0        100<=X<500  unemployed   \n",
       "\n",
       "     installment_commitment     personal_status other_parties  ...  \\\n",
       "0                         4         male single          none  ...   \n",
       "1                         2  female div/dep/mar          none  ...   \n",
       "2                         2         male single          none  ...   \n",
       "3                         2         male single     guarantor  ...   \n",
       "4                         3         male single          none  ...   \n",
       "..                      ...                 ...           ...  ...   \n",
       "995                       3  female div/dep/mar          none  ...   \n",
       "996                       4        male div/sep          none  ...   \n",
       "997                       4         male single          none  ...   \n",
       "998                       4         male single          none  ...   \n",
       "999                       3         male single          none  ...   \n",
       "\n",
       "     property_magnitude age  other_payment_plans   housing existing_credits  \\\n",
       "0           real estate  67                 none       own                2   \n",
       "1           real estate  22                 none       own                1   \n",
       "2           real estate  49                 none       own                1   \n",
       "3        life insurance  45                 none  for free                1   \n",
       "4     no known property  53                 none  for free                2   \n",
       "..                  ...  ..                  ...       ...              ...   \n",
       "995         real estate  31                 none       own                1   \n",
       "996      life insurance  40                 none       own                1   \n",
       "997                 car  38                 none       own                1   \n",
       "998   no known property  23                 none  for free                1   \n",
       "999                 car  27                 none       own                1   \n",
       "\n",
       "                           job num_dependents  own_telephone foreign_worker  \\\n",
       "0                      skilled              1            yes            yes   \n",
       "1                      skilled              1           none            yes   \n",
       "2           unskilled resident              2           none            yes   \n",
       "3                      skilled              2           none            yes   \n",
       "4                      skilled              2           none            yes   \n",
       "..                         ...            ...            ...            ...   \n",
       "995         unskilled resident              1           none            yes   \n",
       "996  high qualif/self emp/mgmt              1            yes            yes   \n",
       "997                    skilled              1           none            yes   \n",
       "998                    skilled              1            yes            yes   \n",
       "999                    skilled              1           none            yes   \n",
       "\n",
       "    class  \n",
       "0    good  \n",
       "1     bad  \n",
       "2    good  \n",
       "3    good  \n",
       "4     bad  \n",
       "..    ...  \n",
       "995  good  \n",
       "996  good  \n",
       "997  good  \n",
       "998   bad  \n",
       "999  good  \n",
       "\n",
       "[1000 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4deb842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'api_key': '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'}\n"
     ]
    }
   ],
   "source": [
    "# --- Инициализация клиента ---\n",
    "from mas_automl.code_agent.openai_wraper import LLMClient, LLMConfig\n",
    "\n",
    "client = LLMClient(LLMConfig())\n",
    "\n",
    "# --- Вызов выбора фреймворка ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "023583c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Fallback: LLM недоступен.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.chat('say asdasfa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abdb71e",
   "metadata": {},
   "source": [
    "## Выбор фреймворка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a62a8",
   "metadata": {},
   "source": [
    "## Итеративная генерация и тестирование кода\n",
    "\n",
    "Ниже показан процесс итеративной генерации кода с тестированием через execnet_gateway\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e262490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV путь: C:\\Users\\User1\\Desktop\\ITMO_bootcamp\\data\\datasets\\openml_31_credit-g.csv\n",
      "Директория для предиктов: C:\\Users\\User1\\Desktop\\ITMO_bootcamp\\data\\datasets\\predictions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Итеративная генерация и тестирование кода\n",
    "from mas_automl.code_agent.base_pipeline import generate_code, evaluate_code\n",
    "from mas_automl.code_agent.execnet_gateway import PythonSandboxClient\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "CSV_PATH = FINAL_DATA[\"manifest\"][\"local_path\"]\n",
    "OUTPUT_DIR = str(Path(CSV_PATH).parent / \"predictions\")\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "framework = \"scikit-learn\"\n",
    "max_iterations = 3\n",
    "feedback = \"\"\n",
    "\n",
    "print(f\"CSV путь: {CSV_PATH}\")\n",
    "print(f\"Директория для предиктов: {OUTPUT_DIR}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d8881d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Итерация 1/3\n",
      "============================================================\n",
      "\n",
      "Генерация кода...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-14 15:23:35,785 [INFO] Creating new execnet gateway with python=c:\\Users\\User1\\Desktop\\ITMO_bootcamp\\.venv\\Scripts\\python.exe\n",
      "2025-11-14 15:23:35,859 [INFO] Gateway and channel created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерированный код:\n",
      "import pandas as pd\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "def train_model(train_df: pd.DataFrame, test_df: pd.DataFrame, label: str):\n",
      "    numeric_features = ['duration', 'credit_amount', 'installment_commitment', 'residence_since', 'age', 'existing_credits', 'num_dependents']\n",
      "    categorical_features = ['checking_status', 'credit_history', 'purpose', 'savings_status', 'employment', 'personal_status', 'other_parties', 'property_magnitude', 'other_payment_plans', 'housing', 'job', 'own_telephone', 'foreign_worker']\n",
      "    \n",
      "    X_train = train_df.drop(columns=[label])\n",
      "    y_train = train_df[label]\n",
      "    \n",
      "    preprocessor = ColumnTransformer(\n",
      "        transformers=[\n",
      "            ('num', StandardScaler(), numeric_features),\n",
      "            ('cat', OneHotEncoder(), categorical_features)\n",
      "        ]\n",
      "    )\n",
      "    \n",
      "    model = Pipeline(steps=[\n",
      "        ('preprocessor', preprocessor),\n",
      "        ('classifier', RandomForestClassifier())\n",
      "    ])\n",
      "    \n",
      "    model.fit(X_train, y_train)\n",
      "    \n",
      "    X_test = test_df.drop(columns=[label])\n",
      "    predictions = model.predict(X_test)\n",
      "    \n",
      "    return model\n",
      "\n",
      "Тестирование кода...\n",
      "1 - start testing\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\ITMO_bootcamp\\src\\mas_automl\\code_agent\\base_pipeline.py:257\u001b[39m, in \u001b[36mevaluate_code\u001b[39m\u001b[34m(code, framework, csv_path, output_dir, iteration, final_data)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     stdout = \u001b[43mresult\u001b[49m.stdout\n\u001b[32m    258\u001b[39m     \u001b[38;5;66;03m# Ищем маркеры RESULT_START и RESULT_END\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'result' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Тестируем код\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mТестирование кода...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m tests_passed, test_feedback, predict_path = \u001b[43mevaluate_code\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCSV_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFINAL_DATA\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mТесты пройдены: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtests_passed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mОбратная связь: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_feedback\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\ITMO_bootcamp\\src\\mas_automl\\code_agent\\base_pipeline.py:273\u001b[39m, in \u001b[36mevaluate_code\u001b[39m\u001b[34m(code, framework, csv_path, output_dir, iteration, final_data)\u001b[39m\n\u001b[32m    271\u001b[39m             result_dict = {\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mНе удалось найти результат в stdout\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m     feedback = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mОшибка парсинга результата: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStdout: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresult\u001b[49m.stdout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStderr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.stderr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, feedback, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m4 - end gateway\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for iteration in range(1, max_iterations + 1):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Итерация {iteration}/{max_iterations}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Генерируем код\n",
    "    print(\"Генерация кода...\")\n",
    "    code = generate_code(framework, client, iteration, feedback, FINAL_DATA)\n",
    "    print(f\"Сгенерированный код:\\n{code}\\n\")\n",
    "    \n",
    "    # Тестируем код\n",
    "    print(\"Тестирование кода...\")\n",
    "    tests_passed, test_feedback, predict_path = evaluate_code(\n",
    "        code, framework, CSV_PATH, OUTPUT_DIR, iteration, FINAL_DATA\n",
    "    )\n",
    "    \n",
    "    print(f\"Тесты пройдены: {tests_passed}\")\n",
    "    print(f\"Обратная связь: {test_feedback}\")\n",
    "    if predict_path:\n",
    "        print(f\"Путь к предиктам: {predict_path}\")\n",
    "        # Загружаем и показываем предикты\n",
    "        try:\n",
    "            pred_df = pd.read_csv(predict_path)\n",
    "            print(f\"\\nПервые 5 строк предиктов:\")\n",
    "            print(pred_df.head())\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка загрузки предиктов: {e}\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    if tests_passed:\n",
    "        print(\"✅ Все тесты пройдены! Останавливаем итерации.\")\n",
    "        break\n",
    "    else:\n",
    "        feedback = test_feedback\n",
    "        print(\"❌ Тесты не пройдены. Переходим к следующей итерации с учетом обратной связи.\\n\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Итоговый результат:\")\n",
    "print(f\"Итераций выполнено: {iteration}\")\n",
    "print(f\"Тесты пройдены: {tests_passed}\")\n",
    "print(f\"Путь к предиктам: {predict_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cc4c40",
   "metadata": {},
   "source": [
    "## Просмотр сохраненных предиктов\n",
    "\n",
    "Если предикты были успешно сохранены, можно загрузить и проанализировать их\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Просмотр сохраненных предиктов\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "if predict_path and Path(predict_path).exists():\n",
    "    pred_df = pd.read_csv(predict_path)\n",
    "    print(f\"Загружено предиктов: {len(pred_df)}\")\n",
    "    print(f\"\\nПервые 10 строк:\")\n",
    "    print(pred_df.head(10))\n",
    "    print(f\"\\nСтатистика:\")\n",
    "    print(pred_df.describe())\n",
    "    \n",
    "    # Простая метрика точности\n",
    "    if 'true_label' in pred_df.columns and 'prediction' in pred_df.columns:\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        accuracy = accuracy_score(pred_df['true_label'], pred_df['prediction'])\n",
    "        print(f\"\\nТочность (accuracy): {accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"Предикты не найдены. Запустите предыдущую ячейку для генерации.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2916ba0",
   "metadata": {},
   "source": [
    "# СТАРЬЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8971f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_code(\n",
    "    framework: str, llm: LLMClient, iteration: int, feedback: str, final_data: Dict[str, Any] | None = None\n",
    ") -> str:\n",
    "    \"\"\"Генерирует код для обучения модели.\"\"\"\n",
    "    preprocessing_info = \"\"\n",
    "    if final_data:\n",
    "        preprocessing_recipe = final_data.get(\"preprocessing_recipe\", {})\n",
    "        if preprocessing_recipe:\n",
    "            preprocessing_info = (\n",
    "                f\"\\n\\nИнформация о препроцессинге:\\n\"\n",
    "                f\"- Числовые колонки: {preprocessing_recipe.get('numeric_columns', [])}\\n\"\n",
    "                f\"- Категориальные колонки: {preprocessing_recipe.get('categorical_columns', [])}\\n\"\n",
    "                f\"- Тип задачи: {preprocessing_recipe.get('task_type', 'classification')}\\n\"\n",
    "            )\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Итерация {iteration}.\n",
    "    Ты — опытный Data Scientist. Нужно написать компактную корректную функцию train_model(...),\n",
    "    которая использует МОЙ AutoML (он уже импортирован; НЕ нужно определять класс AutoML).\n",
    "\n",
    "    Функция train_model должна:\n",
    "\n",
    "    1) Принимать:\n",
    "        - train_df : pandas.DataFrame\n",
    "        - test_df  : pandas.DataFrame\n",
    "        - label : str\n",
    "\n",
    "    2) Правильно разделять данные:\n",
    "        X = train_df.drop(columns=[label])\n",
    "        y = train_df[label]\n",
    "\n",
    "    3) Инициализировать AutoML строго такими параметрами:\n",
    "        automl = AutoML(\n",
    "            task='classification',\n",
    "            use_preprocessing_pipeline=False,\n",
    "            feature_selector_type=None,\n",
    "            use_val_test_pipeline=False,\n",
    "            auto_models_init_kwargs={{ \n",
    "                \"metric\": \"roc_auc\",\n",
    "                \"time_series\": False,\n",
    "                \"models_list\": [\"linear\", \"forests\", \"boostings\"],\n",
    "                \"blend\": True,\n",
    "                \"stack\": True,\n",
    "                \"n_splits\": 10\n",
    "            }},\n",
    "            n_jobs=3,\n",
    "            random_state=0,\n",
    "        )\n",
    "\n",
    "    4) Обучить модель:\n",
    "        automl = automl.fit(\n",
    "            X, y,\n",
    "            auto_model_fit_kwargs={{\"tuning_timeout\": 10}}\n",
    "        )\n",
    "\n",
    "        — НЕ использовать sklearn в любом виде\n",
    "        — НЕ выполнять вручную препроцессинг, кодирование, скейлинг\n",
    "\n",
    "    5) Получить предсказания:\n",
    "        preds = automl.predict(test_df)\n",
    "\n",
    "    6) Вычислить:\n",
    "        score = automl.auto_model.best_score\n",
    "        test_predictions = preds[:, 1]\n",
    "\n",
    "    7) Вернуть:\n",
    "        return automl, score, test_predictions\n",
    "\n",
    "    Если передано preprocessing_recipe — учитывай его только как информационный блок,\n",
    "    но НЕ применяй его в коде.\n",
    "\n",
    "    Информация о препроцессинге:\n",
    "    {preprocessing_info}\n",
    "\n",
    "    ПРИМЕР КАК ИСПОЛЬЗУЕТСЯ МОЙ AutoML (НЕ копировать, только ориентир):\n",
    "\n",
    "        automl = AutoML(...)\n",
    "        automl = automl.fit(X, y, auto_model_fit_kwargs={{\"tuning_timeout\": 10}})\n",
    "        score = automl.auto_model.best_score\n",
    "        test_predictions = automl.predict(X)[:, 1]\n",
    "\n",
    "    Требования к выводу:\n",
    "    - Вернуть СТРОГО: только код функции + необходимые импорты.\n",
    "    - Никакого текста, комментариев, markdown.\n",
    "    - Функция должна называться train_model.\n",
    "    - Переменные: score и test_predictions — обязательны.\n",
    "\n",
    "    Обратная связь:\n",
    "    {feedback or \"нет\"}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    fallback_code = _fallback_code_template_sklearn(final_data)\n",
    "    raw_code = llm.chat(prompt, fallback=fallback_code)\n",
    "    return _extract_code(raw_code) or fallback_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0dd265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fallback_code_template_sklearn(final_data: Dict[str, Any] | None = None) -> str:\n",
    "    \"\"\"Шаблон кода на scikit-learn для fallback.\"\"\"\n",
    "    numeric_cols = [\"duration\", \"credit_amount\", \"installment_commitment\", \"residence_since\", \"age\", \"existing_credits\", \"num_dependents\"]\n",
    "    categorical_cols = [\"checking_status\", \"credit_history\", \"purpose\", \"savings_status\", \"employment\", \"personal_status\", \"other_parties\", \"property_magnitude\", \"other_payment_plans\", \"housing\", \"job\", \"own_telephone\", \"foreign_worker\"]\n",
    "    \n",
    "    if final_data:\n",
    "        preprocessing_recipe = final_data.get(\"preprocessing_recipe\", {})\n",
    "        if preprocessing_recipe:\n",
    "            numeric_cols = preprocessing_recipe.get(\"numeric_columns\", numeric_cols)\n",
    "            categorical_cols = preprocessing_recipe.get(\"categorical_columns\", categorical_cols)\n",
    "    \n",
    "    return (\n",
    "        \"import pandas as pd\\n\"\n",
    "        \"import numpy as np\\n\"\n",
    "        \"from sklearn.compose import ColumnTransformer\\n\"\n",
    "        \"from sklearn.pipeline import Pipeline\\n\"\n",
    "        \"from sklearn.preprocessing import StandardScaler, OneHotEncoder\\n\"\n",
    "        \"from sklearn.impute import SimpleImputer\\n\"\n",
    "        \"from sklearn.ensemble import RandomForestClassifier\\n\\n\"\n",
    "        f\"numeric_cols = {numeric_cols}\\n\"\n",
    "        f\"categorical_cols = {categorical_cols}\\n\\n\"\n",
    "        \"def train_model(train_df: pd.DataFrame, test_df: pd.DataFrame, label: str):\\n\"\n",
    "        \"    # Подготовка признаков\\n\"\n",
    "        \"    numeric_transformer = Pipeline(steps=[\\n\"\n",
    "        \"        ('imputer', SimpleImputer(strategy='median')),\\n\"\n",
    "        \"        ('scaler', StandardScaler())\\n\"\n",
    "        \"    ])\\n\"\n",
    "        \"    categorical_transformer = Pipeline(steps=[\\n\"\n",
    "        \"        ('imputer', SimpleImputer(strategy='most_frequent')),\\n\"\n",
    "        \"        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\\n\"\n",
    "        \"    ])\\n\"\n",
    "        \"    preprocessor = ColumnTransformer(\\n\"\n",
    "        \"        transformers=[\\n\"\n",
    "        \"            ('num', numeric_transformer, numeric_cols),\\n\"\n",
    "        \"            ('cat', categorical_transformer, categorical_cols)\\n\"\n",
    "        \"        ]\\n\"\n",
    "        \"    )\\n\"\n",
    "        \"    \\n\"\n",
    "        \"    # Подготовка данных\\n\"\n",
    "        \"    X_train = train_df.drop(columns=[label])\\n\"\n",
    "        \"    y_train = train_df[label]\\n\"\n",
    "        \"    \\n\"\n",
    "        \"    # Создание пайплайна\\n\"\n",
    "        \"    model = Pipeline(steps=[\\n\"\n",
    "        \"        ('preprocessor', preprocessor),\\n\"\n",
    "        \"        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10))\\n\"\n",
    "        \"    ])\\n\"\n",
    "        \"    \\n\"\n",
    "        \"    # Обучение\\n\"\n",
    "        \"    model.fit(X_train, y_train)\\n\"\n",
    "        \"    \\n\"\n",
    "        \"    return model\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _extract_code(raw_output: str) -> str:\n",
    "    if \"```\" not in raw_output:\n",
    "        return raw_output.strip()\n",
    "    parts = raw_output.split(\"```\")\n",
    "    if len(parts) < 3:\n",
    "        return raw_output.strip()\n",
    "    code_block = parts[1]\n",
    "    if code_block.startswith((\"python\", \"py\")):\n",
    "        code_block = code_block.split(\"\\n\", 1)[1]\n",
    "    return code_block.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e82433c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = generate_code(framework, client, iteration, feedback, FINAL_DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8833bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "if __package__ is None or __package__ == \"\":\n",
    "    from mas_automl.code_agent.load_mocks import load_mock_inputs  # type: ignore\n",
    "    from mas_automl.code_agent.openai_wraper import LLMClient, LLMConfig  # type: ignore\n",
    "    from mas_automl.code_agent.execnet_gateway import PythonSandboxClient, SandboxResult  # type: ignore\n",
    "else:\n",
    "    from .load_mocks import load_mock_inputs\n",
    "    from .openai_wraper import LLMClient, LLMConfig\n",
    "    from .execnet_gateway import PythonSandboxClient, SandboxResult\n",
    "\n",
    "DEFAULT_MAX_ITERATIONS = 3\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PipelineResult:\n",
    "    framework: str\n",
    "    reason: str\n",
    "    code: str\n",
    "    tests_passed: bool\n",
    "    iterations: int\n",
    "    feedback: str\n",
    "    predict_path: str | None = None\n",
    "\n",
    "\n",
    "def evaluate_code(\n",
    "    code: str,\n",
    "    framework: str,\n",
    "    csv_path: str,\n",
    "    CSV_PATH_TO_PREDICT: str,\n",
    "    output_dir: str,\n",
    "    iteration: int,\n",
    "    final_data: Dict[str, Any] | None = None,\n",
    ") -> Tuple[bool, str, str | None]:\n",
    "    \"\"\"\n",
    "    Выполняет код в песочнице, тестирует функцию train_model и сохраняет предикты.\n",
    "    Возвращает (tests_passed, feedback, predict_path).\n",
    "    \"\"\"\n",
    "    sandbox = PythonSandboxClient.get()\n",
    "    \n",
    "    # Получаем информацию о датасете\n",
    "    target_column = \"class\"\n",
    "    if final_data:\n",
    "        target_column = final_data.get(\"manifest\", {}).get(\"target_column\", \"class\")\n",
    "    print(\"1 - start testing\")\n",
    "    # Подготавливаем код для выполнения\n",
    "    test_code = f\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "from automl import AutoML\n",
    "\n",
    "\n",
    "# Загружаем данные\n",
    "df = pd.read_csv(r'{csv_path}')\n",
    "print(f\"Загружено строк: {{len(df)}}\")\n",
    "\n",
    "# Генерированный код пользователя\n",
    "{code}\n",
    "\n",
    "# Выполняем функцию\n",
    "try:\n",
    "    df['pred'] = np.random.rand(len(df))\n",
    "    df.to_csv(r'{CSV_PATH_TO_PREDICT}', index=False)\n",
    "    # print(f\"Предикты сохранены в: {CSV_PATH_TO_PREDICT}\")\n",
    "    \n",
    "    # Простые проверки\n",
    "    errors = []\n",
    "   \n",
    "    if errors and any(errors):\n",
    "        raise ValueError(\"; \".join([e for e in errors if e]))\n",
    "    \n",
    "    result = {{\"ok\": True, \"predict_path\": \"mock\", \"message\": \"Все проверки пройдены\"}}\n",
    "    \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    result = {{\"ok\": False, \"predict_path\": None, \"message\": str(e), \"traceback\": traceback.format_exc()}}\n",
    "\n",
    "# Выводим результат в формате JSON для парсинга\n",
    "print(\"RESULT_START\")\n",
    "print(json.dumps(result, ensure_ascii=False))\n",
    "print(\"RESULT_END\")\n",
    "\"\"\"\n",
    "    \n",
    "    # Выполняем код в песочнице\n",
    "    result = sandbox.run(test_code)\n",
    "    print(\"2 - end testing\")\n",
    "  \n",
    "    if not result.ok:\n",
    "        feedback = f\"Ошибка выполнения: {result.stderr}\\n{result.stdout}\"\n",
    "        return False, feedback, None\n",
    "    print(\"3 - try gateway\")\n",
    "\n",
    "    # Парсим результат из stdout\n",
    "    try:\n",
    "        stdout = result.stdout\n",
    "        # Ищем маркеры RESULT_START и RESULT_END\n",
    "        if \"RESULT_START\" in stdout and \"RESULT_END\" in stdout:\n",
    "            start_idx = stdout.find(\"RESULT_START\") + len(\"RESULT_START\")\n",
    "            end_idx = stdout.find(\"RESULT_END\")\n",
    "            result_json = stdout[start_idx:end_idx].strip()\n",
    "            result_dict = json.loads(result_json)\n",
    "        else:\n",
    "            # Fallback: пытаемся найти JSON в stdout\n",
    "            import re\n",
    "            json_match = re.search(r'\\{[^{}]*\"ok\"[^{}]*\\}', stdout)\n",
    "            if json_match:\n",
    "                result_dict = json.loads(json_match.group())\n",
    "            else:\n",
    "                result_dict = {\"ok\": False, \"message\": \"Не удалось найти результат в stdout\"}\n",
    "    except Exception as e:\n",
    "        feedback = f\"Ошибка парсинга результата: {e}\\nStdout: {result.stdout}\\nStderr: {result.stderr}\"\n",
    "        return False, feedback, None\n",
    "    print(\"4 - end gateway\")\n",
    "\n",
    "    if result_dict.get(\"ok\", False):\n",
    "        predict_path = result_dict.get(\"predict_path\")\n",
    "        message = result_dict.get(\"message\", \"Проверки пройдены\")\n",
    "        return True, message, predict_path\n",
    "    else:\n",
    "        error_msg = result_dict.get(\"message\", \"Неизвестная ошибка\")\n",
    "        traceback_info = result_dict.get(\"traceback\", \"\")\n",
    "        feedback = f\"Тесты не пройдены: {error_msg}\\n{traceback_info}\"\n",
    "        return False, feedback, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a49ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH_TO_PREDICT = 'C:\\\\Users\\\\User1\\\\Desktop\\\\ITMO_bootcamp\\\\data\\\\datasets\\\\TEST\\\\test1__.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ed49a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-14 19:04:38,553 [INFO] Creating new execnet gateway with python=c:\\Users\\User1\\Desktop\\ITMO_bootcamp\\.venv\\Scripts\\python.exe\n",
      "2025-11-14 19:04:38,645 [INFO] Gateway and channel created.\n",
      "2025-11-14 19:04:38,646 [DEBUG] Sending code to sandbox (attempt 1):\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from pathlib import Path\n",
      "import json\n",
      "from datetime import datetime\n",
      "from automl import AutoML\n",
      "\n",
      "\n",
      "# Загружаем данные\n",
      "df = pd.read_csv(r'C:\\Users\\User1\\Desktop\\ITMO_bootcamp\\data\\datasets\\openml_31_credit-g.csv')\n",
      "print(f\"Загружено строк: {len(df)}\")\n",
      "\n",
      "# Генерированный код пользователя\n",
      "print(5)\n",
      "\n",
      "# Выполняем функцию\n",
      "try:\n",
      "    df['pred'] = np.random.rand(len(df))\n",
      "    df.to_csv(r'C:\\Users\\User1\\Desktop\\ITMO_bootcamp\\data\\datasets\\TEST\\test1__.csv', index=False)\n",
      "    # print(f\"Предикты сохранены в: C:\\Users\\User1\\Desktop\\ITMO_bootcamp\\data\\datasets\\TEST\\test1__.csv\")\n",
      "\n",
      "    # Простые проверки\n",
      "    errors = []\n",
      "\n",
      "    if errors and any(errors):\n",
      "        raise ValueError(\"; \".join([e for e in errors if e]))\n",
      "\n",
      "    result = {\"ok\": True, \"predict_path\": \"mock\", \"message\": \"Все проверки пройдены\"}\n",
      "\n",
      "except Exception as e:\n",
      "    import traceback\n",
      "    result = {\"ok\": False, \"predict_path\": None, \"message\": str(e), \"traceback\": traceback.format_exc()}\n",
      "\n",
      "# Выводим результат в форма...[truncated]\n",
      "2025-11-14 19:04:38,647 [DEBUG] Code sent, waiting for result...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование кода...\n",
      "1 - start testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-14 19:04:44,692 [DEBUG] Received result from sandbox (attempt 1).\n",
      "2025-11-14 19:04:44,693 [INFO] [sandbox stdout]\n",
      "Загружено строк: 1000\n",
      "5\n",
      "RESULT_START\n",
      "{\"ok\": true, \"predict_path\": \"mock\", \"message\": \"Все проверки пройдены\"}\n",
      "RESULT_END\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - end testing\n",
      "3 - try gateway\n",
      "4 - end gateway\n",
      "Тесты пройдены: True\n",
      "Обратная связь: Все проверки пройдены\n",
      "Путь к предиктам: C:\\Users\\User1\\Desktop\\ITMO_bootcamp\\data\\datasets\\TEST\\test1__.csv\n",
      "\n",
      "Первые 5 строк предиктов:\n",
      "  checking_status  duration                  credit_history  \\\n",
      "0              <0         6  critical/other existing credit   \n",
      "1        0<=X<200        48                   existing paid   \n",
      "2     no checking        12  critical/other existing credit   \n",
      "3              <0        42                   existing paid   \n",
      "4              <0        24              delayed previously   \n",
      "\n",
      "               purpose  credit_amount    savings_status employment  \\\n",
      "0             radio/tv         1169.0  no known savings        >=7   \n",
      "1             radio/tv         5951.0              <100     1<=X<4   \n",
      "2            education         2096.0              <100     4<=X<7   \n",
      "3  furniture/equipment         7882.0              <100     4<=X<7   \n",
      "4              new car         4870.0              <100     1<=X<4   \n",
      "\n",
      "   installment_commitment     personal_status other_parties  ...  age  \\\n",
      "0                       4         male single          none  ...   67   \n",
      "1                       2  female div/dep/mar          none  ...   22   \n",
      "2                       2         male single          none  ...   49   \n",
      "3                       2         male single     guarantor  ...   45   \n",
      "4                       3         male single          none  ...   53   \n",
      "\n",
      "  other_payment_plans   housing existing_credits                 job  \\\n",
      "0                none       own                2             skilled   \n",
      "1                none       own                1             skilled   \n",
      "2                none       own                1  unskilled resident   \n",
      "3                none  for free                1             skilled   \n",
      "4                none  for free                2             skilled   \n",
      "\n",
      "   num_dependents own_telephone  foreign_worker class      pred  \n",
      "0               1           yes             yes  good  0.489676  \n",
      "1               1          none             yes   bad  0.102710  \n",
      "2               2          none             yes  good  0.697033  \n",
      "3               2          none             yes  good  0.620428  \n",
      "4               2          none             yes   bad  0.630522  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(\"Генерация кода...\")\n",
    "# code = generate_code(framework, client, iteration, feedback, FINAL_DATA)\n",
    "# print(f\"Сгенерированный код:\\n{code}\\n\")\n",
    "iteration = 1 \n",
    "# Тестируем код\n",
    "print(\"Тестирование кода...\")\n",
    "tests_passed, test_feedback, predict_path = evaluate_code(\n",
    "    \"print(5)\", framework, CSV_PATH, CSV_PATH_TO_PREDICT, OUTPUT_DIR, iteration, FINAL_DATA\n",
    ")\n",
    "\n",
    "predict_path = CSV_PATH_TO_PREDICT\n",
    "\n",
    "print(f\"Тесты пройдены: {tests_passed}\")\n",
    "print(f\"Обратная связь: {test_feedback}\")\n",
    "if predict_path:\n",
    "    print(f\"Путь к предиктам: {predict_path}\")\n",
    "    # Загружаем и показываем предикты\n",
    "    try:\n",
    "        pred_df = pd.read_csv(predict_path)\n",
    "        print(f\"\\nПервые 5 строк предиктов:\")\n",
    "        print(pred_df.head())\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка загрузки предиктов: {e}\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59277b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Selected Framework\n",
       "**Framework:** H2O AutoML\n",
       "\n",
       "### Reasoning\n",
       "H2O AutoML является наиболее стабильным и универсальным выбором для табличных данных данного размера (1000 строк, 21 признаков) и типа задачи (бинарная классификация). Оно предлагает надежный стекинг моделей (GBM, XGBoost, GLM, DRF, DeepLearning), автоматическую кросс-валидацию, раннюю остановку и поддержку production-сценариев. Несмотря на отсутствие поддержки мультимодальности и GPU для всех моделей, оно хорошо подходит для задач классификации с высокой воспроизводимостью и стабильностью, что особенно важно в корпоративных и промышленных условиях. В отличие от AutoGluon, которое требует больше ресурсов и может быть менее предсказуемо на небольших наборах данных, H2O AutoML обеспечивает более предсказуемое поведение и более широкую совместимость с существующими инфраструктурными решениями.\n",
       "\n",
       "### Generated Prompt\n",
       "input_variables=['analysis_json', 'frameworks_list', 'metadata_json'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Ты — эксперт по AutoML и ML-инженер. Твоя задача — выбрать наиболее подходящий AutoML-фреймворк для табличных данных. Оцени качество данных, размер, тип задачи, ограничения и предложи лучший вариант из списка.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['analysis_json', 'frameworks_list', 'metadata_json'], input_types={}, partial_variables={}, template='Вот анализ датасета и метаданные:\\n\\n### 📊 Data Analysis\\n{analysis_json}\\n\\n### 🧾 Metadata\\n{metadata_json}\\n\\n### ⚙️ Доступные AutoML фреймворки\\n{frameworks_list}\\n\\nПоясни свой выбор кратко, но содержательно. Если несколько подходят, выбери наиболее универсальный и стабильный вариант. Ответ верни в формате JSON:\\n{{\"framework\": \"...\", \"reason\": \"...\"}}'), additional_kwargs={})]\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Your existing call (unchanged)\n",
    "from mas_automl.code_agent.base_pipeline import choose_framework\n",
    "\n",
    "framework, reason, prompt = choose_framework(\n",
    "    DATA_ANALYZE, METADATA, REGISTRY, FINAL_DATA, client)\n",
    "\n",
    "# Pretty display in notebook\n",
    "display(Markdown(f\"\"\"\n",
    "### Selected Framework\n",
    "**Framework:** {framework}\n",
    "\n",
    "### Reasoning\n",
    "{reason}\n",
    "\n",
    "### Generated Prompt\n",
    "{prompt}\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efb6d4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n"
     ]
    }
   ],
   "source": [
    "print(type(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e9ce2a",
   "metadata": {},
   "source": [
    "# Кодогенерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b098bf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import h2o\n",
      "from h2o.automl import H2OAutoML\n",
      "\n",
      "def train_model(train_df, test_df, label):\n",
      "    h2o.init()\n",
      "    train = h2o.H2OFrame(train_df)\n",
      "    test = h2o.H2OFrame(test_df)\n",
      "    train[label] = train[label].asfactor()\n",
      "    test[label] = test[label].asfactor()\n",
      "    \n",
      "    aml = H2OAutoML(max_models=10, seed=1)\n",
      "    aml.train(x=train.columns, y=label, training_frame=train)\n",
      "    \n",
      "    return aml.leader\n",
      "(True, 'Проверки пройдены.')\n"
     ]
    }
   ],
   "source": [
    "from mas_automl.code_agent.base_pipeline import generate_code, evaluate_code\n",
    "\n",
    "code_sample = generate_code(framework, client, iteration=1, feedback=\"\")\n",
    "print(code_sample)\n",
    "print(evaluate_code(code_sample, framework))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6582026e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.2'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn; sklearn.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip freeze [options]\n",
      "\n",
      "no such option: -m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51fe3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl import AutoML"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
