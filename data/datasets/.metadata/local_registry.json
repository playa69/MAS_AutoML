{
  "AutoGluon": "AutoGluon — AutoML-фреймворк AWS для табличных, текстовых, визуальных и мультимодальных данных. Использует ансамблирование (stacking, bagging, blending) и автоматический подбор гиперпараметров. Архитектура модульная: AutoGluon-Tabular, AutoGluon-Multimodal, AutoGluon-TimeSeries. Поддерживает GPU, распределённое обучение и масштабирование на больших наборах данных. \n\nГде применять: универсальные задачи классификации и регрессии на табличных данных; задачи анализа изображений (classification, object detection) и текстов (sentiment analysis, NER) через AutoMM; смешанные типы данных (таблица + текст/изображение); Kaggle/продакшн-сценарии, где нужно получить максимум качества без ручной настройки. \n\nТехнические возможности: автоматическое кодирование категориальных признаков; генерация новых признаков; встроенный HPO (Bayesian Optimization + Random Search); сохранение и загрузка моделей; интеграция с PyTorch и MXNet; поддержка обучения на GPU. \n\nОграничения: плохо подходит для графовых, многотабличных и сильно временных зависимостей; ограниченный контроль над архитектурами нейросетей; долгие циклы обучения при полном стекинге; RAM и VRAM-зависимый; требует хранения всех промежуточных моделей. \n\nТипичная производительность: на средних наборах данных (до 1 млн строк) достигает state-of-the-art качества при 1–3 часах обучения на GPU. Время масштабируется линейно от числа признаков и размеров ансамбля. \n\nОптимально использовать: при ограниченном времени разработки, когда важно качество предсказаний и допускается несколько часов обучения; когда требуется мультимодальная поддержка и автоматический ансамбль. Не использовать — при необходимости полностью кастомных архитектур, моделей графов, временных зависимостей или строгих лимитов по времени обучения. \n\nПример:\n```python\nfrom autogluon.tabular import TabularPredictor\npred = TabularPredictor(label='target').fit('data.csv', time_limit=3600)\n```",

  "H2O AutoML": "H2O AutoML — промышленный AutoML-фреймворк на Java, с API для Python, R и Scala. Реализует автоматическое обучение и стекинг моделей (GBM, XGBoost, GLM, DRF, DeepLearning, StackedEnsemble). Поддерживает Spark, Hadoop и распределённое обучение. \n\nГде применять: задачи классификации и регрессии на табличных данных от десятков МБ до сотен ГБ; production-сценарии с кластерами Spark/Hadoop; проекты, где важна воспроизводимость и стабильность. Подходит для корпоративных систем, где уже есть JVM-инфраструктура. \n\nТехнические возможности: автоматический отбор признаков, early stopping, кросс-валидация, генерация leaderboard моделей, автоматическое сохранение лучших моделей, интеграция с MOJO/POJO для деплоя в Java-приложения. Поддерживает GPU для XGBoost и Deep Learning. \n\nОграничения: только табличные данные; отсутствует поддержка изображений, текста и мультимодальности; высокая нагрузка на RAM при больших данных; ограниченная кастомизация пайплайна; не подходит для сильно разреженных данных без предварительного преобразования. \n\nТипичная производительность: на наборе из 1–10 млн строк обучение занимает от 20 минут до 2 часов при `max_runtime_secs=3600`. Масштабируется горизонтально, но требует настройки кластера. \n\nОптимально использовать: если нужно стабильное, масштабируемое решение для классических ML-задач; если требуется автоматический стекинг, лидерборд и деплой моделей. Не использовать — при мультимодальных данных, кастомных пайплайнах, NLP и CV-задачах. \n\nПример:\n```python\nimport h2o\nfrom h2o.automl import H2OAutoML\nh2o.init()\ndf = h2o.import_file('data.csv')\naml = H2OAutoML(max_runtime_secs=3600)\naml.train(y='target', training_frame=df)\n```",


  "LightAutoML": "LightAutoML (LAMA) — AutoML-фреймворк от Sber AI Lab, оптимизированный для промышленных задач на табличных данных. Поддерживает автоматический feature engineering, отбор признаков, ансамбли моделей (CatBoost, LightGBM, Linear, NN), интерпретируемость и white-box режим. \n\nГде применять: задачи классификации, регрессии, scoring в банках, финтехе, телекомах и промышленности; средние и крупные датасеты (до 10 млн строк); продакшн-сценарии, где важны контроль, воспроизводимость и интерпретируемость. \n\nТехнические возможности: оптимизация по CPU (LightGBM/CatBoost), автоматический выбор признаков и их типов, управление ролями (`roles`), white-box пресеты для интерпретируемости, поддержка ограничений по времени (`timeout`), работа на одной или нескольких CPU. Есть встроенная explainability (SHAP, permutation importance). \n\nОграничения: только табличные данные; мультимодальность (текст, изображения) ограничена экспериментальными модулями; слабая поддержка временных и графовых структур; нет встроенной GPU-поддержки; требует аккуратного задания ролей признаков. \n\nТипичная производительность: 10–30 минут для среднего набора (до 1 млн строк); до 2 часов для крупных (до 10 млн). Даёт результат, сравнимый с ручной настройкой опытного DS. \n\nОптимально использовать: для задач с ограниченными ресурсами и требованиями к explainability; при необходимости стабильного AutoML для tabular production. Не использовать — если нужно обучение на GPU, мультимодальность, сложные временные зависимости. \n\nПример:\n```python\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML\nfrom lightautoml.tasks import Task\nimport pandas as pd\ntrain = pd.read_csv('train.csv')\nautoml = TabularAutoML(task=Task('binary', metric='auc'))\nroles = {'target': 'target'}\nautoml.fit_predict(train, roles=roles)\n```"
}
