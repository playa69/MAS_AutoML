{
    "AutoGluon": "AutoGluon — AutoML-фреймворк AWS для табличных, текстовых, визуальных и мультимодальных данных. Использует ансамблирование (stacking, bagging, blending) и автоматический подбор гиперпараметров. Архитектура модульная: AutoGluon-Tabular, AutoGluon-Multimodal, AutoGluon-TimeSeries. Поддерживает GPU, распределённое обучение и масштабирование на больших наборах данных. \n\nГде применять: универсальные задачи классификации и регрессии на табличных данных; задачи анализа изображений (classification, object detection) и текстов (sentiment analysis, NER) через AutoMM; смешанные типы данных (таблица + текст/изображение); Kaggle/продакшн-сценарии, где нужно получить максимум качества без ручной настройки. \n\nТехнические возможности: автоматическое кодирование категориальных признаков; генерация новых признаков; встроенный HPO (Bayesian Optimization + Random Search); сохранение и загрузка моделей; интеграция с PyTorch; поддержка обучения на GPU; удобный leaderboard и анализ вкладов моделей. \n\nОграничения: плохо подходит для графовых, многотабличных и сильно временных зависимостей; ограниченный контроль над архитектурами нейросетей; долгие циклы обучения при полном стекинге; RAM/VRAM-зависимость; хранит множество промежуточных артефактов. \n\nТипичная производительность: на средних наборах данных (до ~1 млн строк) достигает сильного качества при 30–180 мин обучения (CPU/GPU). \n\nУстановка:\n```bash\npip install -U autogluon.tabular\n```\n\nСоветы и тюнинг:\n- `presets`: 'medium_quality_faster_train', 'high_quality', 'best_quality', 'optimize_for_deployment'.\n- Контроль времени: `time_limit` (сек), ограничивайте, если важна скорость.\n- Контроль состава моделей: `hyperparameters` (можно отключать тяжёлые модели, например 'KNN', 'NN_Torch').\n- Тип задачи: для 'classification' определите бинарная/мульти по числу классов; для AutoGluon нужно 'binary' или 'multiclass'.\n- Лидерборд: `predictor.leaderboard(silent=True)` для оценки моделей.\n\nПодводные камни:\n- Большие наборы категориальных признаков увеличивают память и время; по возможности снизить кардинальность.\n- При стекинге растёт время/память; используйте более лёгкие `presets`.\n- Для воспроизводимости задайте `random_state` при создании `TabularPredictor`.\n\nПример:\n```python\nfrom autogluon.tabular import TabularPredictor\n\npred = TabularPredictor(label='target', problem_type='binary', eval_metric='roc_auc', random_state=42)\npred.fit(train_data='train.csv',\n         presets='medium_quality_faster_train',\n         time_limit=1800,\n         hyperparameters={'GBM': {}, 'CAT': {}, 'XGB': {}, 'NN_Torch': None, 'KNN': None},\n         verbosity=0)\nprint(pred.leaderboard(silent=True))\n```",
  
    "H2O AutoML": "H2O AutoML — промышленный AutoML-фреймворк на JVM, с API для Python/R/Scala. Реализует автоматический перебор и стекинг моделей (GBM, XGBoost, GLM, DRF, DeepLearning, StackedEnsemble). Поддерживает Spark/Hadoop и распределённое обучение. \n\nГде применять: классификация и регрессия на табличных данных от десятков МБ до сотен ГБ; enterprise-сценарии с требованиями к стабильности и деплою в Java-окружениях. \n\nТехнические возможности: кросс-валидация, early stopping, автоматический leaderboard, сохранение лучших моделей; экспорт через MOJO/POJO; интеграция с H2O Flow. Поддержка GPU — для XGBoost/Deep Learning. \n\nОграничения: только табличные данные; нет изображений/текста/мультимодальности; значительное потребление RAM; ограниченная кастомизация пайплайна. \n\nТипичная производительность: 20–120 мин на наборах 1–10 млн строк при `max_runtime_secs`≈3600 (зависит от ресурсов). \n\nУстановка и запуск:\n```bash\npip install h2o\n# Требуется установленная Java (JDK/JRE) 8+ на хосте\n```\n\nСоветы и тюнинг:\n- Инициализация кластера: `h2o.init(max_mem_size='8G', nthreads=-1)`, следите за RAM.\n- Ограничение времени и качества: `max_runtime_secs`, `stopping_metric`, `nfolds`.\n- Категориальные признаки: приводите к фактору (`asfactor`) при необходимости.\n- Деплой: используйте экспорт MOJO для встраивания в Java-сервисы.\n\nПодводные камни:\n- Конверсия данных в `H2OFrame` может быть узким местом на больших наборах; загружайте напрямую из файла/паркет.\n- На машинах без корректной Java `h2o.init()` не стартует; проверяйте версию JDK.\n- GPU ускоряет не все алгоритмы; не ожидайте ускорения для DRF/GLM.\n\nПример:\n```python\nimport h2o\nfrom h2o.automl import H2OAutoML\nh2o.init(max_mem_size='8G', nthreads=-1)\ndf = h2o.import_file('data.csv')\naml = H2OAutoML(max_runtime_secs=1800, seed=42, stopping_metric='AUC', nfolds=5)\naml.train(y='target', training_frame=df)\nprint(aml.leaderboard.head())\n```", 
  
    "LightAutoML": "LightAutoML (LAMA) — AutoML от Sber AI Lab, оптимизированный для промышленных задач на табличных данных. Поддерживает автоматический feature engineering, отбор признаков, ансамбли (CatBoost, LightGBM, Linear, простые NN), интерпретируемость и white-box режим. \n\nГде применять: классификация/регрессия, скоринг и риск-модели; средние и крупные датасеты (до ~10 млн строк); сценарии, где важны контроль, воспроизводимость и объяснимость решений. \n\nТехнические возможности: CPU-оптимизация (LightGBM/CatBoost), управление ролями (`roles`), пресеты для white-box/gray-box, ограничение по времени (`timeout`), кросс-валидация, базовые отчёты и важности признаков. \n\nОграничения: только табличные данные; ограниченная мультимодальность; слабая поддержка сложных временных и графовых структур; нет нативной GPU-оптимизации; аккуратная настройка `roles` обязательна. \n\nТипичная производительность: 10–30 минут для средних наборов (~1 млн строк) и до 2 часов для крупных. \n\nУстановка:\n```bash\npip install lightautoml\n```\n\nСоветы и тюнинг:\n- Обязательно задавайте `roles` (например, `{'target': 'target', 'drop': ['id']}`) — это влияет на корректность пайплайна.\n- Контроль времени: `timeout` (мин); для быстрых итераций ставьте 5–15 мин.\n- Предустановки: используйте TabularAutoML с `Task('binary'|'reg', metric=...)`; метрика определяет оптимизацию.\n- Ограничение ресурсов: оставляйте `cpu_limit` и `reader_params={'n_jobs': ...}` для предсказуемого времени.\n- Интерпретируемость: включайте white-box пресеты и анализируйте важности (Permutation/SHAP).\n\nПодводные камни:\n- Неверные `roles` (например, неубранные идентификаторы) приводят к утечкам и переобучению.\n- На очень разреженных/высококардинальных данных лучше заранее нормализовать/агрегировать признаки.\n- Без `timeout` пайплайн может работать существенно дольше ожидаемого.\n\nПример:\n```python\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML\nfrom lightautoml.tasks import Task\nimport pandas as pd\n\ntrain = pd.read_csv('train.csv')\nautoml = TabularAutoML(task=Task('binary', metric='auc'))\nroles = {'target': 'target', 'drop': ['id']}\n_oof_pred = automl.fit_predict(train, roles=roles, timeout=1200)\nprint(automl.get_feature_scores())\n```"
  }
  